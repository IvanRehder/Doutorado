;Scopus;"(TITLE-ABS-KEY(mum-t: OR (manned OR unmanned) AND team) OR TITLE-ABS-KEY (""loyal wingman"")) AND (TITLE-ABS-KEY(""cognitive systems"") OR TITLE-ABS-KEY (""artificial intelligence"" OR AI)) AND ( LIMIT-TO ( DOCTYPE,""cp"" ) OR LIMIT-TO ( DOCTYPE,""ar"" ) ) AND ( LIMIT-TO ( LANGUAGE,""English"" ) )"
;EXPORT DATE:18 May 2023;
;;
Author;Saleem, M.R., Mayne, R., Napolitano, R.;
Title;Analysis of gaze patterns during facade inspection to understand inspector sense-making processes;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148398660&doi=10.1038%2fs41598-023-29950-w&partnerID=40&md5=02b030d601c56dd852e26d2a938eebba;
-;-;
DOI;DOI: 10.1038/s41598-023-29950-w;
Abstract;"ABSTRACT: This work seeks to capture how an expert interacts with a structure during a facade inspection so that more detailed and situationally-aware inspections can be done with autonomous robots in the future. Eye tracking maps where an inspector is looking during a structural inspection, and it recognizes implicit human attention. Experiments were performed on a facade during a damage assessment to analyze key, visually-based features that are important for understanding human-infrastructure interaction during the process. For data collection and analysis, experiments were conducted to assess an inspector’s behavioral changes while assessing a real structure. These eye tracking features provided the basis for the inspector’s intent prediction and were used to understand how humans interact with the structure during the inspection processes. This method will facilitate information-sharing and decision-making during the inspection processes for collaborative human-robot teams; thus, it will enable unmanned aerial vehicle (UAV) for future building inspection through artificial intelligence support. © 2023, The Author(s).";
-;-;
Author;Cai, W., Liu, Z., Zhang, M., Wang, C.;
Title;Cooperative Artificial Intelligence for underwater robotic swarm;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150443368&doi=10.1016%2fj.robot.2023.104410&partnerID=40&md5=87ac7791ceb1ad1fb52768415f00b57b;
-;-;
DOI;DOI: 10.1016/j.robot.2023.104410;
Abstract;ABSTRACT: Underwater Robots such as Autonomous Underwater Vehicles (AUVs) and Remotely Operated Vehicles (ROVs) has played an important role in many tasks, such as marine environmental monitoring, underwater resource exploration, oil and gas industries, hydrographic surveys, military missions, etc. Underwater robotic swarm is a team of cooperative underwater robots which focuses on controlling multiple underwater robots to work in an organic group. In contrast to a single underwater robot, underwater robotic swarm represents higher operation efficiency and better stability while executing complex tasks. However, it needs higher intelligence to realize complementary cooperation than a single robot. It is beneficial to researchers to present a comprehensive survey of the state of the art of cooperative research for underwater robotic swarm. We observe that the research of Artificial Intelligence (AI) for multiple underwater robots is still in an early stage. In this paper, we study different collaborative operation mode in detail, such as formation control, task allocation, path planning, obstacle avoidance, flocking control etc. We propose different classification frameworks for these research topics and it also can be used to compare different methods and help engineers choose suitable methods for various applications. To achieve better cooperative performance of underwater robots, there are several key factors, including multi-source heterogeneous sensing, cooperative communication and navigation, information fusion and decision. Moreover, cooperative AI for underwater robotic swarm has different kinds of interesting and helpful applications. Finally, several possible applied AI methods including meta-heuristic algorithms, deep learning method and distributed learning method are accomplishing to cooperation of underwater robotic swarm. © 2023 Elsevier B.V.;
-;-;
Author;Betz, J., Betz, T., Fent, F., Geisslinger, M., Heilmeier, A., Hermansdorfer, L., Herrmann, T., Huch, S., Karle, P., Lienkamp, M., Lohmann, B., Nobis, F., Ögretmen, L., Rowold, M., Sauerbeck, F., Stahl, T., Trauth, R., Werner, F., Wischnewski, A.;
Title;TUM autonomous motorsport: An autonomous racing software for the Indy Autonomous Challenge;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146358202&doi=10.1002%2frob.22153&partnerID=40&md5=18e28675d0cc5db63f1b9fd4f0862ccb;
-;-;
DOI;DOI: 10.1002/rob.22153;
Abstract;ABSTRACT: For decades, motorsport has been an incubator for innovations in the automotive sector and brought forth systems, like, disk brakes or rearview mirrors. Autonomous racing series such as Roborace, F1Tenth, or the Indy Autonomous Challenge (IAC) are envisioned as playing a similar role within the autonomous vehicle sector, serving as a proving ground for new technology at the limits of the autonomous systems capabilities. This paper outlines the software stack and approach of the TUM Autonomous Motorsport team for their participation in the IAC, which holds two competitions: A single-vehicle competition on the Indianapolis Motor Speedway and a passing competition at the Las Vegas Motor Speedway. Nine university teams used an identical vehicle platform: A modified Indy Lights chassis equipped with sensors, a computing platform, and actuators. All the teams developed different algorithms for object detection, localization, planning, prediction, and control of the race cars. The team from Technical University of Munich (TUM) placed first in Indianapolis and secured second place in Las Vegas. During the final of the passing competition, the TUM team reached speeds and accelerations close to the limit of the vehicle, peaking at around (Formula presented.) and (Formula presented.). This paper will present details of the vehicle hardware platform, the developed algorithms, and the workflow to test and enhance the software applied during the 2-year project. We derive deep insights into the autonomous vehicle's behavior at high speed and high acceleration by providing a detailed competition analysis. On the basis of this, we deduce a list of lessons learned and provide insights on promising areas of future work based on the real-world evaluation of the displayed concepts. © 2023 The Authors. Journal of Field Robotics published by Wiley Periodicals LLC.;
-;-;
Author;Sparrow, R.J., Henschke, A.;
Title;Minotaurs, Not Centaurs: The Future of Manned-Unmanned Teaming;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150704209&doi=10.55540%2f0031-1723.3207&partnerID=40&md5=54c02ab7981f206d345e636305c33cc9;
-;-;
DOI;DOI: 10.55540/0031-1723.3207;
Abstract;ABSTRACT: Contesting Paul Scharre’s influential vision of “centaur warfighting” and the idea that autonomous weapon systems will replace human warfighters, this article proposes that the manned-unmanned teams of the future are more likely to be minotaurs, teams of humans under the control, supervision, or command of artificial intelligence. It examines the likely composition of the future force and prompts a necessary conversation about the ethical issues raised by minotaur warfighting. © 2023 Robert J. Sparrow and Adam Henschke.;
-;-;
Author;Yan, F., Zhang, H., Li, Y., Yang, Y., Liu, Y.;
Title;End-to-End: A Simple Template for the Long-Tailed-Recognition of Transmission Line Clamps via a Vision-Language Model;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149905291&doi=10.3390%2fapp13053287&partnerID=40&md5=f3d46b653e1f61f373f8ac9012b16e43;
-;-;
DOI;DOI: 10.3390/app13053287;
Abstract;ABSTRACT: Raw image classification datasets generally maintain a long-tailed distribution in the real world. Standard classification algorithms face a substantial issue because many labels only relate to a few categories. The model learning processes will tend toward the dominant labels under the influence of their loss functions. Existing systems typically use two stages to improve performance: pretraining on initial imbalanced datasets and fine-tuning on balanced datasets via re-sampling or logit adjustment. These have achieved promising results. However, their limited self-supervised information makes it challenging to transfer such systems to other vision tasks, such as detection and segmentation. Using large-scale contrastive visual-language pretraining, the Open AI team discovered a novel visual recognition method. We provide a simple one-stage model called the text-to-image network (TIN) for long-tailed recognition (LTR) based on the similarities between textual and visual features. The TIN has the following advantages over existing techniques: (1) Our model incorporates textual and visual semantic information. (2) This end-to-end strategy achieves good results with fewer image samples and no secondary training. (3) By using seesaw loss, we further reduce the loss gap between the head category and the tail category. These adjustments encourage large relative magnitudes between the logarithms of rare and dominant labels. TIN conducted extensive comparative experiments with a large number of advanced models on ImageNet-LT, the largest long-tailed public dataset, and achieved the state-of-the-art for a single-stage model with 72.8% at Top-1 accuracy. © 2023 by the authors.;
-;-;
Author;Ricardo, J.A., Giacomossi, L., Trentin, J.F.S., Brancalion, J.F.B., Maximo, M.R.O.A., Santos, D.A.;
Title;Cooperative Threat Engagement Using Drone Swarms;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147295554&doi=10.1109%2fACCESS.2023.3239817&partnerID=40&md5=386bd8fbb56ec16a800de73ac0143dab;
-;-;
DOI;DOI: 10.1109/ACCESS.2023.3239817;
Abstract;ABSTRACT: The ability of multiple manned and unmanned aircraft systems to cooperatively engage and disable an aerial threat plays a decisive role in modern warfare scenarios. In this paper, we apply key methods to enable the so-called cooperative threat engagement capability among multiple networked agents, e.g., a swarm of drones, with combat and communication capabilities. In particular, this research combines AI-based decision-making and control techniques for a swarm of loyal wingman drones to coordinate efficient defense actions in a cooperative and autonomous manner. We apply these concepts in a defense scenario that is modeled to analyze the loyal wingman concept, which we consider an interesting testbed for cooperative decision-making and low-level control techniques. The investigated methods were implemented in a realistic 3D UAV simulator for demonstration and evaluation. © 2013 IEEE.;
-;-;
Author;Al-Gawda, M.G., Lau, C.Y., Lai, N.S.;
Title;AUTONOMOUS UAV INSPECTION SYSTEM FOR PREVENTIVE MAINTENANCE OF SOLAR FARMS;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149860641&partnerID=40&md5=a422cd3483d69fc2f4d8fc2aa5fe8759;
-;-;
Abstract;ABSTRACT: The expansion in energy consumption led to the growth in providing more sustainable energy resources and inspection techniques to sustain their development. This expansion will require systematic routine inspections in solar facilities to maintain safe conditions and provide early check-in for natural occurring defects that deteriorate the power efficiency. However, large solar power plants are established in large areas. Traditionally, maintenance crews will personally check the modules or be sent to erroneous zones with thermal cameras, cranes, and scissors lift. It is time-consuming and challenging to walk through a wide area with heavy equipment. A full sweep will take several days for a team, making it a difficult task. Therefore, an autonomous Unmanned Arial Vehicle (UAV) inspection system for preventive maintenance is constructed to radically reduce the workload of people, injuries, money, and time. Using Artificial Intelligence (AI) and deep learning, the system will automatically detect and classify cell type, surface defects, and number of defects. simultaneously, the UAV will autonomously navigate across panel arrays using machine vision algorithms for trajectory tracking and path segmentation along with providing localization for transition between arrays and precision landing to enable wireless charging across the docking station. Multiple tests were performed on this system, giving it a 92.13% average accuracy, 80.33% average precision for the defect detection model, 96% average accuracy, 96.05%, and 96.05% average precision for the solar cell type classifier. The autonomous navigation provided 85% accuracy, while the precision landing using Augmented Reality University of Cordoba (ArUco) localization has a relatively accurate landing with a 9.12 cm average offset distance from the center of the docking station. © School of Engineering, Taylor’s University.;
-;-;
Author;Coutinho, R.W.L., Boukerche, A.;
Title;UAV-Mounted Cloudlet Systems for Emergency Response in Industrial Areas;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132537931&doi=10.1109%2fTII.2022.3174113&partnerID=40&md5=760353cfc448c85d1a2111b7b9f4d140;
-;-;
DOI;DOI: 10.1109/TII.2022.3174113;
Abstract;ABSTRACT: The advancements in Internet of Things (IoT) and embedded systems, 5G networks and next-generation wireless systems, and embedded and distributed artificial intelligence are empowering Industry 4.0. In this new industrial era, smart autonomous and connected systems will improve efficiency, reduce cost and pollution, and increase productivity and safety in industrial 4.0 based applications. Nevertheless, the new generation technologies mentioned above have not been explored to improve safety in multiplant and industrial zones. In this article, we shed light on the design of unmanned aerial vehicles (UAVs)-assisted systems for emergence response in multiplant and industrial zones. We discuss the important contributions of UAV-mounted cloudlet systems to support SAR missions by providing computation, communication, and storage resources to first responders, surveillance of the affected area, real-time monitoring of SAR members and victims, and caching nodes to improve content delivery among SAR teams. Besides, we design an envisioned UAV-cloudlet reference system for emergency response in industrial areas. Moreover, we highlight the current challenges that are being addressed in the literature aimed at making possible the efficient use of the designed UAV-mounted cloudlet systems for emergency response. Finally, we point out some future research directions that require further investigation. © 2005-2012 IEEE.;
-;-;
Author;Sharma, V., Tripathi, A.K.;
Title;A systematic review of meta-heuristic algorithms in IoT based application;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129486489&doi=10.1016%2fj.array.2022.100164&partnerID=40&md5=5ce779a8d6455f08c3fda65e80ef2a7b;
-;-;
DOI;DOI: 10.1016/j.array.2022.100164;
Abstract;ABSTRACT: Internet-of-Things (IoT) has gained quick popularity with the evolution of technologies such as big data analytics, block-chain, artificial intelligence, machine learning, and deep learning. IoT based systems provides smart and automatic framework for the efficient decision making and automation of various task to make human life easy. Meta-heuristic algorithms are self-organized and decentralized algorithms used for solving complex problems using team intelligence. Recently, meta-heuristic algorithms has been widely used for solving a number of IoT based challenges. This paper presents a systematic review of meta-heuristic algorithms used for unfolding the IoT based applications. The broad classification of existing meta-heuristic based algorithms has been documented. Further, the prominent applications of IoT based system using the meta-heuristic algorithms are presented. Moreover, the current research questions are included to illustrate the new opportunities for the researchers. Finally, the current trends in IoT and possible future directions are documented. This paper will provide new directions to the researchers working in the field of meta-heuristic algorithms and IoT based system. © 2022 The Authors;
-;-;
Author;Nikookar, S., Sakharkar, P., Somasunder, S., Basu Roy, S., Bienkowski, A., MacEsker, M., Pattipati, K.R., Sidoti, D.;
Title;Cooperative Route Planning Framework for Multiple Distributed Assets in Maritime Applications;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132707036&doi=10.1145%2f3514221.3526131&partnerID=40&md5=012d9e738f51ada508f10baf1b2f8b10;
-;-;
DOI;DOI: 10.1145/3514221.3526131;
Abstract;ABSTRACT: This work formalizes the Route Planning Problem (RPP), wherein a set of distributed assets (e.g., ships, submarines, unmanned systems) simultaneously plan routes to optimize a team goal (e.g., find the location of an unknown threat or object in minimum time and/or fuel consumption) while ensuring that the planned routes satisfy certain constraints (e.g., avoiding collisions and obstacles). This problem becomes overwhelmingly complex for multiple distributed assets as the search space grows exponentially to design such plans. The RPP is formalized as a Team Discrete Markov Decision Process (TDMDP) and we propose a Multi-agent Multi-objective Reinforcement Learning (MaMoRL) framework for solving it. We investigate challenges in deploying the solution in real-world settings and study approximation opportunities. We experimentally demonstrate MaMoRL's effectiveness on multiple real-world and synthetic grids, as well as for transfer learning. MaMoRL is deployed for use by the Naval Research Laboratory-Marine Meteorology Division (NRL-MMD), Monterey, CA. © 2022 ACM.;
-;-;
Author;Shaji, K.;
Title;Using ant colony optimization to route a team of UAVs to fires based on known fire intensities;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125659027&doi=10.1145%2f3511430.3511462&partnerID=40&md5=47eb82cc91eecdf420eceac9a20709c2;
-;-;
DOI;DOI: 10.1145/3511430.3511462;
Abstract;ABSTRACT: Increasing in severity due to Climate Change, wildfires will increasingly damage human populations. Autonomous solutions to fighting fires using Unmanned Aerial Vehicles (UAVs) show increasing promise in recent years. In this paper, we apply Ant Colony Optimization to allocate a team of UAVs with known fire extinguisher payloads to fires of known intensities. We evaluate the effectiveness of the algorithm on a dataset based on Washington Department of Natural Resources fire data from 2011-2020. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.;
-;-;
Author;Pransky, J.;
Title;"The Pransky interview: Dr Raffaello D’Andrea, Founder, CEO, and Chairman of the board at Verity; Entrepreneur; Professor; Scientist and Artist";
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122163558&doi=10.1108%2fIR-12-2021-0283&partnerID=40&md5=c8f8ca782f72342ae204ac7d6bf3799a;
-;-;
DOI;DOI: 10.1108/IR-12-2021-0283;
Abstract;"ABSTRACT: Purpose: The following article is a “Q&A interview” conducted by Joanne Pransky of Industrial Robot Journal as a method to impart the combined technological, business and personal experience of a prominent, robotic industry PhD and inventor regarding his pioneering efforts and the commercialization of bringing a technological invention to market. This paper aims to discuss these issues. Design/methodology/approach: The interviewee is Dr Raffaello D’Andrea, a highly successful entrepreneur and proven business leader and one of the world’s foremost leaders in robotics and machine learning. D’Andrea is Founder, CEO and Chairman of the Board at Verity, the world’s leading autonomous indoor drone company, as well as a Professor of Dynamic Systems and Control at the Swiss Federal Institute of Technology (ETH) in Zurich. D’Andrea is also one of the co-founders and advisors of Robo-Global, an index and research company focused on investments in robotics, automation and artificial intelligence. In this interview, D’Andrea shares some of his business and personal experiences of working in industry and academia and his criteria for turning his ideas into successful working systems. Findings: Raffaello D’Andrea’s entire career is built on his ability to bridge theory and practice. D’Andrea combined his love for science with his need to create and received a BS degree in engineering science at the University of Toronto, where he was awarded the Wilson Medal as the top graduating student in 1991. He obtained both his MS and PhD degrees in electrical engineering at Caltech, and then he joined the Cornell faculty as an assistant professor. While on leave from Cornell, from 2003 to 2007, he co-founded the disruptive warehouse automation company Kiva Systems, where he led the systems architecture, robot design, robot navigation and coordination, and control algorithms efforts. In 2014, D’Andrea took robotics technology into the air and founded Verity, the world’s first company to deliver a fully integrated autonomous, indoor drone-based system solution. Originality/value: Raffaello D’Andrea combines academia, business and the arts to reinvent autonomous systems. D’Andrea was a founding member of the Systems Engineering Program at Cornell, where he established robot soccer as the flagship, multidisciplinary team project. In addition to pioneering the use of semi-definite programming for the design of distributed control systems, he went on to lead the Cornell Robot Soccer Team to win four world international RoboCup championships. Kiva Systems, co-founded by D’Andrea and acquired by Amazon in 2012, helped the re-branded Amazon Robotics to disrupt the entire warehousing and logistics systems industry. Additionally, D’Andrea is an internationally-exhibited new media artist, best known for the Robotic Chair (Ars Electronica, ARCO, London Art Fair, National Gallery of Canada) and Flight Assembled Architecture (FRAC Centre). With his team at Verity, he created the drone design and choreography for Cirque Du Soleil’s Paramour on Broadway, Metallica’s WorldWired Tour and Céline Dion’s Courage Tour. Other D’Andrea creations include the Flying Machine Arena, where flying robots perform aerial acrobatics, juggle balls, balance poles and cooperate to build structures; the Distributed Flight Array, a flying platform consisting of multiple autonomous single propeller vehicles that are able to drive, dock with their peers and fly in a coordinated fashion; the Balancing Cube, a dynamic sculpture that can balance on any of its edges or corners and its little brother Cubli, a small cube that can jump up, balance and walk; Blind Juggling Machines that can juggle balls without seeing them, and without catching them. D’Andrea is also collaborating with scientists, engineers, and wingsuit pilots to create an actively controlled suit that will allow humans to take off and land at will, to gain altitude, even to perch, while preserving the intimacy of wingsuit flight. D’Andrea has received the IEEE Robotics and Automation Award, the Engelberger Robotics Award, the IEEE/IFR Invention and Entrepreneurship Award in Robotics and Automation and the Presidential Early Career Award for Scientists and Engineers. In 2020, he was inducted in the National Inventors Hall of Fame and elected to the National Academy of Engineering. © 2021, Emerald Publishing Limited.";
-;-;
Author;Bihl, T.J., Jones, A., Farr, P., Straub, K., Bontempo, B., Jones, F.;
Title;Assessing Multi-Agent Reinforcement Learning Algorithms for Autonomous Sensor Resource Management;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152223262&partnerID=40&md5=f50ec4303c4e62811220f231795f30fc;
-;-;
Abstract;ABSTRACT: Unmanned aerial vehicles (UAVs) have applications in search and rescue operations and such operations could be more efficient by using appropriate artificial intelligence (AI) to enable a UAV agent to operate autonomously. Sensor resource management (SRM), which leverages capabilities across location intelligence, facilitates the efficient and effective use of UAVs and their sensors to complete a set of tasks. Furthermore, multiple UAVs, each with different sensor configurations, must be considered when maximizing mission effects. Instantiating operational autonomy for such teams requires considerable coordination. One AI approach relevant to this task is multi-agent reinforcement learning (MARL). However, MARL has seen limited prior use in SRM. This work evaluates the trade-space of MARL algorithms with respect to performing heterogeneous sensor resource management (SRM) tasks, considers the concept of evaluating MARL in a test and evaluation framework and compares a suit of algorithms with random and Bayesian hyperparameter optimization methods. © 2022 IEEE Computer Society. All rights reserved.;
-;-;
Author;Stedman, H., Kocer, B.B., Kovac, M., Pawar, V.M.;
Title;VRTAB-Map: A Configurable Immersive Teleoperation Framework with Online 3D Reconstruction;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146054144&doi=10.1109%2fISMAR-Adjunct57072.2022.00029&partnerID=40&md5=943d40065d5dc71119438635542a20ae;
-;-;
DOI;DOI: 10.1109/ISMAR-Adjunct57072.2022.00029;
Abstract;ABSTRACT: The availability of consumer virtual reality peripherals has led to a growing interest in developing immersive teleoperation interfaces that feature online 3D environment reconstruction of unknown environments. However, there are many unanswered questions around how such systems are used within deployed teleoperation missions and how operators navigate and explore the 3D data presented to them. We present VRTAB-Map, a configurable immersive teleoperation framework built using the RTAB-Map SLAM library. The framework can be configured with different sensor inputs allowing for it to be used as an experimental baseline for understanding operator behaviours under different teleoperation conditions and offering a methodology for real time immersive analytics in teleoperation missions. We analyse its performance during operation and, building upon our previous work in UAV teleoperation, showcase how it can be integrated in a realised teleoperation system featuring a UAV-UGV team. We then explore opportunities for future work that can be achieved with the presented framework including understanding human factors in teleoperation missions, analysing how variable environment representation effects teleoperation performance, and investigating how immersive interface design complements the operator's mental model of complex environments. © 2022 IEEE.;
-;-;
Author;Herschel, R., Wallrath, P., Hofstaetter, M., Taupe, P., Krueger, E., Philippi, M., Kunze, J., Rotter, J.M., Heusinger, V., Ari, M., Kastner, R., Al-Akrawi, A.;
Title;UAV-borne remote sensing for AI-assisted support of search and rescue missions;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145436526&doi=10.1117%2f12.2636032&partnerID=40&md5=603da2e5a077d6377500f8593c878295;
-;-;
DOI;DOI: 10.1117/12.2636032;
Abstract;ABSTRACT: In search and rescue (SAR) missions every minute counts. Semi-collapsed buildings are among the difficult scenarios encountered by search and rescue teams. An UAV-based exploration system can provide crucial information on the accessibility of different sectors, hazards, and injured people. The research project “UAV-Rescue” aims to provide UAV-borne sensing and investigate the use of AI to support this powerful tool. The sensor suite contains a radar sensor for detecting people based on breath and pulse movement. A neural network interprets the extracted data to identify signs of human life and as such persons that need rescuing. We also fuse radar and lidar data to explore the environment of the UAV and obtain a robust basis for simultaneous localization and mapping even under restricted visibility conditions. Additionally, we plan to use AI to support the path planning of the drone taking the digital map as input. Furthermore, AI is leveraged to map intact and damaged building structures. Potentially hazardous gases common to urban settings are tracked. We fuse the acquired information into a model of the explored area with marked locations of potential hazards and people to be rescued. The project also addresses ethical and societal issues raised by the use of UAVs close to people as well as AI supported decision making. The talk will present the system concept including interfaces and sensor fusion approaches. We will show first results of a research project from static and dynamic measurement campaigns demonstrating the capability of radar and lidar based sensing in a complex urban environment. © 2022 SPIE.;
-;-;
Author;Kaliardos, W.N.;
Title;Enough Fluff: Returning to Meaningful Perspectives on Automation;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141938497&doi=10.1109%2fDASC55683.2022.9925804&partnerID=40&md5=540fdde197e69bdc5b4c4b8591b47f2b;
-;-;
DOI;DOI: 10.1109/DASC55683.2022.9925804;
Abstract;"ABSTRACT: As society progresses towards increased automation in aviation - such as with Advanced Air Mobility and Unmanned Aircraft Systems - it is important to have a common understanding and perspective about automation among the many stakeholders, including aviation system designers, operators, maintainers, and regulatory authorities. Unfortunately, the discourse is hindered by misleading perspectives, assumptions, claims, and terminology.There are many examples. The term ""automation""can be simply defined, but it is often confounded with ""autonomous""and other descriptions of the function being automated, and further confounded by our subjective opinions on which functions are considered ""advanced""or ""intelligent"". Automation is often discussed not as a tool that can be leveraged to achieve goals of the aviation community, but rather as a technocentric goal in itself. We often refer to automation as ""an AI""(artificial intelligence) or a ""team member"", or other ways in which we anthropomorphize machines, yet do not clearly define functions for automated components of these desired systems. We argue that humans are prone to errors and that more automation therefore means fewer errors, without a fair balance that considers humans as valuable functional elements. We talk about operator trust as if the idea is unique to AI, when in fact the basic principles for human-automation interaction have not changed. We try to treat automation as a one-dimensional variable, such as with automation levels, but this hides important detail and has limited value in applications such as design, operations, and approvals of complex human-automation systems.This paper identifies issues in recent automation and human-automation discourse, and provides clarifications and recommendations to improve progress towards the integration of increased automation in aviation systems. © 2022 IEEE.";
-;-;
Author;Ryan, R., Al-Rubaye, S., Braithwaite, G.;
Title;UTM Regulatory Concerns with Machine Learning and Artificial Intelligence;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141935924&doi=10.1109%2fDASC55683.2022.9925869&partnerID=40&md5=bf7272612e8f59746432836c4145a2b6;
-;-;
DOI;DOI: 10.1109/DASC55683.2022.9925869;
Abstract;ABSTRACT: Artificial intelligence (AI) and machine learning will have a significant impact on the application of drones and the integration of universal/unmanned traffic management (UTM) that relate to unmanned operations in urban environments at very low-level airspace. Artificial intelligence will necessitate high levels of automation and act as an enabler with respect to the integration of unmanned and manned aviation and will ultimately enable safe operations with respect to high numbers of drones utilising the same airspace, and more specifically with respect to detect and avoid capability. AI is going to be heavily developed and utilised by organisations that certify as U-space service providers (USSP's) when providing a service to Unmanned Aerial Systems (UAS) Operators. The equipment utilised by UAS Operators will to some extent already benefit from AI, but the level of automation is currently constrained by regulation. A legal framework must exist, as AI will not only have a significant impact upon existing laws but will ensure a framework that facilitates safety and the fundamental rights of citizens and businesses with respect to AI. The EU has published a proposed law, namely the Artificial Intelligence Act as permitted under Article 114 of the Treaty on the Functioning of the European Union (TFEU). © 2022 IEEE.;
-;-;
Author;Chang, R.C.-H., Hwang, Y.-T., Lin, Y.-P., Yang, C.-H.;
Title;CAS Research and Teaching Activities in Taiwan [CAS in the World];
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138780153&doi=10.1109%2fMCAS.2022.3189897&partnerID=40&md5=62f548e641995e9c49dc8eb061011ab6;
-;-;
DOI;DOI: 10.1109/MCAS.2022.3189897;
Abstract;ABSTRACT: The Ministry of Science of Technology (MOST) of Taiwan launched a multi-year, US$132 million, nationwide Semiconductor Moonshot Project in 2018. The goal of the Semiconductor Moonshot Project is to challenge the key technology limits of AI edge, embrace the growth era of AI, cultivate AI talents, and create new value for Taiwan. The project includes six areas: 1) Innovative Sensing Devices, Circuits, and Systems, 2) Next-Generation Memory Design, 3) Cognitive Computing and AI Chips, 4) IoT System and Security for Intelligent Edge, 5) Component, Circuit, and System Designs for Unmanned Vehicle System and AR/VR Application, and 6) Emerging Semiconductor Processes, Materials, and Device Technology. In the first phase, 20 teams from major universities in Taiwan were funded. There are about 1950 M.S. & Ph.D. students involved. Up to now, the project has generated more than 1300 high-level academic papers, 6 start-ups, and 47 technology transfers to enterprises. The Taiwan Semiconductor Research Institute (TSRI) facilitates device fabrication and provides design platforms for chip implementation. © 2001-2012 IEEE.;
-;-;
Author;Pastra, A., Schauffel, N., Ellwart, T., Johansson, T.;
Title;Building a trust ecosystem for remote inspection technologies in ship hull inspections;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136840794&doi=10.1080%2f17579961.2022.2113666&partnerID=40&md5=9808068d75b3effe0c9422d681d1efdd;
-;-;
DOI;DOI: 10.1080/17579961.2022.2113666;
Abstract;ABSTRACT: The article contributes to the discussion concerning the role of trust in robotic and autonomous systems (RAS), with a sharp focus on remote inspection technologies (RITs) for vessel inspection, survey and maintenance. To this end, the article provides a first-hand insight into one of the major findings from BUGWRIGHT2—a collaborative project co-funded by the European Union’s Horizon 2020 Research and Innovation programme that aims to change the European vessel-structure maintenance landscape. In doing so, this article explores trust from a psychological perspective, reflecting on its characteristics and predictors, followed by a discussion on the AI-trust ecosystem as envisaged by the European Commission. Structured interviews with thirty-three subject matter experts guide the main analysis revealing that trust is an essential precondition for integrating RITs into the current manual-driven inspection system. A synoptic overview of the vital trust elements is provided before carving out the ways forward for developing a trustworthy environment governed by Human-Robot Interaction. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.;
-;-;
Author;Bapty, T., Whittington, S., Walker, J., Hite, J., Swenson, B., Owens, K., Eisele, F., Scott, J., Owens, R.;
Title;Design Oracle for AI-Based CPS Design;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134349794&doi=10.1109%2fDESTION56136.2022.00009&partnerID=40&md5=91ebd6794e366f0ed63c3db662fa301e;
-;-;
DOI;DOI: 10.1109/DESTION56136.2022.00009;
Abstract;ABSTRACT: Automated design processes, especially using Machine Learning/AI techniques, require proposed systems to be evaluated across all relevant attributes, requirements, and concerns. Traditionally, teams create models in a set of engineering tools for design evaluation data. We describe a Design Oracle, where automated designers can submit a system as a graph of components and request a full range of evaluations, composing analysis workflows containing multiple engineering tools across multiple physical domains, fidelity, and scenarios. Manually created system models are not required. The system works across cloud architectures, supporting the use of parallel computation.The system leverages technology developed under the DARPA Adaptive Vehicle Make/META program, which created a uniform, multi-domain design and component representation, and tools for composition to engineering tool models across multiple tool types, domains, and fidelity levels [1]. The Design Oracle has been used within the DARPA Symbiotic Design for Cyber-Physical Systems, across two classes of target designs, Unmanned Air Vehicles and Unmanned Underwater Vehicles. © 2022 IEEE.;
-;-;
Author;Cheng, C.-S., Behzadan, A.H., Noshadravan, A.;
Title;Uncertainty-aware convolutional neural network for explainable artificial intelligence-assisted disaster damage assessment;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131659946&doi=10.1002%2fstc.3019&partnerID=40&md5=209ffc1a5d21270078d441a65a773ce8;
-;-;
DOI;DOI: 10.1002/stc.3019;
Abstract;ABSTRACT: Accurate damage assessment is a critical step in post-disaster risk assessment, mitigation, and recovery. Current practices performed by experts and reconnaissance teams in the form of field evaluation require considerable time and resources. Recent advances in remote sensing imagery, artificial intelligence (AI), and computer vision have enhanced automated and rapid disaster damage assessment. Recent literature has shown promising progress in AI-assisted aerial damage assessment. However, accounting for the uncertainty in the outcome for improved quantification of confidence and enhanced model explainability for human decision-makers remains one of the key challenges. Overlooking uncertainty can lead to erroneous decisions, especially in highly-consequential tasks such as damage assessment. The aim of this study is to develop uncertainty-aware deep learning models for the assessment of post-disaster damage using aerial imaging. Within the framework of variational Bayesian inference, Monte Carlo dropout sampling technique is used to propagate epistemic uncertainty in model predictions. With this stochastic setting, the model produces damage prediction labels with softmax as random variables, which helps quantify confidence in the model outcome using appropriate measures of uncertainty. Two networks are implemented and trained separately on two different disaster damage datasets consisting of unmanned aerial vehicle building footage as well as satellite-captured post-disaster imagery. The first network attains 59.4% accuracy in building classification, and the second network gives an accuracy of 55.1%. Results from uncertainty analysis, model confidence quantification, and analyzing model attention zone can lead to more explainable and risk-informed automated damage assessment outcomes using AI technology. © 2022 John Wiley & Sons Ltd.;
-;-;
Author;Nohel, J., Stodola, P., Flasar, Z., Rybanský, M.;
Title;Multiple maneuver model of cooperating ground combat troops;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125142278&doi=10.1177%2f15485129221078939&partnerID=40&md5=b8d06d0928da6bf7e85e8daa45efde46;
-;-;
DOI;DOI: 10.1177/15485129221078939;
Abstract;ABSTRACT: The article describes the possibilities of using the Maneuver Control System CZ (MCS CZ) in creating a multiple maneuver of a group of cooperating units. It is a tactical information system designed to support the decision-making of commanders in order to effectively deploy their units on the battlefield. The system evaluates the geographical and hydrometeorological battlefield influences as well as the enemy’s situation to calculate the maneuver axes of a unit composed of up to three teams with the same goal. To verify the calculations of mathematical-algorithmic models of the system, two measurements were performed on model situations. In the first of them, a group of three unmanned systems carried out an attack on an identified delivery system of weapons of mass destruction. The second model situation included a hasty attack by three infantry squads on anti-aircraft equipment. In both cases, the resulting group of maneuvers used the fastest and safe axes of advance, spatially synchronized according to tactical principles. In both cases, the enemy’s weapon systems were quickly attacked and destroyed immediately after their identification from three directions. The commander’s decision-making process was largely replaced by the MCS CZ calculations in model situations, which significantly shortened its duration. © The Author(s) 2022.;
-;-;
Author;Maier, S., Schulte, A.;
Title;A cloud-based approach for synchronous multi-pilot multi-UAV mission plan generation in a MUM-T environment;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123887493&doi=10.2514%2f6.2022-2345&partnerID=40&md5=c55fac5661b03f464002fee023297df7;
-;-;
DOI;DOI: 10.2514/6.2022-2345;
Abstract;ABSTRACT: In this article, we present a new concept that allows multiple human users to cooperatively and simultaneously create a mission plan for multiple unmanned systems equally available to all users assisted by a cognitive agent. With this, we aim to reduce both the workload of individual users and the error rate in mission planning. In addition, we expect an increase in battlefield awareness and improved coordination during mission execution. In military air operations, which are currently exclusively manned, there is a strict separation between the specific mission-related tasks allocated to each team. In a Manned-Unmanned-Teaming (MUM-T) environment, some manned assets are replaced by unmanned aerial vehicles (UAVs). In these setups, one of the tasks of the human user is to plan and monitor the mission. In this context our approach uses a cognitive agent that acts as a centralized planning instance. All tasks that the human users want the UAVs to perform are delegated to the agent, which schedules the individual tasks in a feasible order. It must also merge and deconflict the various plans created by individual pilots into an executable joint mission plan. In addition, the agent creates its own logical plan with the mission flow and can use it to suggest plan changes to human users or execute them directly itself. We have finalized the concept containing the corresponding workflows, procedures, deconflicting, and logical planning capabilities of the central agent. We demonstrate the implementation of the concept using our fully functional MUM-T fighter simulator. Currently, the implementation includes the agent's capabilities to (1) allow multiple pilots to simultaneously delegate tasks for the same available UAVs, (2) detect conflicts that arise during mission plan generation, (3) assist pilots in conflict resolution, (4) associated visualizations, and (5) create a logical plan that will be used to check if the mission plan meets the conditions to achieve the main objective. © 2022, American Institute of Aeronautics and Astronautics Inc.. All rights reserved.;
-;-;
Author;İşci, H., Koyuncu, E.;
Title;Reinforcement Learning Based Autonomous Air Combat with Energy Budgets;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123404598&doi=10.2514%2f6.2022-0786&partnerID=40&md5=ba9d443a927b56c288185148360dfa40;
-;-;
DOI;DOI: 10.2514/6.2022-0786;
Abstract;ABSTRACT: Fighter pilots may become commanders in the air in the future. Modern jet fighter aircraft have different capabilities to command the field by using various equipment. Additionally, manned and unmanned teams can be composed to increase air dominance since the human capacity is limited for long flight times for missions. When this happens, the pilots can command their unmanned wing-mans during the mission. To reach these kinds of scenarios, more tasks need to be realized autonomously to dominate the airfield with the hybrid unmanned fleet. Air combat is one of the most important and challenging tasks for fighter pilots. Due to the complexity of the problem, most of the time the air combat missions need to be realized by human pilots due to the lack of unmanned aircraft's capability. Increasing the autonomy level for this specific problem may be beneficial for armies. Therefore, the air combat mission is mostly studied for many years to solve the problem from several approaches, either pilot assistance systems or fully autonomous missions. Additionally, strong improvements in both computer technology and artificial intelligence have been experienced. The number of problems that have been solved by using artificial networks is also increasing. It is thought that similar approaches can be used to solve an autonomous air combat problem. This article aims to develop an agent that will preserve the specific energy of the aircraft while being successful in air combat missions using artificial intelligence methods. Three different agents with different reinforcement learning-based algorithms (DDPG, SAC, and PPO) are studied for the task. The agents have trained to succeed in the air combat mission in custom-generated simulation infrastructure. The novel training process is explained in detail. The performances of the agents have been assessed with the simulations performed in different scenarios. The results have shown the effectiveness of the algorithms. © 2022, American Institute of Aeronautics and Astronautics Inc. All rights reserved.;
-;-;
Author;Demir, M., McNeese, N.J., Gorman, J.C., Cooke, N.J., Myers, C.W., Grimm, D.A.;
Title;Exploration of Teammate Trust and Interaction Dynamics in Human-Autonomy Teaming;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116065184&doi=10.1109%2fTHMS.2021.3115058&partnerID=40&md5=9756de4040a784f1c3644b06ca83fe99;
-;-;
DOI;DOI: 10.1109/THMS.2021.3115058;
Abstract;"ABSTRACT: This article considers human-autonomy teams (HATs) in which two human team members interact and collaborate with an autonomous teammate to achieve a common task while dealing with unexpected technological failures that were imposed either in automation or autonomy. A Wizard of Oz methodology is used to simulate the autonomous teammate. One of the critical aspects of HAT performance is the trust that develops over time as team members interact with each other in a dynamic task environment. For this reason, it is important to examine the dynamic nature of teammate trust through real-time measures of team interactions. This article examines team interaction and trust to understand better how they change under automation and autonomy failures. Thus, we address two research questions: 1) How does trust in HATs evolve over time?; and 2) How is the relationship between team interaction and trust impacted by the failures? We hypothesize that trust in HATs will decrease as autonomy failures increase. We also hypothesize that team interaction would be related to the development of trust and recovery from the failures. The results implicate three general trends: 1) team interaction dynamics are linked to the development of trust in HATs; 2) trust in the autonomous teammate is only associated with recovery from autonomy failures; 3) team interaction dynamics are related to both automation and autonomy failure recovery. © 2013 IEEE.";
-;-;
Author;Cohen, M.C., Demir, M., Chiou, E.K., Cooke, N.J.;
Title;The Dynamics of Trust and Verbal Anthropomorphism in Human-Autonomy Teaming;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118953698&doi=10.1109%2fICHMS53169.2021.9582655&partnerID=40&md5=7c9751b3140ba5417836a1e5cbb67783;
-;-;
DOI;DOI: 10.1109/ICHMS53169.2021.9582655;
Abstract;ABSTRACT: Trust in autonomous teammates has been shown to be a key factor in human-autonomy team (HAT) performance, and anthropomorphism is a closely related construct that is underexplored in HAT literature. This study investigates whether perceived anthropomorphism can be measured from team communication behaviors in a simulated remotely piloted aircraft system task environment, in which two humans in unique roles were asked to team with a synthetic (i.e., autonomous) pilot agent. We compared verbal and self-reported measures of anthropomorphism with team error handling performance and trust in the synthetic pilot. Results for this study show that trends in verbal anthropomorphism follow the same patterns expected from self-reported measures of anthropomorphism, with respect to fluctuations in trust resulting from autonomy failures. © 2021 IEEE.;
-;-;
Author;Abdel-Basset, M., Chang, V., Nabeeh, N.A.;
Title;An intelligent framework using disruptive technologies for COVID-19 analysis;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094946054&doi=10.1016%2fj.techfore.2020.120431&partnerID=40&md5=42124a35ab58da26ed4c784d21fbd701;
-;-;
DOI;DOI: 10.1016/j.techfore.2020.120431;
Abstract;ABSTRACT: This paper describes a framework using disruptive technologies for COVID-19 analysis. Disruptive technologies include high-tech and emerging technologies such as AI, industry 4.0, IoT, Internet of Medical Things (IoMT), big data, virtual reality (VR), Drone technology, and Autonomous Robots, 5 G, and blockchain to offer digital transformation, research and development and service delivery. Disruptive technologies are essential for Industry 4.0 development, which can be applied to many disciplines. In this paper, we present a framework that uses disruptive technologies for COVID-19 analysis. The proposed framework restricts the spread of COVID-19 outbreaks, ensures the safety of the healthcare teams and maintains patients' physical and psychological healthcare conditions. The framework is designed to deal with the severe shortage of PPE for the medical team, reduce the massive pressure on hospitals, and track recovered patients to treat COVID-19 patients with plasma. The study provides oversight for governments on how to adopt technologies to reduce the impact of unprecedented outbreaks for COVID-19. Our work illustrates an empirical case study on the analysis of real COVID-19 patients and shows the importance of the proposed intelligent framework to limit the current outbreaks for COVID-19. The aim is to help the healthcare team make rapid decisions to treat COVID-19 patients in hospitals, home quarantine, or identifying and treating patients with typical cold or flu. © 2020;
-;-;
Author;Cattani, B.M., Mura, J.M., Ogalde, S., Pouwels, C., Smith, D.J.K., Cardinaux, C., Heemskerk, M., Rovers, S.P., Verma, M.K., Wahidi, M.;
Title;ROBOT-HUMAN EXPLORATION AND INTERFACES DURING THE CHILL-ICE ANALOGUE LUNAR MISSION CAMPAIGN;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127561071&partnerID=40&md5=3d9e09935267abb52ce0b45d41e5f57a;
-;-;
Abstract;ABSTRACT: The CHILL-ICE (Construction of a Habitat Inside a Lunar-analog Lava tube - Iceland Campaign of EuroMoonMars) is a series of analog missions conducted by students and young professionals in Iceland. The first edition took place in August 2021 and consists of two short analog astronaut missions of 48 hours each. The missions focuses on the construction of a small habitat designed and prototyped by students from the Wilson School of Design from Kwantlen Polytechnic University, built inside a subterranean lava tube in the Hallmundarhraun lava field, which is highly similar to those present on the Moon. Prior to the mission, the three-person astronaut crews receive training in geology, systems engineering, emergency rescue and first-aid, as well as psychological assessments and team-building exercises, from a range of CHILL-ICE staff and partners. To ensure a high-fidelity simulation of an actual lunar mission, no communication with Mission Control is possible until successful deployment of the habitat and communication systems, which has an 8-hour time limit to simulate realistic oxygen supplies. During this time the astronauts will be wearing field-tested analog astronaut suits from the Astroland Interplanetary Agency. Upon setting up the habitat, as well as the power and communication systems, the analog astronauts will explore the surrounding lava tube system during research Extra-Vehicular Activities (EVAs). Lunar Zebro, a student-led robotics team from TU Delft and a partner of CHILL-ICE, has developed a rover for use in the CHILL-ICE missions. Zebro is a six-legged rover with a novel type of locomotion, suitable for exploring the rocky lunar surface. This prototype will assess whether swarms of these rovers could explore lunar lava tubes in the future, mapping the interior to determine the feasibility for human access and assessing the effectiveness of robotic lava tube exploration versus human exploration. Similarly, data will also be captured during the mission to test a prototype machine, a learning detection model known as SpotNet. This model is trained on video and image data of the analog astronauts, with the goal of autonomously detecting an astronaut within camera footage. The model achieves accurate detection of the astronauts, and could be used in future missions as an embedded monitoring system in helmet cameras or habitat surveillance cameras. In parallel to the mission, a system engineering design study has been performed on a cable rope system for accessing the lava tubes. The study showed the system could be developed into a feasible prototype for future analog missions involving lava tubes. Furthermore, CHILL-ICE showed an impact on the Icelandic space sector, fostering international collaboration from over 16 nations and a range of public and commercial bodies to work together in undertaking a lunar simulation mission. CHILL-ICE hopes to extend this campaign, expanding future missions to enhance existing robotics experiments and to include activities such as astrobiological research. Copyright © 2021 by the International Astronautical Federation (IAF). All rights reserved.;
-;-;
Author;Rizk, M., Slim, F., Charara, J.;
Title;Toward AI-Assisted UAV for Human Detection in Search and Rescue Missions;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125774350&doi=10.1109%2fDASA53625.2021.9682412&partnerID=40&md5=3f5383d255a9ee1f86ed051bf3467e4e;
-;-;
DOI;DOI: 10.1109/DASA53625.2021.9682412;
Abstract;ABSTRACT: Search and rescue missions during and after disasters require all efforts and high financial expenses. Rapid locating of wounded and lost individuals contributes in directing the rescuers and medical teams. This may increase the probability of saving human lives and plays a significant role in reducing expenses. Currently, the use of unmanned aerial vehicles (UAVs) or drones for remote surveillance and reconnaissance is becoming increasingly popular. On the other hand, emergent artificial intelligence (AI) algorithms based on convolution neural networks (CNN) reveal the ability of real-time detection. Combining the high-performance detection and classification capabilities provided by emergent AI techniques with the exploratory abilities of UAVs allows the UAVs to process the captured sequence of images and report back results in real-time. The evolution of AI-assisted UAVs enables the detection of wounded and trapped persons while flying and allows proper and fast transfer of information to ground stations to lead the rescuers and medical teams to victims' locations. In this paper, we explore augmenting UAVs with processing units executing emergent AI-based detectors. The proposed system can detect humans in real time and send the corresponding coordinates to the ground station. © 2021 IEEE.;
-;-;
Author;Rune, S., Valaker, S.;
Title;Mixed-initiative approaches in the Design of a trusted shift of Coordination Forms in Air Operations: Supporting Collaboration to handle Loyal Wingmen;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123956023&doi=10.1109%2fCACS52606.2021.9638711&partnerID=40&md5=64860b9a9bf5e88ab976cf9e450d11b8;
-;-;
DOI;DOI: 10.1109/CACS52606.2021.9638711;
Abstract;ABSTRACT: Man-unmanned concepts, such as loyal wingman, have the potential to be important force-multiplications. However, man-unmanned teaming may require changes to command and control (C2) in general (e.g. the control with unmanned entities in the context of joint operations) and more detailed TTPs for AirC2 (such as procedures for the interaction between fighter pilots and unmanned entities). Two of the challenges is to achieve 1) trusted delegation to unmanned entities and 2) coordinated action among man and unmanned entities. This paper aim to establish a sound concept development trajectory. The trajectory will consist of oscillating between conceptual development, and empirical investigations feeding back to the conceptual development. We draw on the extant research on man-unmanned problems in cybernetics, human factors (human-in-the-loop) and organization science. Using these lines of inquiry, we develop models for describing and analyzing the man-unmanned problem in general, in order to: 1) Understand man-unmanned teaming in the context of a proposed Norwegian loyal wingman concept (e.g. mixed-initiative, coactive design) 2) Understand loyal wingman in a wider context of C2. (e.g. system-dynamic perspectives) 3) Paying attention to and discussing 1 and 2 in light of the breadth of potential loyal wingman configurations (e.g. along dimensions such as size, range, speed, payload, sensors, effectors, autonomy and artificial intelligence capability, in a long and short term perspective etc.) While we do not describe the specifics of 1, 2 and 3 we discuss generically the variables and principles/theories to consider with respect to 1, 2 and 3. This conceptual development will then form the basis for empirical investigations, such as aided by tabletop discussion workshops, and data collection from simulated and live environments. © 2021 IEEE;
-;-;
Author;Zhang, J., Zhou, W., Xu, Y., Huang, X., Liu, S., Lu, Y., Su, Y., Li, F., Zhan, Y., Huang, J.;
Title;Unattended AI Inspection Collaborative Management Platform;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116883846&doi=10.1007%2f978-981-16-3391-1_37&partnerID=40&md5=e219020e7bbd6254ebf6fd3f5de12464;
-;-;
DOI;DOI: 10.1007/978-981-16-3391-1_37;
Abstract;ABSTRACT: With the widespread application and rapid development of unmanned aerial vehicle (UAVs), the use of UAVs for inspection operations will become a hot spot in order to satisfy the operation and management of UAV resources by inspectors. Taking the inspection in the field of public safety as an example, this article has developed an unattended AI inspection platform with eight functions including real-time monitoring, AI monitoring, AI early warning, data statistics, route planning, task management, equipment management, and team management. Obtain drone location, status information, and monitoring pictures, make full use and visualization of the data collected by drones, and strengthen the deployment of drone resources and the efficiency of public safety inspections. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.;
-;-;
Author;Rasmussen, S., Manyam, S.G., Casbeer, D.;
Title;Swarming artificial intelligence for networked teams (Saint);
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100421464&partnerID=40&md5=a05b9c4d18da4d73b547aa80ea474b33;
-;-;
Abstract;ABSTRACT: The Swarming Artificial Intelligence for Networked Teams (SAINT) architecture was designed in order to develop and flight test cooperative teams of autonomous Unmanned Aerial Vehicles (UAV)s. This paper details research background motivating SAINT, explains the architecture, and then presents development and flight test of a system that performs an autonomous, cooperative system that can be used to detect the strength of an adversaries’ forces. © 2021, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.;
-;-;
Author;Lu, Y., Chen, Q., Jia, G., Guo, Z.;
Title;Development and experiment of elastic-rope launcher for small fixed-wing UAVs;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105407668&doi=10.1109%2fWCMEIM52463.2020.00142&partnerID=40&md5=0e57c849051327ae6fe146debf46b2a0;
-;-;
DOI;DOI: 10.1109/WCMEIM52463.2020.00142;
Abstract;ABSTRACT: Small and medium-sized fixed-wing UAVs have a lower cost compared to large UAVs. Small and medium-sized tactical UAVs have become increasingly prominent, according to the development of intelligence and miniaturization of sensors and weapons, and the new tactics application including teams, swarm, and loyalty wingmen, which is based on artificial intelligence and network communications. Short-range reliable take-off technology is a major problem for small and medium-sized fixed-wing UAVs to achieve all-terrain applications on vehicle-borne and ship-borne. Elastic-rope launcher is available for small and medium sized fixed wing UAVs, with the advantages of brief structure, convenient operation and strong adaptability to environment. This article systematically reviews the development and characteristics of catapult-based UAV take-off technology. The design method of the elastic-rope launcher method is present, including the catapult distance estimation based on the maximum overload constraints and takeoff speed requirement, determination of the initial length of elastic rope according to the launcher geometric configuration and deformation ratio constrains, and the parameters calculation with energy conservation principle. An example UAV launcher is designed and experimental verification is taken. Work in this paper could be in favor of the development of short-range take-off technology for small and medium-sized UAV. © 2020 IEEE.;
-;-;
Author;Vamvoudakis, K.G., Kokolakis, N.-M.T.;
Title;Synchronous reinforcement learning-based control for cognitive autonomy;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096305042&doi=10.1561%2f2600000022&partnerID=40&md5=b73c07a11957aad3ecc4aa124a328911;
-;-;
DOI;DOI: 10.1561/2600000022;
Abstract;ABSTRACT: This monograph provides an exposition of recently developed reinforcement learning-based techniques for decision and control in human-engineered cognitive systems. The developed methods learn the solution to optimal control, zero-sum, non zero-sum, and graphical game problems completely online by using measured data along the system trajectories and have proved stability, optimality, and robustness. It is true that games have been shown to be important in robust control for disturbance rejection, and in coordinating activities among multiple agents in networked teams. We also consider cases with intermittent (an analogous to triggered control) instead of continuous learning and apply those techniques for optimal regulation and optimal tracking. We also introduce a bounded rational model to quantify the cognitive skills of a reinforcement learning agent. In order to do that, we leverage ideas from behavioral psychology to formulate differential games where the interacting learning agents have different intelligence skills, and we introduce an iterative method of optimal responses that determine the policy of an agent in adversarial environments. Finally, we present applications of reinforcement learning to motion planning and collaborative target tracking of bounded rational unmanned aerial vehicles. © 2020 American Institute of Physics Inc.. All rights reserved.;
-;-;
Author;ZHAO, Z., NIU, Y., SHEN, L.;
Title;Adaptive level of autonomy for human-UAVs collaborative surveillance using situated fuzzy cognitive maps;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089422990&doi=10.1016%2fj.cja.2020.03.031&partnerID=40&md5=3ddf0373ef3bb4f7fdb5ca1f89198842;
-;-;
DOI;DOI: 10.1016/j.cja.2020.03.031;
Abstract;ABSTRACT: Collaborating with a squad of Unmanned Aerial Vehicles (UAVs) is challenging for a human operator in a cooperative surveillance task. In this paper, we propose a cognitive model that can dynamically adjust the Levels of Autonomy (LOA) of the human-UAVs team according to the changes in task complexity and human cognitive states. Specifically, we use the Situated Fuzzy Cognitive Map (SiFCM) to model the relations among tasks, situations, human states and LOA. A recurrent structure has been used to learn the strategy of adjusting the LOA, while the collaboration task is separated into a perception routine and a control routine. Experiment results have shown that the workload of the human operator is well balanced with the task efficiency. © 2020 Chinese Society of Aeronautics and Astronautics;
-;-;
Author;Andrews, J.M., Rusnock, C.F., Miller, M.E., Meador, D.P.;
Title;Simulation-Based Evaluation of the Effects of Varying Degrees of Control Abstraction for Manned-Unmanned Teaming on Mental Workload of Pilots;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098893415&doi=10.1109%2fSMC42975.2020.9283167&partnerID=40&md5=56673d74aaf6413ef7704a4a447934f3;
-;-;
DOI;DOI: 10.1109/SMC42975.2020.9283167;
Abstract;ABSTRACT: The future of air combat is expected to evolve significantly to include new technologies and novel concepts of operation. The Manned-Unmanned Teaming concept involves low cost, attritable Unmanned Aerial Vehicles (UAVs) that could be deployed along with a manned aircraft. The UAVs act as a complementary asset and bolster offensive air operations. Given the complexity of future operating environments, the degree of autonomous control required for pilots to concurrently operate multiple UA Vs and their own aircraft is one area of concern. To determine the amount of autonomous control abstraction that has the largest impact in reducing operator workload and increasing system performance, a predictive workload model was developed using the Improved Performance Research Integration Tool (IMPRINT). This research concluded that maned-unmanned teams can increase mission performance and maintain the pilot's cognitive workload at a manageable level by utilizing higher levels of human control abstraction, where unmanned systems have greater degree of autonomy. © 2020 IEEE.;
-;-;
Author;Agrawal, A., Cleland-Huang, J., Steghofer, J.-P.;
Title;Model-Driven Requirements for Humans-on-The-Loop Multi-UAV Missions;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097308620&doi=10.1109%2fMoDRE51215.2020.00007&partnerID=40&md5=9d2bb1e9985c0e4b3cde6c6b4012e75f;
-;-;
DOI;DOI: 10.1109/MoDRE51215.2020.00007;
Abstract;ABSTRACT: The use of semi-Autonomous Unmanned Aerial Vehicles (UAVs or drones) to support emergency response scenarios, such as fire surveillance and search-And-rescue, has the potential for huge societal benefits. Onboard sensors and artificial intelligence (AI) allow these UAVs to operate autonomously in the environment. However, human intelligence and domain expertise are crucial in planning and guiding UAVs to accomplish the mission. Therefore, humans and multiple UAVs need to collaborate as a team to conduct a time-critical mission successfully. We propose a meta-model to describe interactions among the human operators and the autonomous swarm of UAVs. The meta-model also provides a language to describe the roles of UAVs and humans and the autonomous decisions. We complement the meta-model with a template of requirements elicitation questions to derive models for specific missions. We also identify common scenarios where humans should collaborate with UAVs to augment the autonomy of the UAVs. We introduce the meta-model and the requirements elicitation process with examples drawn from a search-And-rescue mission in which multiple UAVs collaborate with humans to respond to the emergency. We then apply it to a second scenario in which UAVs support first responders in fighting a structural fire. Our results show that the meta-model and the template of questions support the modeling of the human-on-The-loop human interactions for these complex missions, suggesting that it is a useful tool for modeling the human-on-The-loop interactions for multi-UAVs missions. © 2020 IEEE.;
-;-;
Author;Kung, C.-M., Yang, W.-S., Wei, T.-Y., Chao, S.-T.;
Title;The fast flight trajectory verification algorithm for Drone Dance System;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091989091&doi=10.1109%2fIAICT50021.2020.9172016&partnerID=40&md5=601439586369546e9172775f3f27d484;
-;-;
DOI;DOI: 10.1109/IAICT50021.2020.9172016;
Abstract;ABSTRACT: Drone swarms are teams of autonomous unmanned aerial vehicles that act as a collective entity. We are interested in humanizing drone swarms, equip-ping them with the ability to emotionally affect human users through their nonverbal motions. We address a fundamental issue of collective motion of aerial robots: how to ensure that large flocks of autonomous drones seamlessly navigate in confined spaces. In this paper, we propose a fast flight trajectory verification algorithm and instant autonomous flight control alarm system, such a flocking model for real drones incorporating an evolutionary optimization framework with carefully chosen order parameters and fitness functions. We numerically demonstrated that the induced swarm behavior remained stable under realistic conditions for large flock sizes and notably for large velocities. We showed that coherent and realistic collective motion patterns persisted even around perturbing obstacles. Furthermore, we validated our model on real hardware, carrying out field experiments with a self-organized swarm of 20 drones. The results confirmed the adequacy of our approach. Successfully controlling dozens of quadcopters will enable substantially more efficient task management in various contexts involving drones. © 2020 IEEE.;
-;-;
Author;O'Riordan-Adjah, C.A.;
Title;Self - Initiative undergraduate research;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095781016&partnerID=40&md5=e4776cde3ae1a15fba97c061cc6f8cdf;
-;-;
Abstract;"ABSTRACT: This paper describes an undergraduate research project conducted at a liberal arts institution during the summer of 2019. The undertaking was distinctive in that it was an engineering project conducted at a liberal arts college by undergraduate students enrolled in the college's engineering program. A multidisciplinary research team was assembled, composed of students majoring in civil, chemical and mechanical engineering. It should be emphasized that this seven-week program was designed to serve primarily as a learning experience for the student researchers. The goals were: (1) to engage undergraduate students in the self-initiative research process; (2) to demonstrate how what they are studying and learning can be put to practical use; and (3) to teach the students the value of their chosen field and how it benefits society. It should be further emphasized that the 'nuts and bolts' specifics of the project, though important, were not the primary objective; learning the value of teamwork, prioritization, time management and communication was. In picking a research topic, the students were asked to identify areas where unmanned aerial vehicles (drones) have been underused or totally unexploited, and to select one for further detailed analysis. Unlike typical research projects, where the potential areas of research and the main topic are preselected by the research instructor, this project allowed the student researchers to make those decisions. Several drone usage areas were identified, including: wildlife analysis, package delivery, athletic analysis, mosquito spraying, and areas in which artificial intelligence (AI) is used to enhance information gathering, such as security surveillance, storm tracking, and wildlife poaching activity. After a thorough review of these uses, mosquito spraying was selected as the focus topic. The decision was based on feasibility, time constraints (just seven weeks to complete the project), budget constraints, and capabilities of the Phantom 4 drone that was used. The research methodology involved the following components: (1) using the team 'brainstorming' process to settle on one research topic; (2) pooling the students' individual research efforts and findings to arrive at a comprehensive conclusion; (3) adapting a structured research approach to a very compressed, limited time frame; (4) coordinating a multidisciplinary team into a collaborative effort to meet specific deadlines; (5) using a high-tech mechanical device (the Phantom 4 Pro drone) to perform an untraditional assignment (spraying mosquitoes); and (6) training the students in the proper use and navigation of drones, and getting them FAA-qualified for pilot and ground observer status. Developing the mosquito spray container and spray release mechanism, and determining the type of spray to use, required two weeks of intensive study, analysis and design, necessitating several trials before achieving satisfactory results. Despite this time-consuming process, the students were able to conduct and complete the practical aspects of the research within the seven-week time-frame, although there wasn't enough time to adequately test the final design. © American Society for Engineering Education 2020.";
-;-;
Author;Bhandari, S., Tang, F., Aliyazicioglu, Z., Raheja, A., DeJonghe, E.;
Title;REU site on UAV technologies: Effectiveness of the program on student success;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095724815&partnerID=40&md5=5c6972ae845ef2b57e90ed25cecd098f;
-;-;
Abstract;ABSTRACT: This paper discusses the effectiveness of the REU Program at California State Polytechnic University, Pomona (Cal Poly Pomona) on the student success. The REU Program titled 'Research Experience for Undergraduates in UAV Technologies' was funded by the NSF's EEC Program. The main goal of the Program was to increase undergraduate students' participation and interest in research on unmanned aerial vehicles (UAV) technologies. Undergraduate students from 2- and 4-year institutions were involved in a multidisciplinary research projects at Cal Poly Pomona. The REU site has so far hosted a total of 31 diverse group of students for 8-10 weeks of summer search during the three year period, with the projects focusing on research on the Dynamics and Control of UAVs, Collision Detection and Avoidance System for UAVs, Artificial Intelligence, Computer Vision, Navigation in GPS-Denied Environments, and Flight Test experience. Another goal is to attract students from community colleges to STEM programs at 4-year institutions and encourage the participants to pursue their studies for graduate degrees. The paper discusses the effectiveness of the Program in meeting its goals and objectives and on student success. The Program has been tracking the participants. Most of the participants are now pursuing their educational or professional career in the area of UAVs and other related areas. The program has also been successful in motivating the participants to graduate degrees in STEM disciplines. Some of the participants are already pursuing their studies for a Master's degree or are planning to apply to Master's/PhD programs. Most of the community college students have transferred to 4-year institutions for degrees in engineering. Also, all the participants have presented their work at student and/or professional conferences. This has helped the participants improve their written and oral communication skills. The paper discusses how the Program influenced in motivating them to graduate studies and/or for R&D career in industry in the areas of UAV technologies. The paper also discusses lessons learned, student feedback, and their suggestion for improvements. Students reported statistically significant changes in skills related to UAVs from pre-participation to post-participation. In addition, improvements in 'soft skills particularly with regard to working in teams, were found in qualitative/quantitative results. © American Society for Engineering Education 2020.;
-;-;
Author;Song, B., Soria Zurita, N.F., Zhang, G., Stump, G., Balon, C., Miller, S.W., Yukish, M., Cagan, J., McComb, C.;
Title;TOWARD HYBRID TEAMS: A PLATFORM to UNDERSTAND HUMAN-COMPUTER COLLABORATION during the DESIGN of COMPLEX ENGINEERED SYSTEMS;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099623706&doi=10.1017%2fdsd.2020.68&partnerID=40&md5=a483444e8af55e3ee1b2cf81208b4e73;
-;-;
DOI;DOI: 10.1017/dsd.2020.68;
Abstract;ABSTRACT: Human-computer hybrid teams can meet challenges in designing complex engineered systems. However, the understanding of interaction in the hybrid teams is lacking. We review the literature and identify four key attributes to construct design research platforms that support multi-phase design, hybrid teams, multiple design scenarios, and data logging. Then, we introduce a platform for unmanned aerial vehicle (UAV) design embodying these attributes. With the platform, experiments can be conducted to study how designers and intelligent computational agents interact, support, and impact each other. © The Author(s), 2020. Published by Cambridge University Press.;
-;-;
Author;Wingo, H.;
Title;Smart city IoT: Co-designing trustworthy public safety drones for indoor flight missions;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094649320&doi=10.34190%2fEWS.20.509&partnerID=40&md5=81a08ad45a42bcf0b4d1d8a1766db573;
-;-;
DOI;DOI: 10.34190/EWS.20.509;
Abstract;"ABSTRACT: This paper proposes a collaborative design (“co-design”) approach to accelerating public and political acceptance of the cyberspace and information risks, inherent to the development and deployment of indoor smart building unmanned aircraft systems (UAS) to provide immediate “visual access” to law enforcement and other armed first responders in the case of an active shooter incident inside of a building, including risks concerning (1) system safety and reliability; (2) supply chain security; (3) cybersecurity; and (4) privacy. The paper explores the potential to use a virtual world platform as part of a phased pilot at the U.S. Service Academies to build trust in the privacy, security and efficacy of a counter active shooter UAS (CAS-UAS), trust necessary to win public and political support for procuring, developing, and deploying such a system. By using a live-virtual-constructive approach similar to the U.S. military’s synthetic training environments (STE), to intentionally engage a cross-functional team in a pilot to field a prototype CAS-UAS, a co-created CAS-UAS could anticipate and address security and privacy concerns of the sort that slowed the roll-out of police body-worn cameras (BWC) and wide area motion imagery (WAMI), particularly in the context of privacy concerns over the use of facial recognition. The paper is intended to provide communities with a new approach to identify and address policy obstacles to deploying smart city IoT technology to save lives, here in the case of a CAS-UAS that can enhance situational awareness for first responders during active shootings inside of public buildings like shopping malls, corporate headquarters, houses of worship or schools. The paper draws on the author’s personal experience testifying before the U.S. Congress concerning recent questions about the supply chain security of small commercial drones. © 2020 Curran Associates Inc.. All rights reserved.";
-;-;
Author;Magid, E., Pashkin, A., Simakov, N., Abbyasov, B., Suthakorn, J., Svinin, M., Matsuno, F.;
Title;Artificial intelligence based framework for robotic search and rescue operations conducted jointly by international teams;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072901857&doi=10.1007%2f978-981-13-9267-2_2&partnerID=40&md5=f634d91c4fba699a10dd1d3572dfee27;
-;-;
DOI;DOI: 10.1007/978-981-13-9267-2_2;
Abstract;ABSTRACT: Many countries suffer from various natural disasters, including heavy rains, that are associated with further flood and landslide disasters. Based on our experiences of different disasters response, we develop a joint international operation framework for a disaster site management with distributed heterogeneous robotic teams that consist of unmanned aerial, ground, surface, and underwater vehicles. The artificial intelligence-based information collection system, which is targeting to become a worldwide standard, contains interaction protocols, thematic mapping approaches, and map fusion processes. The project provides a new working framework and control strategies for heterogeneous robotic teams’ cooperative behavior in sensing, monitoring, and mapping of flood and landslide disaster areas. In this paper, we present an overview of the system and a first stage toward robot interaction protocols development and the system modeling within robot operating system’s Gazebo environment. © Springer Nature Singapore Pte Ltd 2020.;
-;-;
Author;Andrews, T., Stewart, R., Deitzler, W.;
Title;NASA Marshall Space Flight Center Human Factors Engineering Analysis of Various Hatch Sizes;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067690777&doi=10.1007%2f978-3-030-20454-9_57&partnerID=40&md5=29654677ec14f8bfef7fb712938226b9;
-;-;
DOI;DOI: 10.1007/978-3-030-20454-9_57;
Abstract;ABSTRACT: The NASA Docking System (NDS) is a 31.4961-inch (800 mm) diameter circular hatch for astronauts to pass through when docked to other pressurized elements in space or for entrance or egress on surface environments. The NDS is utilized on the Orion Spacecraft and has been implemented as the International Docking System Standard (IDSS). The EV74 Human Factors Engineering (HFE) Team at NASA’s Marshall Space Flight Center (MSFC) conducted human factors analyses with various hatch shapes and sizes to accommodate for all astronaut anthropometries and daily task comfort. It is believed that the hatch, approximately 32 inches, is too small, and a bigger hatch size would better accommodate most astronauts. To conduct human factors analyses, four participants were gathered based on anthropometry percentiles: 1st female, 5th female, 95th male, and 99th male. © 2020, Springer Nature Switzerland AG.;
-;-;
Author;Andrews, T., Searcy, B., Wallace, B.;
Title;Using Virtual Reality and Motion Capture as Tools for Human Factors Engineering at NASA Marshall Space Flight Center;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067672883&doi=10.1007%2f978-3-030-20454-9_41&partnerID=40&md5=adc0d4c3c90247c620815ac68c458c02;
-;-;
DOI;DOI: 10.1007/978-3-030-20454-9_41;
Abstract;"ABSTRACT: NASA Marshall Space Flight Center (MSFC) Human Factors Engineering (HFE) Team is implementing virtual reality (VR) and motion capture (MoCap) into HFE analyses of various projects through its Virtual Environments Lab (VEL). VR allows for multiple analyses early in the design process and more opportunities to give design feedback. This tool can be used by engineers in most disciplines to compare design alternatives and is particularly valuable to HFE to give early input during these evaluations. These techniques are being implemented for concept development of Deep Space Habitats (DSH), and work is being done to implement VR for design aspects of the Space Launch System (SLS). VR utilization in the VEL will push the design to be better formulated before mockups are constructed, saving budget and time. The MSFC VEL will continue forward leaning implementation with VR technologies in these and other projects for better models earlier in the design process. © 2020, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.";
-;-;
Author;Caldwell, B.S., Nyre-Yu, M., Hill, J.R.;
Title;Advances in human-automation collaboration, coordination and dynamic function allocation;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082510802&doi=10.3233%2fATDE190141&partnerID=40&md5=7066a3539cba96bea2513f28d25086d7;
-;-;
DOI;DOI: 10.3233/ATDE190141;
Abstract;ABSTRACT: Effective integration of humans and automation in control systems engineering has been an ongoing effort since the original publication of McRuer’s descriptions of human operators in servomechanism systems in 1959. Over the past 60 years, increasing capabilities of automation and computer systems have resulted in changing considerations of function allocation and human-automation interaction since Fitts’ “Humans are better at / Machines are better at” descriptions of the early 1950s. The processes of distributed autonomy and dynamic function allocation in modern human-automation and human-robotic interactions benefit from increased computing capabilities, resulting in systems with potentially fluid (and sometimes conflicting) boundaries for human vs. automation control. Using examples from human and robotic spaceflight, robotics can demonstrate significant autonomy (automated “safe-moding” and restart by Mars rovers), and humans may have limited autonomy (when astronauts conducting extravehicular activity rely on and wait for ground controllers to create or modify procedures to complete required tasks). Proposed future advances in human-automation interaction and coordination include the development of “centaur” teams of humans interacting with sophisticated software and robotic agents as team members (rather than fixed allocations as human-controlled servos or automation-controlled autonomous systems). Approaches within the authors’ lab include qualitative research of process and cognitive task demands to create functional architecture for AI applications in cyber security. Another method uses agent-based modeling to incorporate individual thinking style and interpersonal interactions in task performance simulations, effectively creating more robust hybrid systems incorporating cognitive and social factors in complex settings. © 2019 The authors and IOS Press.;
-;-;
Author;Darwante, S., Kadam, A., Talele, H., Ade, O., Bankar, A.;
Title;Border surveillance monitoring application;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088161089&doi=10.1109%2fICCUBEA47591.2019.9128792&partnerID=40&md5=c1f893b7983f37ca822ac113863e35c4;
-;-;
DOI;DOI: 10.1109/ICCUBEA47591.2019.9128792;
Abstract;ABSTRACT: In recent years, quad-copters is getting used in style of applications. The extremely agile dynamics of a quad-copter enable it to simply start and fly in any indoor or out of doors situation. The goal is to return up with a network of UAVs which will facilitate troopers for patrolling the country's border efficiently, whereas remaining cost effective. The aim was one in all detection of intruders as opposition detainment. To form UAV utterly autonomous this needs localization. In an outside atmosphere it's doable to use GPS based mostly position feedback to fly over a trajectory. By Using GPS calculate the trail distance, speed, tracing path is feasible and avoiding the obstacles is possible. Also, detection of targets may well be effective through air surveillance with the assistance of extremely cognitive and machine intelligent image process algorithms. Software technologies and hardware needed for multi tasks are modularized based on the requirements of the mission.The air and ground groups worked along to produce a system that incorporates a comprehensive image of the border whereas remaining cost effective and maintain strict security on the border. The UAV or quad-copter can stay in constant communication with the bottom base to effectively detect and track targets. In addition to this, the system is equipped with functionality to send real-time alert of intruder detected at certain location to nearby patrolling team with the help of android app and real-time database such as firebase. This demonstrates a use of GPS to form autonomous vehicles and the use of image process technology, machine intelligence for aerial visualization and detection of targets. © 2019 IEEE.;
-;-;
Author;Zhao, Z., Wang, C., Niu, Y., Shen, L., Ma, Z., Wu, L.;
Title;Adjustable Autonomy for Human-UAVs Collaborative Searching Using Fuzzy Cognitive Maps;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075749124&doi=10.1109%2fCCHI.2019.8901937&partnerID=40&md5=4b3cfa798d932e632d5e7b129e785d09;
-;-;
DOI;DOI: 10.1109/CCHI.2019.8901937;
Abstract;ABSTRACT: Collaborating with a team of UAVs remains a challenge for a human operator in the target searching task where the operator has to simultaneously monitor several video streams to search and verify the targets. In this paper, we propose an adjustable autonomy method that can dynamically change the levels of autonomy (LOA) for the UAVs according to the task complexity as well as the operator's cognitive workload. Specifically, we use a fuzzy cognitive map (FCM) to construct the framework of autonomy levels for unmanned systems (ALFUS). We have shown the effectiveness of the proposed method in an experiment that one human collaborates with four UAVs in a target searching task. © 2019 IEEE.;
-;-;
Author;Xu, D., Hui, Z., Liu, Y., Chen, G.;
Title;Morphing control of a new bionic morphing UAV with deep reinforcement learning;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067028833&doi=10.1016%2fj.ast.2019.05.058&partnerID=40&md5=2b779fffad455414b6ebb82112f3b84e;
-;-;
DOI;DOI: 10.1016/j.ast.2019.05.058;
Abstract;ABSTRACT: With rapid development of aviation technology, materials science and artificial intelligence, aircraft design is pursuing higher requirements both in civil and military fields. The new generation of aircraft should have the autonomous capable of performing a variety of tasks (such as take-off and landing, cruising, maneuvering, hover, attack, etc.) under a highly variable flight environment (height, Mach number, etc.) and meanwhile maintaining good performance. Morphing aircraft can use smart materials and actuators to autonomously deform the shape according to the changes in flight environment and mission, and always maintain an optimal aerodynamic shape, therefore get flourished developments. Based on the ability of birds to stretch wings when flying at low speed and to constrict wings at high speed, a new bionic morphing UAV has been designed and developed as the study model by our team. In order to make this new aircraft be able to complete rapid autonomous morphing and aerodynamic performance optimization under different missions and flight conditions, we developed deep neural networks and reinforcement learning techniques as a control strategy. Considering the continuity of the state and action spaces for model, the Deep Deterministic Policy Gradient (DDPG) algorithm based on the actor-critic, model-free algorithm was adopted and verified on the classic nonlinear Pendulum model and Cart Pole game. After the feasibility was verified, morphing aircraft model was controlled to complete prescribed deformation using DDPG algorithm. Furthermore, on the condition that the DDPG algorithm can control morphing well, through training and testing on model using simulation data from wind tunnel tests and actual flight, the autonomous morphing control for the shape optimization of the bionic morphing UAV model could be realized. © 2019 Elsevier Masson SAS;
-;-;
Author;Adão, T., Pinho, T.M., Pádua, L., Santos, N., Sousa, A., Sousa, J.J., Peres, E.;
Title;Using virtual scenarios to produce machine learnable environments for wildfire detection and segmentation;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074278302&doi=10.5194%2fisprs-archives-XLII-3-W8-9-2019&partnerID=40&md5=392a4d162ab7b4300d6a2c58839a047d;
-;-;
DOI;DOI: 10.5194/isprs-archives-XLII-3-W8-9-2019;
Abstract;ABSTRACT: Today's climatic proneness to extreme conditions together with human activity have been triggering a series of wildfire-related events that put at risk ecosystems, as well as animal and vegetal patrimony, while threatening dwellers nearby rural or urban areas. When intervention teams-firefighters, civil protection, police-acknowledge these events, usually they have already escalated to proportions hardly controllable mainly due wind gusts, fuel-like solo conditions, among other conditions that propitiate fire spreading. Currently, there is a wide range of camera-capable sensing systems that can be complemented with useful location data-for example, unmanned aerial systems (UAS) integrated cameras and IMU/GPS sensors, stationary surveillance systems-and processing components capable of fostering wildfire events detection and monitoring, thus providing accurate and faithful data for decision support. Precisely in what concerns to detection and monitoring, Deep Learning (DL) has been successfully applied to perform tasks involving classification and/or segmentation of objects of interest in several fields, such as Agriculture, Forestry and other similar areas. Usually, for an effective DL application, more specifically, based on imagery, datasets must rely on heavy and burdensome logistics to gather a representative problem formulation. What if putting together a dataset could be supported in customizable virtual environments, representing faithful situations to train machines, as it already occurs for human training in what regards some particular tasks (rescue operations, surgeries, industry assembling, etc.)? This work intends to propose not only a system to produce faithful virtual environments to complement and/or even supplant the need for dataset gathering logistics while eventually dealing with hypothetical proposals considering climate change events, but also to create tools for synthesizing wildfire environments for DL application. It will therefore enable to extend existing fire datasets with new data generated by human interaction and supervision, viable for training a computational entity. To that end, a study is presented to assess at which extent data virtually generated data can contribute to an effective DL system aiming to identify and segment fire, bearing in mind future developments of active monitoring systems to timely detect fire events and hopefully provide decision support systems to operational teams. © 2019 International Society for Photogrammetry and Remote Sensing.;
-;-;
Author;Xiong, P., Liu, H., Tian, Y.;
Title;Mission effectiveness evaluation of manned/unmanned aerial team based on OODA and agent-based simulation;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076619445&doi=10.1145%2f3348488.3348491&partnerID=40&md5=5d11c8ea1e870240c266675b54e067b5;
-;-;
DOI;DOI: 10.1145/3348488.3348491;
Abstract;ABSTRACT: Coordinated operation of manned and unmanned aerial vehicles is being taken as an important operation mode by military and research institutions in various countries. However, the complex coordination of aircrafts in the fleet has caused great difficulties for the evaluation of mission effectiveness. This paper studies the method to evaluate the mission effectiveness of manned/ unmanned aerial team based on agent-based simulation and proposes an approach called resource consumption analyze to establish evaluation index system. This approach decomposes missions into multiple tasks, and further decomposes the process of tasks based on Observe-Orient-Decide-Act (OODA) to facilitate modeling tasks and developing evaluation indicators. Moreover, this paper builds the behavior models of combat units based on OODA and conducts several simulation experiments to evaluate the mission effectiveness of manned/unmanned aerial team. These experiments show that the evaluation approach based on OODA and agent-based simulation can help to evaluate the mission effectiveness of manned/unmanned aerial team and design more suitable aircraft for future warfare. © 2019 Association for Computing Machinery.;
-;-;
Author;O'Riordan-Adjah, C.A.;
Title;Implementing research steps in undergraduate research;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078782171&partnerID=40&md5=b4f9f695fae138ece54ab0f8d3ed0088;
-;-;
Abstract;"ABSTRACT: This paper describes an eight-week undergraduate research project conducted at Principia College in Elsah, Illinois during the summer of 2018. The undertaking was distinctive in that it was an engineering research project conducted at a liberal-arts college by undergraduate students enrolled in the college's engineering program. A multidisciplinary research team was assembled, comprised of undergraduate engineering students serving as research assistants; a faculty instructor serving as project director and advisor to the students; and a Principia alumnus serving as an image processing and artificial intelligence (AI) consultant and advisor. The following engineering disciplines were represented by the team: civil, architectural, industrial, chemical and mechanical. The team performed a structural analysis of an historically significant building on campus, the Maybeck Chapel, designed by renowned architect Bernard R. Maybeck. Data collection involved using unmanned aerial vehicles (UAVs), commonly known as drones, to capture aerial photographs of the structure for detailed analysis. The selected methodology for conducting the project was a typical Engineering Design Process used primarily as a teaching tool to demonstrate the value and effectiveness of adhering to a standard, structured method for identifying the project objectives; collecting data; organizing and analyzing the accumulated information; and presenting the findings in both oral and written form. The project was instrumental in teaching the value and importance of the following: (1) close interaction and personal relationships between students and instructor; (2) collaborative efforts and teamwork among the students themselves; (3) organization and discipline; (4) time management and communication skills; (5) openness to research ideas and concepts; and (6) appreciation of the school's diverse curriculum. Finally, the overall goal was to encourage and teach the students how to think, plan, analyze, create, revise or improve what they create, and above all ask questions. © American Society for Engineering Education, 2019.";
-;-;
Author;Gorman, J.C., Demir, M., Cooke, N.J., Grimm, D.A.;
Title;Evaluating sociotechnical dynamics in a simulated remotely-piloted aircraft system: a layered dynamics approach;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061063547&doi=10.1080%2f00140139.2018.1557750&partnerID=40&md5=995bcf1daf959f3d194d9d8bf00f4564;
-;-;
DOI;DOI: 10.1080/00140139.2018.1557750;
Abstract;"ABSTRACT: As coordination mechanisms change and technology failures occur, a sociotechnical system must reorganise itself across human and technological layers to maintain effectiveness. We present a study examining reorganisation across communication, controls and vehicle layers of a remotely-piloted aircraft system (RPAS) using a layered dynamics approach. Team members (pilot; navigator; photographer) performed 5 simulated RPAS missions using different operator configurations, including all-human and human-autonomy teams. Reorganization (operationally defined using entropy) time series measured the changing system reorganisation profiles under different operator configurations and following autonomy failures. Correlations between these reorganisation profiles and team effectiveness scores describe the manner in which the system had to be coordinated to maintain effectiveness under these changing conditions. Four unplanned autonomy failures were analysed to visualise system reorganisation following a technology failure. With its objective and real-time modelling and measurement capabilities, layered dynamics complements existing systems thinking tools for understanding sociotechnical complexity and enhancing system effectiveness. Practitioner summary: A layered dynamics approach for understanding how a sociotechnical system dynamically reorganises itself is presented. The layered dynamics of RPAS were analysed under different operator configurations and following autonomy failures. Layered dynamics complements existing system-thinking tools for modelling sociotechnical system complexity and effectiveness. Abbreviation: RPAS: remotely-piloted aircraft system; HIS: human-systems integration; EAST: event analysis of systemic teamwork; H1: hypothesis 1; H2: hypothesis 2; H3: hypothesis 3; CERTT-STE: cognitive engineering research on team tasks--synthetic task environment; AVO: air vehicle operator; PLO: payload operator; DEMPC: data exploitation, mission planning, and communications; ACT-R: adaptive control of thought-rational; sec: seconds; ANOVA: analysis of variance. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.";
-;-;
Author;Mondal, M., Syryamkin, S.I.;
Title;Gesture based terrain mapping and recognition-overview;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065617859&doi=10.1088%2f1757-899X%2f516%2f1%2f012050&partnerID=40&md5=42014c762b0f4cfd61b3044d57ceb73a;
-;-;
DOI;DOI: 10.1088/1757-899X/516/1/012050;
Abstract;ABSTRACT: Up until a few years ago, the only way to get an aerial overview of a designated area was to fly over it with a manned aircraft and physically inspecting the areas or taking pictures of it. Unmanned Aerial Vehicles, have been a blessing to all the industries which relied on aerial images or drawings for their work. Unmanned aerial vehicles also knows as drones, in more colloquial terms, is a blessing to all industries in the world. The cost of manufacturing and assembling drones have gone down significantly as majority of people adapted to using it. The film industries are using it to get excellent footage with accurate direction and lighting. Civilians can use it as toys. Students can use it to learn avionics and flight mechanisms. Youtubers use it for professional high resolution footage. Rescue teams use it for surveying the area. Armies use it to get a tactical advantage in a firefight and recently, Amazon is using drones for superfast delivery service. The possibilities are endless if properly invested on. Machine Learning and Artificial Intelligence are next best thing in the field of Computer Science and that's why I plan to merge these two fields and present something which fundamentally adds more features and a hive mind facility to even work without a commanding signal. © Published under licence by IOP Publishing Ltd.;
-;-;
Author;Andong, S., Yamamoto, H.;
Title;Victim Detection System Using Autonomous UAV Flight and Data Analysis based on Multiple Beacon Radio Sensing;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063882561&doi=10.1109%2fICAIIC.2019.8668991&partnerID=40&md5=43c8d889a3948832711dea6fe6b0fd74;
-;-;
DOI;DOI: 10.1109/ICAIIC.2019.8668991;
Abstract;ABSTRACT: In recent years, the number of people who get lost in a mountainous area due to natural disaster and bad weather is increasing. In order to quickly detect the location of the victims when the accident is occurred, a beacon device for climbers has been utilized so far. However, range of the radio wave transmitted from the beacon device is very short, hence dangerous situations might occur on the rescue team when they get in to the mountainous area in order to search for victims.Therefore, in this research, we develop a new system which can detect victim's location and condition by utilizing UAV (Unmanned Aerial Vehicle). In the proposed system, after a rescuer starts to control the UAV by using a control application of a smartphone, the UAV automatically moves to a location where the accident is occurred, and searches the location of victim by moving to the direction where a radio wave from the beacon can be measured strongly. Furthermore, the UAV identifies a condition of the victim by measuring and analyzing the received signal strength of radio waves transmitted from the beacon device on multiple frequency bands which has different propagation characteristics. For example, a radio wave of the 429MHz frequency bands is easily absorbed by moisture compared with the 920MHz bands. These mean that the received signal strength of radio waves of the 429MHz band is lower than that of the 920MHz band when the beacon is covered by snow. By utilizing these propagation characteristics, we attempt to determine the condition of the victim. © 2019 IEEE.;
-;-;
Author;Yourdshahi, E.S., Angelov, P., Marcolino, L.S., Tsianakas, G.;
Title;Towards Evolving Cooperative Mapping for Large-Scale UAV Teams;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062799360&doi=10.1109%2fSSCI.2018.8628838&partnerID=40&md5=d77ee8f966557da4274b53c8212b0650;
-;-;
DOI;DOI: 10.1109/SSCI.2018.8628838;
Abstract;ABSTRACT: A team of UAVs has great potential to handle real-world challenges. Knowing the environment is essential to perform in an effective manner. However, in many situations, a map of the environment will not be available. Additionally, for autonomous systems, it is necessary to have approaches that require little energy, computing, power, weight and size. To address this, we propose a light-weight, evolving, and memory efficient cooperative approach for estimating the map of an environment with a team of UAVs. Additionally, we present proof-of-concept experiments with real-life flights, showing that we can estimate maps using an off-the-shelf web-camera. © 2018 IEEE.;
-;-;
Author;Cavaliere, D., Senatore, S.;
Title;Towards an agent-driven scenario awareness in remote sensing environments;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062769642&doi=10.1109%2fSSCI.2018.8628882&partnerID=40&md5=13ce39871313c4ce7019cd6329d0e9d1;
-;-;
DOI;DOI: 10.1109/SSCI.2018.8628882;
Abstract;ABSTRACT: In dynamic environments, autonomous and unmanned vehicle systems (UVSs) represent a reliable solution, especially when the request of high performance is a stringent constraint for complex and risky tasks, such as searching survival points, multiple target monitoring, and tracking, etc. In these cases, cooperative activities among all the involved UVSs are strategic for the achievement of a collective goal. When UVS teams work collaboratively, they collect heterogeneous data from multiple sources and bring benefits through an enhanced situational awareness (SA). Multi-UVS scenarios are, by their nature, easy to be modeled as multi-agent systems. This paper presents an agent-based modeling, governing different types of unmanned vehicles that are sent ahead in an area of interest to gather environmental, sensing, image data in order to provide a complete multi-view scenario understanding. The agent model is instantiated in each vehicle, and depending on the vehicle features, encapsulates a semantic mental modeler, customized for the specific vehicle features. The agents collect raw data from the environment and translate them into high-level knowledge, i.e., a conceptualization of the data semantics (i.e., a set of pixels assumes the meaning of a car). The proposed agent-based modeling lays on a synergy between Semantic Web technologies and Fuzzy Cognitive Map (FCM) models, producing a high-level description of the evolving scenes, and then a comprehensive scenario situational awareness. © 2018 IEEE.;
-;-;
Author;Piacentini, C., Bernardini, S., Beck, J.C.;
Title;Autonomous target search with multiple coordinated UAVS;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088524494&doi=10.1613%2fJAIR.1.11635&partnerID=40&md5=72246f191b3ea3f5ad235d6cb50a7058;
-;-;
DOI;DOI: 10.1613/JAIR.1.11635;
Abstract;ABSTRACT: Search and tracking is the problem of locating a moving target and following it to its destination. In this work, we consider a scenario in which the target moves across a large geographical area by following a road network and the search is performed by a team of unmanned aerial vehicles (UAVs). We formulate search and tracking as a combinatorial optimization problem and prove that the objective function is submodular. We exploit this property to devise a greedy algorithm. Although this algorithm does not offer strong theoretical guarantees because of the presence of temporal constraints that limit the feasibility of the solutions, it presents remarkably good performance, especially when several UAVs are available for the mission. As the greedy algorithm suffers when resources are scarce, we investigate two alternative optimization techniques: Constraint Programming (CP) and AI planning. Both approaches struggle to cope with large problems, and so we strengthen them by leveraging the greedy algorithm. We use the greedy solution to warm start the CP model and to devise a domain-dependent heuristic for planning. Our extensive experimental evaluation studies the scalability of the different techniques and identifies the conditions under which one approach becomes preferable to the others. ©2019 AI Access Foundation. All rights reserved.;
-;-;
Author;Akçakoca, M., Atıcı, B.M., Gever, B., Oğuz, S., Demir, M., Saldiran, E., Yuksek, B., Koyuncu, E., Yeniceri, R., Inalhan, G.;
Title;A simulation-based development and verification architecture for micro uav teams and swarms;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083941381&doi=10.2514%2f6.2019-1979&partnerID=40&md5=9055b715cad9a17a94f4c8c21ca362d7;
-;-;
DOI;DOI: 10.2514/6.2019-1979;
Abstract;ABSTRACT: In this work, we present an unmanned aerial vehicle (UAV) simulation-based, hardware and software development and verification architecture structured around the Robot Operating System (ROS). One of the key expectations of such a system is a graceful increase in architectural and computational complexity as the number of vehicles and vehicle complexity increases. In addition, the system is expected to provide the ability to test and verify algorithms both at the software and hardware level before real flight operations. This requirement also couples with the requested flexibility of updating the models and the algorithms based on the results coming from real operations. As such, the designed architecture allows joint simulation and testing at both hardware and software layers for multiple vehicle and swarm operations. Specifically, the architecture consists of distinct and networked layers where hardware elements such as autopilot systems (e.g., Pixhawk, Ardupilot etc.), ground stations and external motion capture/localization systems (e.g., Vicon, Otus Tracker etc.) are integrated around the ROS simulation shell. In addition, the dynamics, sensor models, motion planning and other features can be driven by highly parallel MATLAB/Simulink models. Visualization and visual sensing is obtained through linking of virtual reality with simulation environments such as Gazebo and Airsim. This highly reconfigurable architecture allows research teams to work on multidisciplinary areas such as modeling, control, computer vision, artificial intelligence and machine learning within the same simulation and test environment. © 2019, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.;
-;-;
Author;Demir, M., McNeese, N.J., Cooke, N.J.;
Title;The Evolution of Human-Autonomy Teams in Remotely Piloted Aircraft Systems Operations;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083548846&doi=10.3389%2ffcomm.2019.00050&partnerID=40&md5=9084d51774d7cbd555497c6dabec5a24;
-;-;
DOI;DOI: 10.3389/fcomm.2019.00050;
Abstract;ABSTRACT: The focus of this current research is 2-fold: (1) to understand how team interaction in human-autonomy teams (HAT)s evolve in the Remotely Piloted Aircraft Systems (RPAS) task context, and (2) to understand how HATs respond to three types of failures (automation, autonomy, and cyber-attack) over time. We summarize the findings from three of our recent experiments regarding the team interaction within HAT over time in the dynamic context of RPAS. For the first and the second experiments, we summarize general findings related to team member interaction of a three-member team over time, by comparison of HATs with all-human teams. In the third experiment, which extends beyond the first two experiments, we investigate HAT evolution when HATs are faced with three types of failures during the task. For all three of these experiments, measures focus on team interactions and temporal dynamics consistent with the theory of interactive team cognition. We applied Joint Recurrence Quantification Analysis, to communication flow in the three experiments. One of the most interesting and significant findings from our experiments regarding team evolution is the idea of entrainment, that one team member (the pilot in our study, either agent or human) can change the communication behaviors of the other teammates over time, including coordination, and affect team performance. In the first and second studies, behavioral passiveness of the synthetic teams resulted in very stable and rigid coordination in comparison to the all-human teams that were less stable. Experimenter teams demonstrated metastable coordination (not rigid nor unstable) and performed better than rigid and unstable teams during the dynamic task. In the third experiment, metastable behavior helped teams overcome all three types of failures. These summarized findings address three potential future needs for ensuring effective HAT: (1) training of autonomous agents on the principles of teamwork, specifically understanding tasks and roles of teammates, (2) human-centered machine learning design of the synthetic agent so the agents can better understand human behavior and ultimately human needs, and (3) training of human members to communicate and coordinate with agents due to current limitations of Natural Language Processing of the agents. © Demir, McNeese and Cooke.;
-;-;
Author;Mishra, M., Mannaru, P., Sidoti, D., Bienkowski, A., Zhang, L., Pattipati, K.R.;
Title;Context-driven proactive decision support for hybrid teams;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073424957&doi=10.1609%2faimag.v40i3.4810&partnerID=40&md5=c7e31e0d4f65162f57ca980aff6c9f47;
-;-;
DOI;DOI: 10.1609/aimag.v40i3.4810;
Abstract;ABSTRACT: R apidly changing patterns in today's world impose real-time decision-making requirements in many complex organizations, ranging from maritime establishments to agile manufacturing systems and commercial enterprises. One of the key trends in maritime operations is the pervasive use of smart machines (for example, unmanned aerial and underwater vehicles) for countersmuggling, search and rescue operations, and battle management, to name a few. The primary reasons for the use of unmanned vehicles include their operability from remote locations, ultralong endurance, and high-risk mission acceptance. Additionally, these smart machines can be made smaller, agile, and more economical than their manned counterparts. With rapid advances in AI, smart machines and agents are becoming more autonomous (that is, they can both respond to human commands and operate independently) and require only intermittent human intervention to keep them aligned with human intentions. In March 2018 (Wakabayashi 2018), a pedestrian was hit and killed by a self-driving car (with an emergency driver behind the wheel), indicating the need for a human driver to intervene in a timely manner to avoid mishaps. It was later found that the emergency braking system in the car was disabled and the driver was streaming a TV show before the incident. This mishap could have been avoided had the emergency brakes been enabled and had the driver been paying attention. This incident illustrates the need to make machines more intelligent so that they can mimic the human thought processes of understanding the environment and can provide appropriate alerts for interfacing with the human when attention is warranted or required for not only unexpected but uncertain situations as well. © 2019 AI Access Foundation. All rights reserved.;
-;-;
Author;Sousa, D., Sargento, S., Pereira, A., Luís, M.;
Title;Self-adaptive Team of Aquatic Drones with a Communication Network for Aquaculture;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072860307&doi=10.1007%2f978-3-030-30244-3_47&partnerID=40&md5=ef053794cd29ab5cb1cec11357502668;
-;-;
DOI;DOI: 10.1007/978-3-030-30244-3_47;
Abstract;ABSTRACT: The use of Unmanned Surface Vehicle (USV) teams, more commonly known as drones, has become increasingly common for aquaculture scenarios due to their availability and low cost. For monitoring to be feasible and in real time, it is necessary for the drones to be in constant communication so that they can organize themselves and send data to a land platform. This paper presents a cooperative navigation behavior in constant communication with the network layer to achieve a better overall performance in the coverage of a space and a better network quality between heterogeneous USVs. In conclusion, increasing the amount of USVs is beneficial as long as an Avoid or Assist does not impact the overall time. © 2019, Springer Nature Switzerland AG.;
-;-;
Author;Blowers, M., Scrafford, S., Williams, J.;
Title;Blockchain technologies and distributed ledger systems as enablers for real time decision support;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070087973&doi=10.1117%2f12.2519948&partnerID=40&md5=bd6bc1bdbd8c0ebe3452db64ef1b4341;
-;-;
DOI;DOI: 10.1117/12.2519948;
Abstract;ABSTRACT: Blockchain technologies and smart contracts were considered for their potential to provide tremendous benefits as decision support tools to the next generation of Warfighters. An investigative team focused on novel security-enhanced information gathering and decision support Artificial-Intelligence (AI) based software agents that will serve as decision support co-pilots when commanders are developing real-time multi-domain orders of battle. As a core construct for this architecture, smart contracts allow for the governance of these systems to be time-bound and/or condition-bound. This disruptive technology propels progress made with distributed multi-agent systems with the numerous security benefits of blockchain technologies. Methods for implementing intelligent computing agents that follow and execute the logic embedded in a contract model will provide a transparent record of agents, chain of trust and chain of custody on the blockchain. This paper will explore mechanisms for maintaining a hierarchy of smart contracts allowing reasoning and decision support over different aspects of the overall command structure. Finally, the potential for maintaining multiple levels of classification across communication channels for platforms tasked with collection and reconnaissance missions will explored. © 2019 SPIE.;
-;-;
Author;Lodeiro-Santiago, M., Caballero-Gil, P., Aguasca-Colomo, R., Caballero-Gil, C.;
Title;Secure UAV-based system to detect small boats using neural networks;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062858138&doi=10.1155%2f2019%2f7206096&partnerID=40&md5=d18582686772deade5788b68302b117d;
-;-;
DOI;DOI: 10.1155/2019/7206096;
Abstract;ABSTRACT: This work presents a system to detect small boats (pateras) to help tackle the problem of this type of perilous immigration. The proposal makes extensive use of emerging technologies like Unmanned Aerial Vehicles (UAV) combined with a top-performing algorithm from the field of artificial intelligence known as Deep Learning through Convolutional Neural Networks. The use of this algorithm improves current detection systems based on image processing through the application of filters thanks to the fact that the network learns to distinguish the aforementioned objects through patterns without depending on where they are located. The main result of the proposal has been a classifier that works in real time, allowing the detection of pateras and people (who may need to be rescued), kilometres away from the coast. This could be very useful for Search and Rescue teams in order to plan a rescue before an emergency occurs. Given the high sensitivity of the managed information, the proposed system includes cryptographic protocols to protect the security of communications. © 2019 Moisés Lodeiro-Santiago et al.;
-;-;
Author;Stevens, C.A., Fisher, C.R., Morris, M.B., Myers, C., Spriggs, S., Dukes, A.;
Title;Cognitive metrics profiling: A model-driven approach to predicting and classifying workload;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053592463&doi=10.1007%2f978-3-319-94223-0_22&partnerID=40&md5=0a566523e472cab69699928708c30443;
-;-;
DOI;DOI: 10.1007/978-3-319-94223-0_22;
Abstract;ABSTRACT: Workload management is integral to the success of human-machine teams, and involves measuring and predicting workload and implementing proactive interventions to mitigate the adverse effects of degraded performance. Common approaches to workload measurement rely on the use of subjective, behavioral, and physiological metrics. These approaches suffer from two important limitations. First, the mapping between workload, subjective ratings, behavior, and physiology is complex and noisy, resulting in high uncertainty. Second, metrics based on subjective ratings, behavior, and physiology often fail to explain why performance degrades, and consequentially does not inform the development of mitigation strategies. As an alternative, we propose using cognitive metrics profiling (CMP) to improve the measurement and prediction of workload. This approach uses computational cognitive models to simulate the activity within individual cognitive systems, such as vision, audition, memory, and motor, to measure and understand workload. We discuss how CMP can be used in an unmanned vehicle control task. © Springer International Publishing AG, part of Springer Nature (outside the USA) 2019.;
-;-;
Author;Chen, J., Gao, X., Chen, X., He, Q.;
Title;A Shifting Method for Intelligent Operational Mode of UAVs;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060795465&doi=10.1109%2fICARCV.2018.8581242&partnerID=40&md5=6ce8b750fe7bd329f6d2b3b437e622b6;
-;-;
DOI;DOI: 10.1109/ICARCV.2018.8581242;
Abstract;ABSTRACT: This paper proposed the intelligent operational mode to support UAVs autonomous decision-making, so the pilot's cognitive load declined and the UAV's decision performance improved in manned/unmanned aerial vehicles (MAV/UAVs) teams. The intelligent operational mode, which is determined by UAVs' comprehension of the human-machine-environment system, reflects the decision preference of UAVs. To explain how the intelligent operation mode shifts, two models were created based on Fuzzy Cognitive Map (FCM) and Fuzzy Grey Cognitive Map (FGCM). The first model assessed the pilot's cognitive load and the second derived the intelligent operational mode from the pilot's cognitive loads and many other critical factors. At the end of this paper, the rationality and feasibility of the proposed models are checked by several cases. © 2018 IEEE.;
-;-;
Author;Pransky, J.;
Title;The Pransky interview: Professor Robin R. Murphy, Co-founder of the Field of Disaster Robotics and Founder of Roboticists Without Borders;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055213530&doi=10.1108%2fIR-07-2018-0136&partnerID=40&md5=41dd92c596dcc9968ae67aa14cf0658d;
-;-;
DOI;DOI: 10.1108/IR-07-2018-0136;
Abstract;"ABSTRACT: Purpose: This paper is a “Q&A interview” conducted by Joanne Pransky of Industrial Robot Journal as a method to impart the combined technological, business and personal experience of a prominent, robotic industry engineer-turned successful innovator and leader regarding the challenges of bringing technological discoveries to fruition. This paper aims to discuss these issues. Design/methodology/approach: The interviewee is Dr Robin R. Murphy, Raytheon Professor of Computer Science and Engineering, Texas A&M University; Co-lead, Emergency Informatics EDGE Innovation Network Center, Texas A&M, Director of the Humanitarian Robotics and AI Laboratory and Vice President of the Center for Robot-Assisted Search and Rescue (CRASAR) http://crasar.org. In this interview, Dr Murphy provides answers to questions regarding her pioneering experiences in rescue robotics. Findings: As a child, Dr Murphy knew she wanted to be a mechanical engineer and obtained her BME degree from Georgia Institute of Technology (Georgia Tech). While working in industry after her BME, she fell in love with computer science and received an MS and PhD in Computer Science at Georgia Tech where she was a Rockwell International Doctoral Fellow. In the mid-1990s, while teaching at the Colorado School of Mines, she pioneered rescue robots after one of her graduate students returned from the Oklahoma City bombing and suggested that small rescue robots should be developed for future disasters. The National Science Foundation awarded Murphy and her students the first grant for search-and-rescue robots. She has since assisted in responses at more than 20 worldwide disasters, including Hurricane Katrina, the Crandall Canyon Mine collapse, the Tohoku Tsunami and the Fukushima Daiichi nuclear accident. Originality/value: The response to the World Trade Center attacks after September 11, 2001 by Dr Murphy’s team from the University of South Florida (the only academic institution), along with four other teams brought together by CRASAR, marked the first recorded use of a rescue robot at a disaster site. In addition to being a founder in the field of rescue robots, she is also a founder in the field of human–robot interaction and the Roboticists Without Borders. She has written over 100 publications and three books: the best-selling textbook, Introduction to AI Robotics, Disaster Robotics and Robotics-Through-Science-Fiction: Artificial Intelligence Explained Six Classic Robot Short Stories. Dr Murphy has received approximately 20 national awards and honors including: the AUVSI’s Al Aube Outstanding Contributor Award, the Eugene L. Lawler Award for Humanitarian Contributions within Computer Science and Informatics, CMU Field Robotics Institute “Pioneer in Field Robotics” and TIME Magazine, Innovators in Artificial Intelligence. She is an IEEE Fellow. © 2018, Emerald Publishing Limited.";
-;-;
Author;Das, A., Kol, P., Lundberg, C., Doelling, K., Sevil, H.E., Lewis, F.;
Title;A Rapid Situational Awareness Development Framework for Heterogeneous Manned-Unmanned Teams;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059900545&doi=10.1109%2fNAECON.2018.8556769&partnerID=40&md5=08364bb6da53901212ea4e28adde9035;
-;-;
DOI;DOI: 10.1109/NAECON.2018.8556769;
Abstract;ABSTRACT: This paper presents a robust framework for configuring and deploying a heterogeneous team of smart unmanned systems and human agents in dynamic and un-modeled environments to rapidly build mission critical situational awareness with selective details of potential areas of interest, especially focusing on minimized cognitive loading of the human agents. Five key components, namely control, communication, artificial intelligence (AI), platform, and visualization, merge seamlessly into a holistic framework to deliver this rapid situational awareness development capability to the heterogeneous manned unmanned team (MUM-T). In this framework, the overall control is seen as a combination of agent level control and mission level control. A common software, Robot Operating System (ROS), is used to establish communication, and consequently consensus, among the heterogeneous swarm of unmanned systems. These unmanned platforms are customized with co-processing hardware that can execute advanced artificial intelligence machine learning (AI/ML) modules to not only deliver stable and cooperative performance of these unmanned platforms in the swarm but also support human-centric human robot interaction (HRI). Finally, to reduce the cognitive burden on the human agents, a triaged visualization scheme, enabled through mixed reality (MR) technology, is implemented. This paper presents a preliminary proof of concept study for the presented hybrid map (i.e. 2D mapping with 3D detailing) construction framework, tested with a heterogeneous swarm of unmanned aerial vehicles (UAVs) of varying capabilities, teamed with a human operator. © 2018 IEEE.;
-;-;
Author;Sherstjuk, V., Zharikova, M., Sokol, I.;
Title;Forest Fire-Fighting Monitoring System Based on UAV Team and Remote Sensing;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055774076&doi=10.1109%2fELNANO.2018.8477527&partnerID=40&md5=cd26efc514b9788ae60db1d5ef1250a2;
-;-;
DOI;DOI: 10.1109/ELNANO.2018.8477527;
Abstract;ABSTRACT: This work presents a monitoring system for tactical forest fire-fighting operations based on a team of unmanned aerial vehicles and remote sensing techniques. Functions and missions of the system, as well as its architecture, are considered. Image processing and remote sensing algorithms are presented, a way for data integration into a fire-spreading model in a real-time forest fire response decision support system is proposed. The combination of automatic monitoring and remote sensing techniques with an approximate fire-spreading model can provide required credibility and efficiency of fire prediction and response. © 2018 IEEE.;
-;-;
Author;Bhandari, S., Aliyazicioglu, Z., Tang, F., Raheja, A.;
Title;Research experience for undergraduates in UAV technologies;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051209278&partnerID=40&md5=d873880ac322c553a7c04cee558953df;
-;-;
Abstract;ABSTRACT: The Research Experience for Undergraduates (REU) in UAV Technologies Program is funded by the National Science Foundation's (NSF) Engineering Education & Centers (EEC) Program. The main goal of this program is to increase undergraduate students' participation and interest in research on unmanned aerial vehicles (UAV) technologies. Undergraduate students from 2- and 4-year institutions are involved in a multidisciplinary research projects at the Cal Poly Pomona. The REU site supports 10 students for 10 weeks of summer research per year, with the projects focusing on research on the Dynamics and Control of UAVs, Obstacle & Collision Avoidance System for UAVs, Machine Learning, Artificial Intelligence, Computer Vision, and Flight Test experience. Another goal is to attract students from community colleges to STEM programs at 4-year institutions and encourage the participants to pursue their studies for graduate degrees. This paper presents an overview of student activities, lessons learned so far, and the assessment of the first year of the program. The students were carefully and closely mentored by an interdisciplinary team of faculty members from various departments within the Colleges of Engineering and Science. The participating students learned to use computational tools needed to engage in multidisciplinary UAV research projects. They learned to do the scientific literature review, and had an opportunity to improve written and oral communication skills. The participants were required to present a poster, give an oral presentation of the research, and submit abstract (s) to student and/or professional conferences. In addition, the students participated in a series of research symposium and seminars designed to expose them to a range of research topics, and engage in professional development activities such as workshop on Application to Graduate Programs, Resume Building, Ethics in Engineering and Science, etc. © American Society for Engineering Education, 2018.;
-;-;
Author;Liu, Z., Gao, X., Fu, X.;
Title;A cooperative search and coverage algorithm with controllable revisit and connectivity maintenance for multiple unmanned aerial vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046671494&doi=10.3390%2fs18051472&partnerID=40&md5=0d7f962d82360caa560848ec34205f4d;
-;-;
DOI;DOI: 10.3390/s18051472;
Abstract;ABSTRACT: In this paper, we mainly study a cooperative search and coverage algorithm for a given bounded rectangle region, which contains several unknown stationary targets, by a team of unmanned aerial vehicles (UAVs) with non-ideal sensors and limited communication ranges. Our goal is to minimize the search time, while gathering more information about the environment and finding more targets. For this purpose, a novel cooperative search and coverage algorithm with controllable revisit mechanism is presented. Firstly, as the representation of the environment, the cognitive maps that included the target probability map (TPM), the uncertain map (UM), and the digital pheromone map (DPM) are constituted. We also design a distributed update and fusion scheme for the cognitive map. This update and fusion scheme can guarantee that each one of the cognitive maps converges to the same one, which reflects the targets’ true existence or absence in each cell of the search region. Secondly, we develop a controllable revisit mechanism based on the DPM. This mechanism can concentrate the UAVs to revisit sub-areas that have a large target probability or high uncertainty. Thirdly, in the frame of distributed receding horizon optimizing, a path planning algorithm for the multi-UAVs cooperative search and coverage is designed. In the path planning algorithm, the movement of the UAVs is restricted by the potential fields to meet the requirements of avoiding collision and maintaining connectivity constraints. Moreover, using the minimum spanning tree (MST) topology optimization strategy, we can obtain a tradeoff between the search coverage enhancement and the connectivity maintenance. The feasibility of the proposed algorithm is demonstrated by comparison simulations by way of analyzing the effects of the controllable revisit mechanism and the connectivity maintenance scheme. The Monte Carlo method is employed to validate the influence of the number of UAVs, the sensing radius, the detection and false alarm probabilities, and the communication range on the proposed algorithm. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.;
-;-;
Author;Brutzman, D., Blais, C.L., Davis, D.T., McGhee, R.B.;
Title;Ethical Mission Definition and Execution for Maritime Robots under Human Supervision;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040938066&doi=10.1109%2fJOE.2017.2782959&partnerID=40&md5=9e1eabc5000d1a7fe59f8e316c1f3fc6;
-;-;
DOI;DOI: 10.1109/JOE.2017.2782959;
Abstract;ABSTRACT: Experts and practitioners have worked long and hard toward achieving functionally capable robots. While numerous areas of progress have been achieved, ethical control of unmanned systems meeting legal requirements has been elusive and problematic. Common conclusions that treat ethical robots as an always-amoral philosophical conundrum requiring undemonstrated morality-based artificial intelligence are simply not sensible or repeatable. Patterning after successful practice by human teams shows that precise mission definition and task execution using well-defined, syntactically valid vocabularies is a necessary first step. Addition of operational constraints enables humans to place limits on robot activities, even when operating at a distance under gapped communications. Semantic validation can then be provided by a Mission Execution Ontology to confirm that no logical or legal contradictions are present in mission orders. Thorough simulation, testing, and certification of qualified robot responses are necessary to build human authority and trust when directing ethical robot operations at a distance. Together these capabilities can provide safeguards for autonomous robots possessing the potential for lethal force. This approach appears to have broad usefulness for both civil and military application of unmanned systems at sea. © 1976-2012 IEEE.;
-;-;
Author;Brinkmann, W., Bartsch, S., Sonsalla, R.U., Cordes, F., Kuehn, D., Kirchner, F.;
Title;Advanced robotic systems in the context of future space exploration;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065310957&partnerID=40&md5=6012ec045b53319f08c618babc6b0b8c;
-;-;
Abstract;ABSTRACT: Future space exploration is calling for more sophisticated robotic solutions for various applications. Plans are made by the prime space agencies for challenging and complex missions, ranging from orbital servicing to deep space exploration with a strong focus on robotic and manned missions to Moon and Mars. In order to cope with these upcoming mission goals a need arises for capable robotic solutions, bringing together innovative technologies and software algorithms to provide reliable, highly integrated robotic systems with advanced autonomous behavior. The German Research Center for Artificial Intelligence - Robotics Innovation Center (DFKI RIC) has a traditionally strong background in the field of space robotics. This paper aims at presenting an overview of the robotic systems developed at DFKI RIC in the context of advanced space missions. Based on current mission roadmaps, an overview of upcoming space missions is presented and evaluated, to identify and cluster the mission targets and most demanding needs for robotic systems in future robot-based or -assisted missions. The type of systems range from advanced (mobile) manipulators to humanoid and multi-legged walking and climbing robots as well as highly mobile rover platforms to autonomous underwater vehicles. The paper presents the main system features, their aspired application scenarios as well as evaluation results gained in analogue missions or relevant test scenarios. The robot control ranges from human-in-the-loop control approaches of single systems to fully autonomous exploration missions of heterogeneous robot teams. With a view to the aspired future missions, the robotic systems are discussed in context to the upcoming mission needs and evaluated against their suitability. Furthermore, an outlook for the enhancement of the systems is given as well as a potential view beyond the current space mission roadmaps. Â© 2018 by the International Astronautical Federation. All rights reserved.;
-;-;
Author;Ropero, F., Muñoz, P., R-Moreno, M.D.;
Title;A strategical path planner for UGV-UAV cooperation in Mars Terrains;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058396374&doi=10.1007%2f978-3-030-04191-5_8&partnerID=40&md5=e0c6432d8c8d38c2ce213ea39f41d4f8;
-;-;
DOI;DOI: 10.1007/978-3-030-04191-5_8;
Abstract;ABSTRACT: Mars exploration is an ongoing researching topic mainly due to the technological breakthroughs in robotic platforms. Space agencies as NASA, are considering future Mars explorations where multi-robot teams cooperate to maximize the scientific return. In this regard, we present a cooperative team formed by a Unmanned Aerial Vehicle (UAV) and a Unmanned Ground Vehicle (UGV) to autonomously perform a Mars exploration. We develop a strategical path planner to compute a route plan for the UGV-UAV team to reach all the target points of the exploration. The key problems that we have considered in Mars explorations for the UGV-UAV team are: the UAV energy constraints and the UGV functionality constraints. Our strategical path planner models the UGV as a moving charging station which will carry the UAV through secure locations close to the target points locations, and the UAV will visit the target points using the UGV as a recharging station. Our solution has been tested in several scenarios and the results demonstrate that our approach is able to carry out a coordinated plan in a local optimal mission time on a real Mars terrain. © Springer Nature Switzerland AG 2018.;
-;-;
Author;Zou, K., Zhang, R., Jiang, Y.;
Title;Yield estimation using unmanned aerial vehicle low-altitude imaging for dense planting cotton field;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054185897&doi=10.13031%2faim.201800777&partnerID=40&md5=13938a3e3851a9bbb2735d32aec772e0;
-;-;
DOI;DOI: 10.13031/aim.201800777;
Abstract;ABSTRACT: Cotton yield estimation is very important for cotton production. This paper presents a method for estimating the yield with UAV imaging system in dense planting cotton field. First of all, in the cotton field defined a number of sample areas. Then the images of the sample areas were obtained by UAV imaging system, and cotton boll pixels were extracted from the image by a machine learning algorithm and the cotton unit coverage (CUC) rate was calculated. All cotton balls in the sampling area were collected, and the cotton yield was calculated. The relationship between cotton unit coverage and cotton yield of each sample areas was explored, and a regression model of cotton unit coverage and cotton yield was obtained. Cotton yield was calculated based on this model. Our research team used this method to estimate the yield of a dense planting cotton field. The accuracy of estimating yield was 89.13%，and the efficiency of estimating was 133.33 m2 / min. The experimental results indicate that this method is suitable for cotton yield estimation. © 2018 American Society of Agricultural and Biological Engineers. All rights reserved.;
-;-;
Author;Allen, B.D.;
Title;Serious gaming for building a basis of certification via trust and trustworthiness of autonomous systems;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051647799&doi=10.2514%2f6.2018-3844&partnerID=40&md5=847a402844d0db04809ec3d1c4a07c28;
-;-;
DOI;DOI: 10.2514/6.2018-3844;
Abstract;ABSTRACT: Autonomous systems governed by a variety of adaptive and nondeterministic algorithms are being planned for inclusion into safety-critical environments, such as unmanned aircraft and space systems in both civilian and military applications. However, until autonomous systems are proven and perceived to be capable and resilient in the face of unanticipated conditions, humans will be reluctant or unable to delegate authority, remaining in control aided by machine-based information and decision support. Proving capability, or trustworthiness, is a necessary component of certification. Perceived capability is a component of trust. Trustworthiness is an attribute of a cyber-physical system that requires context-driven metrics to prove and certify. Trust is an attribute of the agents participating in the system and is gained over time and multiple interactions through trustworthy behavior and transparency. Historically, artificial intelligence and machine learning systems provide answers without explanation – without a rationale or insight into the machine “thinking”. In order to function as trusted teammates, machines must be able to explain their decisions and actions. This transparency is a product of both content and communication. NASA’s Autonomy Teaming & TRAjectories for Complex Trusted Operational Reliability (ATTRACTOR) project seeks to build a basis for certification of autonomous systems via establishing metrics for trustworthiness and trust in multi-agent team interactions, using AI explainability and persistent modeling and simulation, in the context of mission planning and execution, with analyzable trajectories. Inspired by Massively Multiplayer Online Role Playing Games (MMORPG) and Serious Gaming, the proposed ATTRACTOR modeling and simulation environment is similar to online gaming environments in which player (aka agent) participants interact with each other, affect their environment, and expect the simulation to persist and change regardless of any individual agent’s active participation. This persistent simulation environment will accommodate individual agents, groups of self-organizing agents, and large-scale infrastructure behavior. The effects of the emerging adaptation and co-evolution can be observed and measured to building a basis of measurable trustworthiness and trust, toward certification of safety-critical autonomous systems. © 2018, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.;
-;-;
Author;Schmitt, F., Schulte, A.;
Title;Experimental evaluation of a scalable mixed-initiative planning associate for future military helicopter missions;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050337471&doi=10.1007%2f978-3-319-91122-9_52&partnerID=40&md5=1402cb25acee59d80b45265fe80530ce;
-;-;
DOI;DOI: 10.1007/978-3-319-91122-9_52;
Abstract;ABSTRACT: This article describes a scalable mixed-initiative planning concept, in which a human pilot is assisted during mission (re-)planning by an artificial planning agent. The agent serves as an additional team member and enables rapid planning and re-planning of multiple vehicles. For this purpose, the agent adapts its extent of assistance based on the necessity of the given situation. The concept was implemented for the use case of manned-unmanned teaming in future military helicopter missions. Thereby, the mixed-initiative agent was implemented with three different levels of automation. The article focuses on the experimental evaluation with German military helicopter pilots. Results show the advantages of the scalable mixed-initiative concept especially in time critical and high workload situations. © Springer International Publishing AG, part of Springer Nature 2018.;
-;-;
Author;Chen, J., Zhang, Q., Hou, B.;
Title;An assessment method of pilot workload in manned/unmanned-aerial-vehicles team;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049157105&doi=10.1109%2fICSPCC.2017.8242499&partnerID=40&md5=95f8849fdb93ad319ad793994f9ae6bf;
-;-;
DOI;DOI: 10.1109/ICSPCC.2017.8242499;
Abstract;ABSTRACT: In manned/unmanned-aerial-vehicles team, the workload of manned-aerial-vehicle (MAV) pilot is an important indicator to measure pilot's cognitive state. Evaluating the pilot workload is significant to analyze human-robotics system cognition and intelligent interaction questions. This paper proposed a mathematical model that can measure pilot workload. The model evaluates the workload through three factors: pilot utilization factor, unmanned-aerial-vehicle (UAV) request rate and the number of human-robotics interaction. Finally we simulated the model at five different levels of autonomy(LOA), proving the rationality of the model. © 2017 IEEE.;
-;-;
Author;Abrajano, G., Favila, C., Luo, C.Y., Trono, E., Lagazo, D., Sevilla, B., Honrado, J., Solpico, D., Yu, J., Chua, K., Mamaradlo, J., Jose, C., Yao, C.J., Dela Cruz, J., Ancheta, E., Domingo, A., Ong, J., Datuin, J., Yasumoto, K., Libatique, N., Tangonan, G.;
Title;Demonstrations of post-disaster resilient communications and decision-support platform with UAVs, ground teams and vehicles using delay-tolerant information networks on sub-GHz frequencies;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047755451&doi=10.1109%2fGHTC.2017.8239327&partnerID=40&md5=51c84f158fd30a7ce6bf7154ce1bdefa;
-;-;
DOI;DOI: 10.1109/GHTC.2017.8239327;
Abstract;ABSTRACT: We developed an approach to a resilient communications system for post-disaster situations that make use of cooperative missions involving multiple unmanned aerial vehicles (UAV), ground teams, and vehicle communication hubs (VHUB). In this paper, we will discuss how the communication system can operate even without relying on conventional communication networks such as the cellular network and Internet, which we assume may not be available in a post-disaster scenario, by using the concept of delay-tolerant networks (DTN). By using sub-GHz radio frequencies, we can also extend the range of transmission of responder nodes from several hundred meters to a few kilometers, allowing for the ground-to-ground and ground-to-sky communications. We will also discuss and demonstrate the components of the system and several applications on victim finding, rescue, and identification. Other key capabilities of the decision support node include mapping and visualization of disaster area and victim locations, information dissemination through ad-hoc broadcast messaging, and other disaster mobile kiosk applications. We envision the technical approach discussed in this paper to eventually be deployed in future post-disaster decision-support systems based on accurate situational awareness data. Maps, videos, and other post-disaster operational information will eventually be provided to partner organizations in an effective and timely manner. © 2017 IEEE.;
-;-;
Author;Tiwari, K., Jeong, S., Chong, N.Y.;
Title;Map-reduce Gaussian process (MR-GP) for multi-UAV based environment monitoring with limited battery;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044169239&doi=10.23919%2fSICE.2017.8105445&partnerID=40&md5=8a2158da2c440aff0512048e209b6312;
-;-;
DOI;DOI: 10.23919/SICE.2017.8105445;
Abstract;ABSTRACT: Environment monitoring is a challenging task owing to its ever changing dynamics. Furthermore, deploying a team of resource constrained robots to persistently monitor the environment encompasses intelligently selecting the training samples which are spread across a significantly large area to conservatively spend the resources allocated. In order to accomplish this using a team of fully autonomous self-reliant robots, we pose this problem as a map-reduce architecture: Map phase involves each individual member gathering its training samples and generating the best possible model of the environment followed by the Reduce phase where we merge all these models into a single globally consistent model to infer the environment dynamics. Our preliminary contributions to both these phases have shown significant ease to parallelize the process of gathering training samples whilst reducing the over-all model uncertainty. We demonstrated these results in a communication devoid simulated environment using publicly available datasets. © 2017 The Society of Instrument and Control Engineers - SICE.;
-;-;
Author;Gutzwiller, R.S., Reeder, J.;
Title;Human interactive machine learning for trust in teams of autonomous robots;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021390653&doi=10.1109%2fCOGSIMA.2017.7929607&partnerID=40&md5=666e9366628f63239cb899a8d4d33638;
-;-;
DOI;DOI: 10.1109/COGSIMA.2017.7929607;
Abstract;ABSTRACT: Unmanned systems are increasing in number, while their manning requirements remain the same. To decrease manpower demands, machine learning techniques and autonomy are gaining traction and visibility. One barrier is human perception and understanding of autonomy. Machine learning techniques can result in 'black box' algorithms that may yield high fitness, but poor comprehension by operators. However, Interactive Machine Learning (IML), a method to incorporate human input over the course of algorithm development by using neuro-evolutionary machine-learning techniques, may offer a solution. IML is evaluated here for its impact on developing autonomous team behaviors in an area search task. Initial findings show that IML-generated search plans were chosen over plans generated using a non-interactive ML technique, even though the participants trusted them slightly less. Further, participants discriminated each of the two types of plans from each other with a high degree of accuracy, suggesting the IML approach imparts behavioral characteristics into algorithms, making them more recognizable. Together the results lay the foundation for exploring how to team humans successfully with ML behavior. © 2017 IEEE.;
-;-;
Author;Shoval, S.;
Title;VolleyBot: A competative framework for AI and UAV research and development;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014287253&doi=10.1109%2fICSEE.2016.7806185&partnerID=40&md5=7d42cc5f5ba96f86813f2d354389f686;
-;-;
DOI;DOI: 10.1109/ICSEE.2016.7806185;
Abstract;ABSTRACT: This paper proposes a new setup for AI and UAV research and development, using the volleyball competition as a framework called VolleyBot. Similar to the way RoboCup is used for ground mobile robotic competition, VolleyBot offers a competitive setup for teams of small and medium sized unmanned aerial vehicles (UAVs), in particular quadrotors. In VolleyBot, two teams, separated by a net, are trying to score points by grounding a ball in the opposing team's court. Each player consists of a UAV that is equipped with a racket or a bat to handle the ball. Each UAV team member must be capable of intercepting the ball and operate at a high level of coordination and collaboration with other team members. VolleyBot offers a common task for evaluating theories, algorithms, designs, and implementations of multi-UAV systems. The VolleyBot setup is a dynamic challenging competitive environment that advances UAV researchers and users. © 2016 IEEE.;
-;-;
Author;Imhof, B., Hogle, M., Davenport, B., Weiss, P., Urbina, D., Røyrvik, J., Vögele, T., Parro, V., Nottle, A.;
Title;Project Moonwalk: Lessons learnt from testing human robot collaboration scenarios in a lunar and Martian simulation;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051550035&partnerID=40&md5=63e5ef1979d529877fa2045ab91deb66;
-;-;
Abstract;ABSTRACT: There is a global interest to send humans to the moon and to Mars and diverse early preparations are underway. One important aspect in preparing for future challenges is to develop technologies and tools that can help in simulation activities to train for future missions. Humans will be supported by robots on their missions in exploring and conducting science on extra-terrestrial surfaces. The paper summarizes all the efforts undertaken by six European partners as part of a research and technology project in the European Union’s Space Framework Programme. Under the lead of the DFKI (German Centre for Artificial Intelligence), industry partners Comex - France, Airbus Group UK, Space Applications Services - Belgium, LIQUIFER Systems Group - Austria and the research institutions NTNU – Norway (Samfunnsforsking, Centre for Interdisciplinary Research in Space) and INTA (Centro de Astrobiologia) – Spain collaborated to develop simulation hardware (space simulation suit, assistant rover) and tools (communications system, sampling) for human robot interaction. The general objective of MOONWALK was to enhance European capabilities for future human space exploration, especially surface Extra-Vehicular Activity (EVA) for the moon and Mars. This was targeted through research, development and evaluation of operations concepts and technologies for exploration and exobiology-related EVA tasks, focusing on human-robot collaboration and the development of earth-analogue simulation equipment. During a two-week simulation campaign conducting Martian scenarios, in Rio Tinto, Spain, a simulation astronaut and assistant rover collaborated as partners in mapping, surveying and sampling activities. Rio Tinto is an internationally recognized Martian analogue, having extremophile life similar to that on Mars, due to the pronounced mineral content of the region and the bacterial that feeds upon it. SHEE, the first European self-deployable simulation habitat, served as local mission control, and as ingress/egress for the suited astronaut. Lunar simulations were conducted in a depth of 10-metres, off the coast of Marseilles in open sea, and added to both which additional to the logistic challenge added a psychological challenge. Mission control for both analogues, was located near Brussels. The paper will describe the set-up, components, the analysis and validation of the performed analogue missions with respect to technical and human factors. A dataset comprising of 120 variables, 75 responses and 14 respondents was analysed. Additionally, an open question survey was collected, 52 lessons learned, including many comments about components. Data was gathered from 28 different EVAs, comparing an astronaut-astronaut team versus the astronaut-robot team in terms of performance and psychological impact. Copyright © 2017 by the International Astronautical Federation (IAF). All rights reserved.;
-;-;
Author;Miller, M.J., Pittman, C.W., Feigh, K.M.;
Title;Next-generation human extravehicular spaceflight operations support systems development;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051367158&partnerID=40&md5=513978bf523451d3617bc06967820c0c;
-;-;
Abstract;ABSTRACT: This paper presents the research, design, and development efforts aimed at constructing next generation software that supports human extravehicular activity (EVA), commonly known as a spacewalk. EVA operations today rely on an extensive team of Earth-based flight controllers who actively monitor and direct EVA progress while maintaining crew and vehicle safety. However, future deep-space mission destinations will impose round-trip communication delays. In the case of Mars, round-trip delays range from 8 to 40 minutes. As a result, astronauts will need to rely on local decision support systems (DSS) to make tactical decisions during execution without Earth-based support personnel. This paper first presents the content, structure and form of existing EVA support systems that were leveraged as source material for prototype development. Then detailed descriptions of the engineering specifications and design features are provided of the two prototypes, (Baseline and Advanced), that were built. Finally, the phases software development and corresponding architectures are discussed. As a result of this effort, this study was able to harness the rapid prototyping capabilities and broad platform support of modern web technologies to iterate on designs and successfully deploy a high fidelity system to controlled laboratory simulations and NASA analog research sites. The results of this work provide an empirically derived set of design solutions to guide the future of EVA operational support systems for future human spaceflight missions. © 2017 by the International Astronautical Federation. All rights reserved.;
-;-;
Author;Das, A.N., Doelling, K., Lundberg, C., Sevil, H.E., Lewis, F.;
Title;A Mixed reality based hybrid swarm control architecture for manned-unmanned teaming (MUM-T);
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040928941&doi=10.1115%2fIMECE2017-72076&partnerID=40&md5=e1bd6d87f514aa47a7378a3f0792a67e;
-;-;
DOI;DOI: 10.1115/IMECE2017-72076;
Abstract;ABSTRACT: Recent advancements in robotics have established standard control and planning algorithms for robot localization, navigation, and manipulation, which extend the automation from skill-based to rule-based. Such automation approaches, however, are susceptible to environmental dynamics and the burden of corresponding event handling falls on the human operator. In multi-agent systems, any deviation from the otherwise inefficient one operator to one robot mapping can result in an exponential growth of system complexity, and, in the absence of some form of artificial intelligence supervisory control, the overall framework can quickly become unmanageable, counterproductive, and even hazardous. Therefore, for future mannedunmanned teaming, a knowledge-based cooperative control architecture is warranted that can process cognitive reasoning at the meta-level to autonomously carry out some or all tactical parts of the mission while maintaining constant connection with the human operator. Furthermore, in such a scenario, the human operator needs to be able to communicate with multiple robotic agents via natural language and gesture interface so that he/she can efficiently manage not just one robot but the entire swarm or at least a segment. This paper will discuss a hybrid swarm autonomy architecture to coordinate a diverse team of robots using an immersive and intuitive interface technology for cooperative control of unmanned platforms. This novel interactive interface will offer situational awareness and decision presentation capabilities. Implemented through a real time, networked, mixed reality environment, it will be designed to support rapid exploration and evaluation with the swarm as well as dynamic interaction among different human operators. One of the major objectives of this research is to reduce cognitive load on operators and enable trust among robots and humans. This paper will discuss the approach to design and evaluate a distributed trust control algorithm for high-throughput hybrid swarm autonomy, and implement it through a curated, controlled-access portal to integrate swarm algorithms and collective behavior. Major discussion points will include: customization of unmanned platforms for distributed control and sensor fusion, development and implementation of a mixed reality human robot interface portal, and incorporation of a neuro-cognitive dynamic trust controller for swarm autonomy. It is envisioned that through such interconnection between humans and robots the effectiveness of the swarm can be boosted to carry out the missions with unprecedented speed and accuracy at a fraction of the cost for complex systems. This paper presents experimental validation to the analytical models involving real and virtual platforms. Copyright © 2017 ASME.;
-;-;
Author;Odonkor, P., Ball, Z., Chowdhury, S.;
Title;A distributed intelligence approach to using collaborating unmanned aerial vehicles for oil spill mapping;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034788513&doi=10.1115%2fDETC2017-68320&partnerID=40&md5=3e22373799d976dbe0f3d4508e6b7652;
-;-;
DOI;DOI: 10.1115/DETC2017-68320;
Abstract;ABSTRACT: From swarming locusts to schools of fish, the complex emergent behaviors exhibited by multi-agent swarm systems in nature present a compelling basis for their application towards real-world challenges. This paper capitalizes on this potential by proposing a swarm-intelligence inspired approach towards mapping complex offshore oil spills - one that uses a collaborating team of small (inexpensive) unmanned aerial vehicles. By leveraging the idea of occupancy grids, a new probability map concept is developed to enable agent-level situational awareness, while significantly reducing computing overheads (image data to intelligence generation in 1 sec) and communication overheads ( 1.7 KB of average data sharing across the swarm agents). The probability map is further exploited for waypoint planning using the principles of swarm dynamics and a rule-based reasoning approach to allow for dynamic preference shifts towards map exploitation and exploration. Detection of oil is performed by using a generalizable concept of anomaly detection that is derived from a color-based segmentation approach. Two simulated case studies, derived from actual oil spill images, are presented with results highlighting the strengths of the proposed approach. © Copyright 2017 ASME.;
-;-;
Author;Santos, R.M., Orozco, J., Mosse, D., Petrucci, V., Ochoa, S.F., Meseguer, R.;
Title;Flying real-time network for disaster assistance;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031410237&doi=10.1007%2f978-3-319-67585-5_58&partnerID=40&md5=5e9af4b024b8be20ea3782109fb06c55;
-;-;
DOI;DOI: 10.1007/978-3-319-67585-5_58;
Abstract;ABSTRACT: Landslides and large floods are serious natural disasters that every year cause multiple deaths and loss in property around the world. When these events occur in areas like the “favelas” or mountain regions in coastal cities like Rio de Janeiro, the situation becomes critical as buildings and infrastructures are not prepared to withstand them. Search and rescue teams in such disaster areas need to rely on real-time communication, which often cannot be adequately provided by cell or radio networks. In this paper, we argue that flying ad-hoc networks can provide the support needed in these scenarios and propose a new solution towards that goal, termed Flying Witness Units. We make our case by presenting real-time schedulability analysis of message delivery for a disaster scenario. © 2017, Springer International Publishing AG.;
-;-;
Author;Ruf, C., Stütz, P.;
Title;Model-driven sensor operation assistance for a transport helicopter crew in manned-unmanned teaming missions: Selecting the automation level by machine decision-making;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986309355&doi=10.1007%2f978-3-319-41959-6_21&partnerID=40&md5=b54e59c7e604766ddde253d2d3b504ce;
-;-;
DOI;DOI: 10.1007/978-3-319-41959-6_21;
Abstract;ABSTRACT: One of the research fields at the Institute of Flight Systems (IFS) of the University of the Armed Forces (UniBwM) focuses on the integration of reconnaissance sensor operation support in manned-unmanned teaming (MUM-T) helicopter missions. The purposive deployment of mission sensors carried by a team of unmanned aerial vehicles (multi-UAV) in such missions is expected to bring in new and impactful aspects, especially in workload-intensive situations. Paradigms of variable automation in the sensor domain and cognitive assistant systems are intended to achieve an operationally manageable solution. This paper provides an overview of the sensor assistant system to be deployed in a MUM-T setup. To manage sensor deployment automation functions, a machine decision making process represented by an agent system will be described. Depending on a workload state input, a suitable level of automation will be chosen from a predefined set. A prototype system of such agent with its capability to react on varied stimuli will be demonstrated in a reduced toy problem setup. © Springer International Publishing Switzerland 2017.;
-;-;
Author;Chen, J., Xu, J., Ding, L., Zhong, L.;
Title;Limited intervention collaborative decision-making of MAV/UAV team based on FCM;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006855459&doi=10.1109%2fICSPCC.2016.7753683&partnerID=40&md5=a8e4d2c825177bb2e2e43ae46a1fedcd;
-;-;
DOI;DOI: 10.1109/ICSPCC.2016.7753683;
Abstract;ABSTRACT: In order to exert the autonomy of Unmanned Aerial Vehicle's(UAV) decision-making, based on fuzzy cognitive map (FCM), UAV's autonomous decision-making model is established. However, when UAV cannot make certain decision because of self-limiting, Manned Aerial Vehicle(MAV) will make intervention. Thus this paper designs three levels of limited intervention collaborative decision-making mechanism. By adding auxiliary decision information or adjusting decision threshold, MAV can help UAV make a new decision. This type of decision-making mechanism not only plays full use of UAV's autonomy, but also reduces MAV's control burden, decreases the frequent communication in decision-making process, which is very suitable for increasingly complex battlefield environment. Simulation indicates that limited intervention collaborative decision-making of MAV/UAV team is reasonable and feasible. © 2016 IEEE.;
-;-;
Author;Rao, G.N., Rao, P.J., Duvvuru, R.;
Title;A Drone Remote Sensing for Virtual Reality Simulation System for Forest Fires: Semantic Neural Network Approach;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995607491&doi=10.1088%2f1757-899X%2f149%2f1%2f012011&partnerID=40&md5=84bfa32e661f750fac49f0704086bfb8;
-;-;
DOI;DOI: 10.1088/1757-899X/149/1/012011;
Abstract;ABSTRACT: Wild fires have significant impact on atmosphere and lives. The demand of predicting exact fire area in forest may help fire management team by using drone as a robot. These are flexible, inexpensive and elevated-motion remote sensing systems that use drones as platforms are important for substantial data gaps and supplementing the capabilities of manned aircraft and satellite remote sensing systems. In addition, powerful computational tools are essential for predicting certain burned area in the duration of a forest fire. The reason of this study is to built up a smart system based on semantic neural networking for the forecast of burned areas. The usage of virtual reality simulator is used to support the instruction process of fire fighters and all users for saving of surrounded wild lives by using a naive method Semantic Neural Network System (SNNS). Semantics are valuable initially to have a enhanced representation of the burned area prediction and better alteration of simulation situation to the users. In meticulous, consequences obtained with geometric semantic neural networking is extensively superior to other methods. This learning suggests that deeper investigation of neural networking in the field of forest fires prediction could be productive. © Published under licence by IOP Publishing Ltd.;
-;-;
Author;Chen, J., Xu, J., Zhong, L.;
Title;Limited intervention collaborative decision making of MAV-UAV team based on VFCM;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989945210&doi=10.1109%2fSCC.2016.128&partnerID=40&md5=a223407cfb23354c22ac90d272d86bbf;
-;-;
DOI;DOI: 10.1109/SCC.2016.128;
Abstract;ABSTRACT: In view of complex battlefield environment and technological factors, unmanned aerial vehicle's (UAV) decision-making cannot accurately reflect battlefield situation and make reasonable decisions by itself. To solve this problem, this paper presents a limited intervention collaborative decision-making mechanism between manned aerial vehicle(MAV) and UAV based on visualising fuzzy cognitive map (VFCM). By use of limited intervention trigger strategy, high efficiency and feasibility of decision-making can be ensured. Simulation indicates that limited intervention collaborative decision making of the MAV/UAV team is reasonable and feasible. © 2016 IEEE.;
-;-;
Author;Mercado, J.E., Rupp, M.A., Chen, J.Y.C., Barnes, M.J., Barber, D., Procci, K.;
Title;Intelligent Agent Transparency in Human-Agent Teaming for Multi-UxV Management;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962858665&doi=10.1177%2f0018720815621206&partnerID=40&md5=35875abe1b5422ca7b143c29a32ba671;
-;-;
DOI;DOI: 10.1177/0018720815621206;
Abstract;ABSTRACT: Objective: We investigated the effects of level of agent transparency on operator performance, trust, and workload in a context of human-agent teaming for multirobot management. Background: Participants played the role of a heterogeneous unmanned vehicle (UxV) operator and were instructed to complete various missions by giving orders to UxVs through a computer interface. An intelligent agent (IA) assisted the participant by recommending two plans - a top recommendation and a secondary recommendation - for every mission. Method: A within-subjects design with three levels of agent transparency was employed in the present experiment. There were eight missions in each of three experimental blocks, grouped by level of transparency. During each experimental block, the IA was incorrect three out of eight times due to external information (e.g., commander's intent and intelligence). Operator performance, trust, workload, and usability data were collected. Results: Results indicate that operator performance, trust, and perceived usability increased as a function of transparency level. Subjective and objective workload data indicate that participants' workload did not increase as a function of transparency. Furthermore, response time did not increase as a function of transparency. Conclusion: Unlike previous research, which showed that increased transparency resulted in increased performance and trust calibration at the cost of greater workload and longer response time, our results support the benefits of transparency for performance effectiveness without additional costs. Application: The current results will facilitate the implementation of IAs in military settings and will provide useful data to the design of heterogeneous UxV teams. © 2015 Human Factors and Ergonomics Society.;
-;-;
Author;Fan, Y., Ma, J., Wang, G., Li, T.;
Title;Design of a heterogeneous marsupial robotic system composed of an USV and an UAV;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966470178&doi=10.1109%2fICACI.2016.7449858&partnerID=40&md5=7a081fdd4d5967b20ee5e999e7a63f75;
-;-;
DOI;DOI: 10.1109/ICACI.2016.7449858;
Abstract;ABSTRACT: This paper provides both the core ideas of a heterogeneous marsupial robotic System and the details of the practical aspects related to its hardware architecture and cooperative system structure. This heterogeneous marsupial robotic system is composed by an unmanned surface vehicle (USV) that acts as a carrier and an unmanned aerial vehicle (UAV) that acts as a passenger, and it is designed for military tasks and other tasks like environmental monitoring, wild life tracking, and search & rescue missions. Through the combination, the cooperative marsupial robots benefit from their heterogeneity by using the superiority of each team member and overcoming their limitations. Moreover, the attitude control simulation model of the UAV is built, and the self-adaptive fuzzy parameter tuning rules for PID flight controller are given, so as to realize the online self-tuning of the controller parameters. Simulation results show that: compared with the conventional PID controller, this attitude control algorithm of fuzzy self-adaptive PID has a better dynamic response performance. © 2016 IEEE.;
-;-;
Author;Hansen, M., Calhoun, G., Douglass, S., Evans, D.;
Title;Courses of action display for multi-unmanned vehicle control: A multi-disciplinary approach;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025808545&partnerID=40&md5=86b4a7772ca527fbe91a567cd2714c5f;
-;-;
Abstract;ABSTRACT: Operational concepts in which a single operator teams with multiple autonomous vehicles are now considered feasible due to advances in automation technology. This will require that an operator be able to express a high-level intent, or goal, to the vehicle team rather than direct the actions of individual assets. Successful operator-autonomy collaboration must quickly capture the operator's intent and then portray the autonomy's trade-offs between different courses of action in an intuitive interface. This paper describes how a multi-disciplinary effort was employed in the design of a display that highlights the trade-off of autonomy-generated plans and supports the efficient allocation of assets to surveillance tasks. Our novel control station approach combines domain modeling and multi-objective optimization with innovative interfaces to enable a single operator to effectively command a team of unmanned vehicles. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;
-;-;
Author;Pilz, N.A., Kreil, M., Kron, M., Mitrofanow, A., Garcia, M., More, N.;
Title;Commercial support services for microgravity experiments on parabolic flights;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016494418&partnerID=40&md5=89f98eea011614687ab23a4aa447b75a;
-;-;
Abstract;ABSTRACT: The Berlin based company Blue Sky Solutions was founded as a spin-off from its partner company AI: Aerospace Institute in order to provide commercial launch services for small satellites as well as support services for microgravity experiments on aircraft parabolic flights. Aircraft parabolic flights are a very useful tool for performing short duration microgravity investigations in the field of physics, life sciences, and space technology as well as space flight simulations including the training of astronauts before a space mission. The main advantages of parabolic flights for micrograv-ity investigations are the short turn-around time between the experiment proposal and its performance, the reliability of the campaign dates, the flexibility of the experimental approach, the possibility of direct intervention by investigators on-board the aircraft during and between parabolas as well as the possibility of modifying the experiment set-up between flights. Against the background of verifying different space technologies under microgravity conditions, the team members of Blue Sky Solutions have performed on a regular basis several parabolic flight campaigns on the European aircraft Airbus Zero-G in cooperation with the German Aerospace Center DLR. The flown experiments comprised microgravity testing of different experimental breadboard models for a net capture based active debris removal system as well as several test model configurations of separation mechanisms for small satellites. During these campaigns, which included very large experiment rack structures and heavy free floating objects, the team members of Blue Sky Solutions have experienced a total number of over 680 parabolas, equaling an accumulated flight time in microgravity of more than 4 hours. Based on its own parabolic flight experience, Blue Sky Solutions provides to worldwide industry customers and members of the scientific community an attractive all-round carefree package to perform their microgravity experiment successfully on a parabolic flight campaign. The support services by Blue Sky Solutions completely cover not only the experiment design and all related safety aspects, but also the entire mandatory documentation. Experiments to be performed and all equipment to be installed on-board the Zero-G aircraft are carefully designed by qualified engineers from a structural, mechanical, electrical, safety and operational point of view and reviewed by experts several months before the campaign in order to be compliant with all experiment design requirements. In addition, special precautions are taken to ensure that all operations during flights are conducted safely and that flying experimenters are adequately prepared for the repeated high and low gravity environments. Copyright © 2016 by the International Astronautical Federation (IAF). All rights reserved.;
-;-;
Author;Baker, C.A.B., Ramchurn, S., Teacy, W.T.L., Jennings, N.R.;
Title;Planning search and rescue missions for UAV teams;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013102486&doi=10.3233%2f978-1-61499-672-9-1777&partnerID=40&md5=892f002c9bd6be708790e2ea9669aec5;
-;-;
DOI;DOI: 10.3233/978-1-61499-672-9-1777;
Abstract;ABSTRACT: The coordination of multiple Unmanned Aerial Vehicles (UAVs) to carry out aerial surveys is a major challenge for emergency responders. In particular, UAVs have to fly over kilometre-scale areas while trying to discover casualties as quickly as possible. To aid in this process, it is desirable to exploit the increasing availability of data about a disaster from sources such as crowd reports, satellite remote sensing, or manned reconnaissance. In particular, such information can be a valuable resource to drive the planning of UAV flight paths over a space in order to discover people who are in danger. However challenges of computational tractability remain when planning over the very large action spaces that result. To overcome these, we introduce the survivor discovery problem and present as our solution, the first example of a continuous factored coordinated Monte Carlo tree search algorithm. Our evaluation against state of the art benchmarks show that our algorithm, Co-CMCTS, is able to localise more casualties faster than standard approaches by 7% or more on simulations with real-world data. © 2016 The Authors and IOS Press.;
-;-;
Author;Ahmed, N.;
Title;Collaborative autonomous sensing with Bayesians in the loop;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010805025&doi=10.1117%2f12.2246705&partnerID=40&md5=99a6c1d502bdf526e8c40bc795dbb1af;
-;-;
DOI;DOI: 10.1117/12.2246705;
Abstract;ABSTRACT: There is a strong push to develop intelligent unmanned autonomy that complements human reasoning for applications as diverse as wilderness search and rescue, military surveillance, and robotic space exploration. More than just replacing humans for 'dull, dirty and dangerous' work, autonomous agents are expected to cope with a whole host of uncertainties while working closely together with humans in new situations. The robotics revolution firmly established the primacy of Bayesian algorithms for tackling challenging perception, learning and decision-making problems. Since the next frontier of autonomy demands the ability to gather information across stretches of time and space that are beyond the reach of a single autonomous agent, the next generation of Bayesian algorithms must capitalize on opportunities to draw upon the sensing and perception abilities of humans-in/on-the-loop. This work summarizes our recent research toward harnessing 'human sensors' for information gathering tasks. The basic idea behind is to allow human end users (i.e. non-experts in robotics, statistics, machine learning, etc.) to directly 'talk to' the information fusion engine and perceptual processes aboard any autonomous agent. Our approach is grounded in rigorous Bayesian modeling and fusion of flexible semantic information derived from user-friendly interfaces, such as natural language chat and locative hand-drawn sketches. This naturally enables 'plug and play' human sensing with existing probabilistic algorithms for planning and perception, and has been successfully demonstrated with human-robot teams in target localization applications. © 2016 SPIE.;
-;-;
Author;Wu, F., Ramchurn, S.D., Chen, X.;
Title;Coordinating human-UAV teams in disaster response;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006160265&partnerID=40&md5=121cfad19e1153785fee9d148c1a7b96;
-;-;
Abstract;ABSTRACT: We consider a disaster response scenario where emergency responders have to complete rescue tasks in dynamic and uncertain environment with the assistance of multiple UAVs to collect information about the disaster space. To capture the uncertainty and partial observability of the domain, we model this problem as a POMDP. However, the resulting model is computationally intractable and cannot be solved by most existing POMDP solvers due to the large state and action spaces. By exploiting the problem structure we propose a novel online planning algorithm to solve this model. Specifically, we generate plans for the responders based on Monte-Carlo simulations and compute actions for the UAVs according to the value of information. Our empirical results confirm that our algorithm significantly outperforms the state-of-the-art both in time and solution quality.;
-;-;
Author;Monfort, S.S., Sibley, C.M., Coyne, J.T.;
Title;Using machine learning and real-time workload assessment in a high-fidelity UAV simulation environment;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989344908&doi=10.1117%2f12.2219703&partnerID=40&md5=63710a410ffaaf7fd2267d1b482eb095;
-;-;
DOI;DOI: 10.1117/12.2219703;
Abstract;ABSTRACT: Future unmanned vehicle operations will see more responsibilities distributed among fewer pilots. Current systems typically involve a small team of operators maintaining control over a single aerial platform, but this arrangement results in a suboptimal configuration of operator resources to system demands. Rather than devoting the full-time attention of several operators to a single UAV, the goal should be to distribute the attention of several operators across several UAVs as needed. Under a distributed-responsibility system, operator task load would be continuously monitored, with new tasks assigned based on system needs and operator capabilities. The current paper sought to identify a set of metrics that could be used to assess workload unobtrusively and in near real-time to inform a dynamic tasking algorithm. To this end, we put 20 participants through a variable-difficulty multiple UAV management simulation. We identified a subset of candidate metrics from a larger pool of pupillary and behavioral measures. We then used these metrics as features in a machine learning algorithm to predict workload condition every 60 seconds. This procedure produced an overall classification accuracy of 78%. An automated tasker sensitive to fluctuations in operator workload could be used to efficiently delegate tasks for teams of UAV operators. © 2016 SPIE.;
-;-;
Author;Voshell, M., Tittle, J., Roth, E.;
Title;Multi-level human-autonomy teams for distributed mission management;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980030886&partnerID=40&md5=2b317153fa6ef08341790b13e116c3a4;
-;-;
Abstract;ABSTRACT: Control of the air in envisioned large-scale battles against near-peer adversaries will require revolutionary new approaches to airborne mission management, where decision authority and platform autonomy are dynamically delegated and functional roles and combat capabilities are assigned across multiple distributed tiers of platforms and human operators. System capabilities range from traditional airborne battle managers, to manned tactical aviators, to autonomous unmanned aerial systems. Due to the overwhelming complexity, human operators will require the assistance of advanced autonomy decision aids with new mechanisms for operator supervision and management of teams of manned and unmanned systems. In this paper we describe a conceptual distributed mission management approach that employs novel human-automation teaming constructs to address the complexity of envisioned operations in highly contested environments. We then discuss a cognitive engineering approach to designing role- and task-tailored human machine interfaces between humans and the autonomous systems. We conclude with a discussion of multi-level evaluation approaches for experimentation. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;
-;-;
Author;Kosmatin Fras, M., Grigillo, D.;
Title;Implementation of active teaching methods and emerging topics in photogrammetry and remote sensing subjects;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979501924&doi=10.5194%2fisprsarchives-XLI-B6-87-2016&partnerID=40&md5=fb252e7ffe4170c6dcc2fc50c627dc56;
-;-;
DOI;DOI: 10.5194/isprsarchives-XLI-B6-87-2016;
Abstract;ABSTRACT: Fast technological developments in photogrammetry and remote sensing areas demand quick and steady changes in the education programme and its realization. The university teachers and assistants are faced with ensuring the learning materials, data and software for practical lessons, as well as project proposals for student's team work and bachelor or master thesis. In this paper the emerging topics that already have a considerable impact in the practice are treated mostly from the educational aspect. These relatively new topics that are considered in this paper are unmanned aerial systems for spatial data collection, terrestrial and aerial laser scanning, mobile mapping systems, and novelties in satellite remote sensing. The focus is given to practical implementation of these topics into the teaching and learning programme of Geodesy and Geoinformation at the University of Ljubljana, Faculty of Civil and Geodetic Engineering, and experiences gained by the authors so far. Together with the technological advances, the teaching approaches must be modernized as well. Classical approaches of teaching, where a lecturer gives lecture ex cathedra and students are only listeners, are not effective enough. The didactics science of teaching has developed and proved in the practice many useful approaches that can better motivate students for more active learning. We can use different methods of team work like pro et contra debate, buzzing groups, press conference, moderated discussion etc. An experimental study on active teaching methods in the class of students of the Master programme of Geodesy and Geoinformation has been made and the results are presented. After using some new teaching methods in the class, the students were asked to answer two types of a questionnaire. First questionnaire was the standard form developed by Noel Entwistle, an educational psychologist who developed the Approaches to Studying Inventory (ASI) for identifying deep and surface approaches to learning. The second questionnaire was developed for our purpose to get the feedback from students on active teaching and learning methods. Although this investigation has been done only for one class of master programme students, the results are encouraging and we could extract some recommendations for the future.;
-;-;
Author;McNeese, N.J., Cooke, N.J.;
Title;Team cognition as a mechanism for developing collaborative and proactive decision support in remotely piloted aircraft systems;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978909360&doi=10.1007%2f978-3-319-39952-2_20&partnerID=40&md5=9dda8a397d4952d0945c1ed4fdc5f00e;
-;-;
DOI;DOI: 10.1007/978-3-319-39952-2_20;
Abstract;ABSTRACT: Remotely piloted aircraft systems (RPAS) are steadily increasing in their presence and role in the Military’s overall strategic operational picture. The benefits of RPAS are apparent, ranging from saving time, money, and lives. Yet, the utilization of RPAS is still very challenging in many different aspects. Teams have become a central focus of RPAS due to their many benefits. Yet, teamwork is challenging and the RPAS community must continue to attempt to understand how to support it. A specific aspect of teamwork that has proven over the years to be of paramount importance is team cognition. In this paper, we discuss how team cognition needs to be considered during the development of collaborative and proactive RPAS decision support. We highlight the concept of team cognition accounting for multiple perspectives, outline an integrative perspective of team cognition for the RPAS domain, and conclude by outlining multiple design objectives for utilizing team cognition as a mechanism for RPAS decision support. © Springer International Publishing Switzerland 2016.;
-;-;
Author;Gutzwiller, R.S., Lange, D.S.;
Title;Tasking teams: Supervisory control and task management of autonomous unmanned systems;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978882436&doi=10.1007%2f978-3-319-39907-2_38&partnerID=40&md5=2e668165a3997563aaa72351c8eefe93;
-;-;
DOI;DOI: 10.1007/978-3-319-39907-2_38;
Abstract;ABSTRACT: How does one collaborate with and supervise a team? Here, we discuss a novel interface for managing tasks, developed as part of a multi-heterogeneous unmanned systems testbed, that aids cognitive operations and teaming. Existing models of team effectiveness among humans can frame cooperative teaming of computer agents and human supervisors. We use the three main characteristics of the input – process – output model to frame discussions of the task manager interface as a potential teaming facilitator, finding it should facilitate effectiveness on several elements. We conclude with the expectation of examination and support from future experiments. © Springer International Publishing Switzerland 2016.;
-;-;
Author;Sanchez-Garcia, J., Garcia-Campos, J.M., Toral, S.L., Reina, D.G., Barrero, F.;
Title;An Intelligent Strategy for Tactical Movements of UAVs in Disaster Scenarios;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962641658&doi=10.1155%2f2016%2f8132812&partnerID=40&md5=41303bfc78815145cd00d3ce7f8447c6;
-;-;
DOI;DOI: 10.1155/2016/8132812;
Abstract;ABSTRACT: Unmanned Aerial Vehicles (UAVs) are envisioned as flexible and fast-deploying communication network for disaster scenarios, where the typical communication infrastructure is likely to be malfunctioning. A few works propose UAVs for building communication links autonomously between rescue team's members in disaster scenarios. The techniques used are usually based on navigation, positioning, and signal strength processing. However, these techniques may not be enough if the objective is to provide communication services to the maximum number of victims and rescuers and not only to a few rescuers. In this situation, dissimilarity metrics, like the Jaccard distance, can provide information about whether the communication service provided to victims is efficient or not (e.g., providing a better distribution of the victims assigned to each UAV acting as service provider). We propose an intelligent strategy that allows UAVs to perform tactical movements in a disaster scenario, combining the Jaccard distance and artificial intelligence algorithms like hill climbing and simulated annealing. Our strategy maximizes the number of victims that are serviced by the UAVs while avoiding network disconnections. Also, a mobility model specifically developed for modelling the victims' movements within the incident site of a disaster scenario is proposed. © 2016 J. Sanchez-Garcia et al.;
-;-;
Author;Lee, H.S., Oh, J.H., Lee, B.H.;
Title;Design and implementation for multiple-robot deployment in intelligent space;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952885447&doi=10.1109%2fETFA.2015.7301549&partnerID=40&md5=0c6f6155c1c731faa9b3a7938c784c16;
-;-;
DOI;DOI: 10.1109/ETFA.2015.7301549;
Abstract;ABSTRACT: This paper presents the problem of robot deployment for a number of scattered tasks. We aim to minimize the duration it takes for all robots to reach their assigned task locations. In previous work, we have proposed a team composed of one carrier robot (CR) and several servant robots to accomplish the mission. Then we have suggested an algorithm that determines a path of the CR for an efficient deployment under a few constraints, which is verified by simulations. Assuming that the servant robots are unmanned aerial vehicles (UAVs), the present paper extends the discussion to a real robot experiment. We design and implement a deployment system in intelligent space. The feasibility of the study is demonstrated through an experiment. © 2015 IEEE.;
-;-;
Author;Hu, X., Ma, H., Ye, Q., Luo, H.;
Title;Hierarchical method of task assignment for multiple cooperating UAV teams;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951757861&doi=10.1109%2fJSEE.2015.00109&partnerID=40&md5=fb7e02fd065696049a3340fc8b535801;
-;-;
DOI;DOI: 10.1109/JSEE.2015.00109;
Abstract;ABSTRACT: The problem of task assignment for multiple cooperating unmanned aerial vehicle (UAV) teams is considered. Multiple UAVs forming several small teams are needed to perform attack tasks on a set of predetermined ground targets. A hierarchical task assignment method is presented to address the problem. It breaks the original problem down to three levels of sub-problems: target clustering, cluster allocation and target assignment. The first two sub-problems are centrally solved by using clustering algorithms and integer linear programming, respectively, and the third sub-problem is solved in a distributed and parallel manner, using a mixed integer linear programming model and an improved ant colony algorithm. The proposed hierarchical method can reduce the computational complexity of the task assignment problem considerably, especially when the number of tasks or the number of UAVs is large. Experimental results show that this method is feasible and more efficient than non-hierarchical methods.;
-;-;
Author;Heitmeyer, C.L., Pickett, M., Leonard, E.I., Archer, M.M., Ray, I., Aha, D.W., Trafton, J.G.;
Title;Building high assurance human-centric decision systems;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925508179&doi=10.1007%2fs10515-014-0157-z&partnerID=40&md5=9011d38555016dd0c34d2fffb7c2572e;
-;-;
DOI;DOI: 10.1007/s10515-014-0157-z;
Abstract;ABSTRACT: Many future decision support systems will be human-centric, i.e., require substantial human oversight and control. Because these systems often provide critical services, high assurance is needed that they satisfy their requirements. This paper, the product of an interdisciplinary research team of experts in formal methods, adaptive agents, and cognitive science, addresses this problem by proposing a new process for developing high assurance human-centric decision systems. This process uses AI (artificial intelligence) methods—i.e., a cognitive model to predict human behavior and an adaptive agent to assist the human—to improve system performance, and software engineering methods—i.e., formal modeling and analysis—to obtain high assurance that the system behaves as intended. The paper describes a new method for synthesizing a formal system model from Event Sequence Charts, a variant of Message Sequence Charts, and a Mode Diagram, a specification of system modes and mode transitions. It also presents results of a new pilot study investigating the optimal level of agent assistance for different users in which the agent design was evaluated using synthesized user models. Finally, it reviews a cognitive model for predicting human overload in complex human-centric systems. To illustrate the development process and our new techniques, we describe a human-centric decision system for controlling unmanned vehicles. © 2014, Springer Science+Business Media New York.;
-;-;
Author;Venugopalan, T.K., Subramanian, K., Sundaram, S.;
Title;Multi-UAV task allocation: A team-based approach;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964958308&doi=10.1109%2fSSCI.2015.17&partnerID=40&md5=dee39e6c2a14542ee1db807bc76e595f;
-;-;
DOI;DOI: 10.1109/SSCI.2015.17;
Abstract;ABSTRACT: This paper presents a team-search based decentralized task allocation scheme for multiple homogeneous unmanned aerial vehicles (UAVs) to provide protection to static convoys of ground vehicles. The UAVs, during operation, protect the ground convoy by searching their vicinity for imminent threat, analyzing/ confirming threat level, attacking it and finally assessing the damage to confirm if the threat has been nullified. The proposed approach utilizes search maps to form a common information base for intelligent decision making. A decentralized scheme is developed based on team theory, wherein the best course of action for each UAV is selected to minimize resource use of the team. This scheme is generic enough to handle different types of UAVs and control technique and caters to a dynamic environment. The proposed convoy protection scheme is evaluated by software simulation with multi-UAV-multi-Targets. Different experiments were performed to analyze the efficacy of this approach. The performance comparison with greedy task allocation highlights the advantage of the proposed scheme. © 2015 IEEE.;
-;-;
Author;Recchiuto, C., Sgorbissa, A., Wanderlingh, F., Zaccaria, R.;
Title;UAV teams in emergency scenarios: A summary of the work within the project PRISMA;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964009651&partnerID=40&md5=bfca58cedd9583be20b9d73bf56fc755;
-;-;
Abstract;ABSTRACT: In recent years autonomous robots, and Unmanned Aerial Vehicles (UAVs) in particular, are becoming always more important in the context of emergency scenarios, being able to anticipate the actions of human operators and to support them during rescue operations. In this context, the investigation of strategies for the autonomous control of UAVs, for the development of Human-Swarm Interfaces and for the coverage of large areas is crucial. All these aspects have been analyzed within the Italian project PRISMA, and they will be here summarized. Copyright © 2015 for the individual papers by the papers' authors.;
-;-;
Author;Borck, H., Karneeb, J., Alford, R., Aha, D.W.;
Title;Case-based behavior recognition in beyond visual range air combat;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952006633&partnerID=40&md5=1ffea268681cad7f17863daa385f4c06;
-;-;
Abstract;ABSTRACT: An unmanned air vehicle (UAV) can operate as a capable team member in mixed human-robot teams if it is controlled by an agent that can intelligently plan. However, planning effectively in a beyond-visual-range air combat scenario requires understanding the behaviors of hostile agents, which is challenging in partially observable environments such as the one we study. In particular, unobserved hostile behaviors in our domain may alter the world state. To effectively counter hostile behaviors, they need to be recognized and predicted. We present a Case-Based Behavior Recognition (CBBR) algorithm that annotates an agent's behaviors using a discrete feature set derived from a continuous spatio-temporal world state. These behaviors are then given as input to an air combat simulation, along with the UAV's plan, to predict hostile actions and estimate the effectiveness of the given plan. We describe an implementation and evaluation of our CBBR algorithm in the context of a goal reasoning agent designed to control a UAV and report an empirical study that shows CBBR outperforms a baseline algorithm. Our study also indicates that using features which model an agent's prior behaviors can increase behavior recognition accuracy. Copyright © 2015, Association for the Advancement of Artificial Intelligence. All rights reserved.;
-;-;
Author;Stepanov, D., Bakhshiev, A., Gromoshinskii, D., Kirpan, N., Gundelakh, F.;
Title;Determination of the relative position of space vehicles by detection and tracking of natural visual features with the existing tv-cameras;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951871369&doi=10.1007%2f978-3-319-26123-2_41&partnerID=40&md5=730e8f3a7e91bbe09a546f003b344acd;
-;-;
DOI;DOI: 10.1007/978-3-319-26123-2_41;
Abstract;ABSTRACT: During spacecrafts maneuvers, especially at the rendezvous and docking stages, one of the most important tasks is to determine the relative positions of the vehicles. The current Russian “Course” and recently proposed ATV/HTV docking systems are complex and require mounting of specific cumbersome equipment on the outer sides of both vehicles. The proposed TV-based docking control system uses the existing cameras, “natural” visible features of the ISS and an ISS laptop to determine all six relative coordinates of the vehicles. At the training stage the ISS 3D-model and video recordings are used. This paper describes the algorithm flow and the problems of the passive, TV-only approach. The system efficiency is tested against models, mockups and the recordings of previous rendezvous of “Progress”, “Soyuz” and ATV spacecrafts. The nearest goal of the system is to become an independent docking control system helping the ground docking control team and the cosmonauts. © Springer International Publishing Switzerland 2015.;
-;-;
Author;Ramchurn, S.D., Fischer, J.E., Ikuno, Y., Wu, F., Flann, J., Waldock, A.;
Title;A study of human-agent collaboration for multi-UAV task allocation in dynamic environments;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949774896&partnerID=40&md5=3ccc3fa1b2ee64aa75244ecfe7df63af;
-;-;
Abstract;ABSTRACT: We consider a setting where a team of humans oversee the coordination of multiple Unmanned Aerial Vehicles (UAVs) to perform a number of search tasks in dynamic environments that may cause the UAVs to drop out. Hence, we develop a set of multi-UAV supervisory control interfaces and a multiagent coordination algorithm to support human decision making in this setting. To elucidate the resulting interactional issues, we compare manual and mixed-initiative task allocation in both static and dynamic environments in lab studies with 40 participants and observe that our mixed-initiative system results in lower workloads and better performance in re-planning tasks than one which only involves manual task allocation. Our analysis points to new insights into the way humans appropriate flexible autonomy.;
-;-;
Author;Love, J., Amai, W., Blada, T., Little, C., Neely, J., Buerger, S.;
Title;Enhanced physical security through a command-intent driven multi-agent sensor network;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947292616&doi=10.1007%2f978-3-319-20816-9_75&partnerID=40&md5=fd676251b769522172b7a4a2e6d64a00;
-;-;
DOI;DOI: 10.1007/978-3-319-20816-9_75;
Abstract;"ABSTRACT: Sandia’s Intelligent Systems, Robotics, and Cybernetics group (ISRC) created the Sandia Architecture for Heterogeneous Unmanned System Control (SAHUC) to demonstrate how heterogeneous multi-agent teams could be used for tactical operations including the protection of high-consequence sites. Advances in multi-agent autonomy and unmanned systems have provided revolutionary new capabilities that can be leveraged for physical security applications. SAHUC applies these capabilities to produce a command-intent driven, autonomously adapting, multi-agent mobile sensor network. This network could enhance the security of high-consequence sites; it can be quickly and intuitively re-tasked to rapidly adapt to changing security conditions. The SAHUC architecture, GUI, autonomy layers, and implementation are explored. Results from experiments and a demonstration are also discussed. © Springer International Publishing Switzerland 2015.";
-;-;
Author;Gutzwiller, R.S., Lange, D.S., Reeder, J., Morris, R.L., Rodas, O.;
Title;Human-computer collaboration in adaptive supervisory control and function allocation of autonomous system teams;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947223062&doi=10.1007%2f978-3-319-21067-4_46&partnerID=40&md5=f41d8915d8d30ad184c4136f2a3e5bda;
-;-;
DOI;DOI: 10.1007/978-3-319-21067-4_46;
Abstract;ABSTRACT: The foundation for a collaborative, man-machine system for adaptive performance of tasks in a multiple, heterogeneous unmanned system teaming environment is discussed. An autonomics system is proposed to monitor missions and overall system attributes, including those of the operator, autonomy, states of the world, and the mission. These variables are compared within a model of the global system, and strategies that re-allocate tasks can be executed based on a mission-health perspective (such as relieving an overloaded user by taking over incoming tasks). Operators still have control over the allocation via a task manager, which also provides a function allocation interface, and accomplishes an initial attempt at transparency. We plan to learn about configurations of function allocation from human-in-the-loop experiments, using machine learning and operator feedback. Integrating autonomics, machine learning, and operator feedback is expected to improve collaboration, transparency, and human-machine performance. © Springer International Publishing Switzerland 2015.;
-;-;
Author;Dobbins, T., Hill, J., Thompson, T., McCartan, S., Brand, T., Smoker, A.;
Title;Human-centred, scalable, combat system design for littoral operations;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947080788&partnerID=40&md5=249b4cbf9785877177140b1072b2cc8a;
-;-;
Abstract;ABSTRACT: Combat operations in the littoral and amphibious environments present unique challenges to both the warfighters, and the system designers. High-tempo navigation, in shallow / congested waters, and in degraded visual environments, increases the stresses on the individuals and teams before combat related tasks are considered. All combat tasks require the crew, and the crafts systems, to have the appropriate level of situation awareness and decision making capability. This Joint Cognitive System (JCS) supports the interoperability needed to achieve successful operational outcomes, particularly in joint operations. Resilience, is essential in the high-tempo coastal environment. Littoral / amphibious craft, being typically small and fast, and by necessity lean manned must be efficient and optimised. Understanding the crew's roles, tasks and competences provides the definitions required for the information architectures and flow, both intra and inter vessel, that supports the JCS and defines the vessel's Combat System. The JCS, and therefore the Combat System, can be scaled with the vessels size, as a number of the crews / systems functions remain the same. Designing the combat JCS from a human-centred perspective, provides an essential foundation for designing the vessel and delivering the required littoral / amphibious capability. © 2015: The Royal Institution of Naval Architects.;
-;-;
Author;Wallar, A., Plaku, E., Sofge, D.A.;
Title;A planner for autonomous risk-sensitive coverage (PARCov) by a team of unmanned aerial vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923096536&doi=10.1109%2fSIS.2014.7011807&partnerID=40&md5=175b71d31e276da5bd40461f94b91ea2;
-;-;
DOI;DOI: 10.1109/SIS.2014.7011807;
Abstract;ABSTRACT: This paper proposes a path-planning approach to enable a team of unmanned aerial vehicles (UAVs) to efficiently conduct surveillance of sensitive areas. The proposed approach, termed PARCov (Planner for Autonomous Risk-sensitive Coverage), seeks to maximize the area covered by the sensors mounted on each UAV while maintaining high sensor data quality and minimizing detection risk. PARCov leverages from swarm intelligence the idea of using simple interactions among UAVs to promote an emergent behavior that achieves the desired objectives. PARCov uses a dynamic grid to keep track of the parts of the space that have been surveyed and the times that they were last surveyed. This information is then used to move the UAVs toward areas that have not been covered in a long time. Moreover, a nonlinear optimization formulation is used to determine the altitude at which each UAV flies. The efficiency and scalability of PARCov is demonstrated in simulation using complex environments and an increasing number of UAVs to conduct risk-sensitive surveillance. © 2014 IEEE.;
-;-;
Author;Balduccini, M., Nguyen, D.N., Regli, W.C.;
Title;Coordinating UAVs in dynamic environments by network-aware mission planning;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912572129&doi=10.1109%2fMILCOM.2014.168&partnerID=40&md5=8f55b78f0488acbf3176a05abf72d65f;
-;-;
DOI;DOI: 10.1109/MILCOM.2014.168;
Abstract;ABSTRACT: Traditional AI planning has been used successfully in many domains, including logistics, scheduling and game playing. This paper examines how AI planning techniques can be extended to coordinate teams of unmanned aerial vehicles (UAVs) in dynamic environments. Specifically challenging are real-world environments where UAVs and other network-enabled devices must communicate to coordinate- and communication actions are neither reliable nor free. Such network-centric environments are common in military, public safety and commercial applications, yet most planning research (even multi-agent planning) usually takes communications among distributed agents as a given. The emerging application challenge of unmanned systems makes this problem of central focus. This work examines the problem of planning, plan monitoring and coordination of the mission of multiple UAVs in a communication-constrained environment. The work introduces several abstractions that enable AI planners to reason about communication and networking knowledge, and provides the underlying network system the means for including mission data as part of network operations. This work has been empirically validated using a distributed network-centric software evaluation test bed and the results provide guidance to designers in how to understand and control intelligent systems that operate in these environments. © 2014 IEEE.;
-;-;
Author;Varela, G., Caamaño, P., Orjales, F., Deibe, T., López-Peña, F., Duro, R.J.;
Title;Autonomous UAV based search operations using constrained sampling evolutionary algorithms;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896707806&doi=10.1016%2fj.neucom.2013.03.060&partnerID=40&md5=cda537d554f505399e75a11757042500;
-;-;
DOI;DOI: 10.1016/j.neucom.2013.03.060;
Abstract;ABSTRACT: This paper introduces and studies the application of Constrained Sampling Evolutionary Algorithms in the framework of an UAV based search and rescue scenario. These algorithms have been developed as a way to harness the power of Evolutionary Algorithms (EA) when operating in complex, noisy, multimodal optimization problems and transfer the advantages of their approach to real time real world problems that can be transformed into search and optimization challenges. These types of problems are denoted as Constrained Sampling problems and are characterized by the fact that the physical limitations of reality do not allow for an instantaneous determination of the fitness of the points present in the population that must be evolved. A general approach to address these problems is presented and a particular implementation using Differential Evolution as an example of CS-EA is created and evaluated using teams of UAVs in search and rescue missions. The results are compared to those of a Swarm Intelligence based strategy in the same type of problem as this approach has been widely used within the UAV path planning field in different variants by many authors. © 2013 Elsevier B.V.;
-;-;
Author;Duncan, B.A., Murphy, R.R.;
Title;Safety considerations for small unmanned aerial systems with distributed users;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946690936&doi=10.1109%2fSSRR.2014.7017648&partnerID=40&md5=7c2911d4059cae052cf039e87041e54f;
-;-;
DOI;DOI: 10.1109/SSRR.2014.7017648;
Abstract;"ABSTRACT: This paper identifies three categories of safety risks posed by allowing multiple users to engage with small Unmanned Aerial Systems (sUAS) and offers five recommendations on how to reduce or mitigate these vulnerabilities. Data from sUAS can benefit multiple experts at a disaster who may not be familiar with robots or colocated with the pilot. Two different styles of interfaces have been developed and tested with responders conducting exercises to facilitate team coordination with a quadrotor at Texas A&M Engineering Extension Service's Disaster City® over a four year period. The two interfaces illustrate three distinct categories of safety concerns: unsafe control regimes, loss of situation awareness, and increased stress. Five recommendations are proposed to mitigate or eliminate the safety concerns: separate the payload camera from the platform, giving the pilot a dedicated ""pilot-cam"" and the experts a fully gimbaled payload; use artificial intelligence to resolve conflicts between competing directives from multiple experts; allow the pilot, or a software agent, to turn off the expert's ability to control or communication; use multi-modal warnings rather than rely on visual cues; and add guarded motion to prevent collisions. © 2014 IEEE.";
-;-;
Author;Lutz, R.;
Title;SISO standards in action: A DSEEP based process framework for UAS airspace integration analysis;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910147154&partnerID=40&md5=e5ac6e62ff4033582f22ecb586ab00b4;
-;-;
Abstract;ABSTRACT: The Navy's Triton Program (MQ-4C) is developing a high altitude, long endurance Unmanned Aircraft System that is required to operate safely and effectively in the vicinity of other air traffic. To verify that potential hazards in the Triton operational environment can be effectively mitigated, the Triton Safety Case relies heavily on Modeling and Simulation (M&S) to generate substantiating evidence for claims of flight safety across various missions and varying airspace characteristics. Execution of the M&S activities needed to produce this evidence requires close collaboration among multiple organizations fulfilling different roles and responsibilities. Integrating this disparate set of activities into a single coherent and coordinated process is an extremely difficult challenge from a management perspective, since there is a considerable degree of concurrency, iteration, and dependency among the tasks performed by these different teams. A process framework is a mechanism for harmonizing disparity among multiple interacting engineering processes. This paper discusses the application of the IEEE 1730 Distributed Simulation Engineering and Execution Process (DSEEP) as the process framework used for Triton Airspace Integration (AI) project planning and control. The IEEE 1730 standard defines an end-to-end lifecycle process model that captures the full range of activities needed to develop and employ M&S in support of defined study/analysis objectives. Although an IEEE product, the DSEEP was originally developed by SISO as a Sponsor Committee of the IEEE. The DSEEP provides the overarching structure and organization for the Triton Evidence Generation Management Plan (EGMP), which defines the mapping from all Triton evidence generation tasks to corresponding DSEEP elements. This mapping ensures the completeness of the Triton evidence generation process, defines the relationships among the various roles and responsibilities supported by different participating organizations, and defines the dependencies among the artifacts produced by these organizations. The EGMP also includes a DSEEP-based Integrated Master Schedule and supporting tools for EMGP execution. Copyright © (2014) by SISO - Simulation Interoperability Standards Organization All rights reserved.;
-;-;
Author;Le, V.T., Filippidis, A., Lim, C.P., Abdelrahman, W., Nahavandi, S.;
Title;Mini-micro unmanned aerial vehicle intelligence: A threat to land vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902345429&doi=10.3233%2f978-1-61499-405-3-79&partnerID=40&md5=cd46752a110892bf8f900cd74b742ab5;
-;-;
DOI;DOI: 10.3233/978-1-61499-405-3-79;
Abstract;ABSTRACT: Increasing use of commercial off-the-shelf Mini-Micro Unmanned Aerial Vehicle (MAV) systems with enhanced intelligence methodologies can potentially be a threat, if this technology falls into the wrong hands. In this study, we investigate the level of threat imposed on critical infrastructure using different MAV swarm artificial intelligence traits and coordination methodologies. The critical infrastructure in consideration is a moving commercial land vehicle that may be transporting for example an important civil servant or politician. Non-dimensional fitness functions used for measuring MAV mission effectiveness have been established for the case studies considered in this paper. The findings indicated that increased in intelligent and coordination level elevate teams' efficiency, therefore poses a higher degree of threat to targeted land vehicle. Observations from the study have suggested that memory-based cooperative technique provides a consistent efficiency compared to other methods for the mission objectives considered in this paper. © 2014 The authors and IOS Press. All rights reserved.;
-;-;
Author;Kaplan, D.;
Title;Intelligent design;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898033223&partnerID=40&md5=359c3c23afdbb579fa7c467ddd07c301;
-;-;
Abstract;ABSTRACT: A new partnership between NASA and Deloitte hopes to bring many of NASA's proven technologies to the oil and gas industry. One aspect of the NASA portion of the alliance that may be critical to future oil and gas operations is what is currently under development, a remote decision support system. This technology uses artificial intelligence (AI) to augment real-time decision-making during emergency situations. David Kaplan, chief of the quality organization at NASA's Johnson Space Center in Houston, says having a system onboard that could aid teams in the decision making process is critical to mission success when communication between mission control and remote workers is difficult. For NASA, the ultimate goal is a manned trip to Mars, a journey that can take approximately nine months. More and more sensors and information for the station and the shuttles help to assure safe operations, reduce risk, and help engineers foresee trends that need to be interacted with.;
-;-;
Author;Lange, D.S., Verbancsics, P., Gutzwiller, R.S., Reeder, J.;
Title;Trust in sparse supervisory control;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883410343&partnerID=40&md5=209b6c9ef355f2f821fc01a0453b9573;
-;-;
Abstract;ABSTRACT: Command and Control (C2) is the practice of directing teams of autonomous units, regardless if the units are directed by human decision making or are unmanned. Humans are adaptive and their behaviors are recognizable to their superiors who were educated in a similar manner. This paper describes the sparse supervisory control that must be exercised over teams of highly autonomous units, and considers what it means for a commander to supervise autonomous un-manned systems (AUS) that employ machine learning and cooperative autonomy. Commanders must decide whether to trust behaviors they have never seen before, and developing that trust may require several strategies. This paper describes some possible strategies in an effort to explain the challenges that must be solved. © 2013, Association for the Advancement of artificial intelligence.;
-;-;
Author;Gangl, S., Lettl, B., Schulte, A.;
Title;Management of multiple unmanned combat aerial vehicles from a single-seat fighter cockpit in manned-unmanned fighter missions;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086949031&doi=10.2514%2f6.2013-4899&partnerID=40&md5=e7dda9eaa605ad2d77d7f7f4908ce195;
-;-;
DOI;DOI: 10.2514/6.2013-4899;
Abstract;ABSTRACT: This article describes a concept for a single-seat fighter cockpit based system, simultaneously managing up to three unmanned combat aerial vehicles (UCAV) during mission execution. The concept is primarily based on the theory of cooperative and cognitive automation, developed at the Institute of Flight Systems at the University of the Bundeswehr Munich (UBM). Its main component is a modular assistant system, which consists of one artificial cognitive unit (ACU) per UCAV, a self-explanation capability module (SECM) and a team coordination module (TCM). The ACUs grant the unmanned team members capabilities for cooperative and rational behavior in the mission context. In order to support the manned-unmanned collaboration the assistant system is equipped with a SECM and TCM. The SECM explains the observable behavior of the unmanned platforms to the human pilot. It also aims at increasing the pilot's trust in the unmanned systems. The TCM is responsible for all aspects of team coordination, especially between manned and unmanned tasks. The presented concept is implemented in a highly realistic mission simulation environment including a generic fighter simulator, equipped with conventional avionic systems. The article concludes with first experimental results obtained in a test campaign in collaboration with the German Air Force.;
-;-;
Author;Tweedale, J.W.;
Title;Using Multi-Agent Systems to Enhance the Level of Autonomy in Unmanned Vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904612792&doi=10.1007%2f978-3-642-42017-7_14&partnerID=40&md5=4f93c5666da616124056e8db3d0a7aa9;
-;-;
DOI;DOI: 10.1007/978-3-642-42017-7_14;
Abstract;ABSTRACT: This paper describes preliminary work performed to gain an understanding of how to implement a Multi-Agent System (MAS) that can be used to improve the Level of Automation (LOA) within interfaces used by operators when controlling Unmanned Air Vehicles (UAVs). The unmanned systems market is estimated to exceed $12 billion annually by 2017. Hence there is pressure to build an autonomous fleet of vehicles that can be supervised by one human using mission level intent. This concept can be supported by a framework composed of interoperable MAS components acting as a team. A user interface will enable humans to select the mode of operation based on their desired level of trust. Unfortunately the term autonomy is often used synonymously with automation and this habit often confuses the topic. It is true that technology can be used to provide system automation, but increased autonomy is currently constrained by limitations in the ability to program the desired decision-making capabilities within the machine. Hybridised Computational Intelligence (CI) techniques using cognitive architectures may enable science to embed autonomy into existing mission systems. The ability to provide cognitive processing (to provide on-board intelligence) is yet to be realised. Additional capabilities are required to achieve cognition, contextual orientation, rationality, reasoning and considered decision making within the context of the situation. Hence, a sound and scalable cognitive architecture may be considered as the next step in achieving autonomy. As such, further research is required in order to evolve and adapt these concepts. Therefore, this research concentrates on the current concerns affecting the domain. © Springer-Verlag Berlin Heidelberg 2013.;
-;-;
Author;Gangl, S., Lettl, B., Schulte, A.;
Title;Single-seat cockpit-based management of multiple UCAVs using on-board cognitive agents for coordination in manned-unmanned fighter missions;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880741551&doi=10.1007%2f978-3-642-39354-9_13&partnerID=40&md5=51abe28e89db3acb1b2385eac2b6056f;
-;-;
DOI;DOI: 10.1007/978-3-642-39354-9_13;
Abstract;ABSTRACT: This article describes an automation concept, which enables the pilot of a single-seat fighter aircraft to manage more than one unmanned combat aerial vehicle (UCAV). The presented concept bases on the theory of cognitive and cooperative automation and suggests that unmanned aircraft are equipped with on-board artificial cognitive units (ACUs). By this, unmanned platforms are enabled to exhibit cooperative capabilities and rational behavior in the context of the mission. To accomplish efficient manned-unmanned cooperation the concept additionally proposes to support the pilot with an assistant system module for team coordination tasks and to provide a self-explanation capability to the unmanned aircraft. This concept has been realized as laboratory prototype and already been tested with operational personnel in our human-in-the-loop full scenario simulation environment. For the further evaluation of the concept an experimental design has been worked out. © 2013 Springer-Verlag Berlin Heidelberg.;
-;-;
Author;Boeldieu, L.;
Title;The design of intelligent devices as moon/mars base;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883521296&partnerID=40&md5=394a985ffc71e0f028cbcb92c890db00;
-;-;
Abstract;"ABSTRACT: The place of man in space is considered to be the instrument by which he acquires knowledge. The conception of an intelligent architecture (dynamic, interactive, organic and with a controlled ambiance) on Moon or Mars should be looked at as an ideally oriented device that propels cognitive process and allows to acquire knowledge to the occupants. The aim of this exercise is to determine the architectural form of this ideal device, which permits a global and very precise perception of the extreme environment, and at the same time to build a better understanding that will lead to a greater adaptation of this sustained colonization. The design of intelligent devices in the extreme environments is a result of close collaboration (an exchange of different hypotheses and analytical data) between engineers, architects and psychologists.The analysis of Moon or Mars base architectures includes the projects presented in the final report of the IRS space station design workshop 2009, held in Stuttgart University. For this workshop a large team was formed by beginners and experts. During this workshop I had a chance to face the problem of a structure without window facilities owing to radiation levels in a mission for a long period on the Moon. The problem was solved in a holistic and multidisciplinary approach including the human factor, with different ideas. One of the solutions was to simulate perception with principles like camera obscura or periscopes. This paper investigates about how the architectural form of a Moon or Mars base well adapted to his environment emerges from biomorphism of human senses of perception in a kind of ""morphogenesis"" based on the stages of the cognitive process in order to achieve a sustainable manned mission architecture. Copyright © (2012) by the International Astronautical Federation.";
-;-;
Author;Bornstein, J.A., Mitchell, R.R.;
Title;Foundations of autonomy for ground robotics;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874796605&doi=10.1117%2f12.919721&partnerID=40&md5=6286b02eb11e3c14bc72b551def0eecc;
-;-;
DOI;DOI: 10.1117/12.919721;
Abstract;ABSTRACT: Unmanned systems have become a critical element of the Army's Force Structure for applications such as Emergency Ordnance Disposal (EOD). Systems currently fielded are typically tele-operated and, thus, impose significant cognitive burden upon the operator. The Robotics CTA (RCTA), a collaborative research endeavor between the Army Research Laboratory and a consortium of eight industrial and academic partners, is developing fundamental technology to enable a new level of autonomous capability for future unmanned systems that can act as teammates to Soldiers making up a small unit. The Alliance is focusing research in five key areas: a cognitively based world model, semantic perception, learning, meta-cognition, and adaptive behaviors. Because current world model representations are relatively shallow, metrically based, and support only brittle behaviors, the RCTA is creating a cognitive-to-metric world model that can incorporate and utilize mission context. Current perceptual capabilities for unmanned systems are generally limited to a small number of well defined objects or behaviors. The RCTA is raising perception to a semantic level that enables understanding of relationships among objects and behaviors. To successfully team with small units, the command and control of unmanned systems must move away from the current hardware controller paradigm to one of verbal and gestural communication, implicit cues, and transparency of action between Soldier and robot. The RCTA is also exploring adaptive behavior and mechanics that will permit manipulation of arbitrarily shaped objects, animal-like mobility in complex environments, and conduct of military missions in dynamic tactical conditions. Efforts to incorporate learning from the lowest levels of the architecture upwards are key to each of the above. © 2012 Copyright Society of Photo-Optical Instrumentation Engineers (SPIE).;
-;-;
Author;Schneider, F.E., Wildermuth, D., Wolf, H.-L.;
Title;Professional ground robotic competitions from an educational perspective: A consideration using the example of the European Land Robot Trial (ELROB);
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869799684&doi=10.1109%2fIS.2012.6335168&partnerID=40&md5=8553eb17383c06c5720f237c900fc871;
-;-;
DOI;DOI: 10.1109/IS.2012.6335168;
Abstract;ABSTRACT: Structured robotic competitions have become a common method of evaluating the performance of robotic techniques. Some of these contests received a great deal of publicity and are widely used to attract people to AI and robotics, and to science, engineering and technology in general. In this paper the authors discuss possible educational benefits of robotic competitions. In particular, large and professionally organized outdoor ground robot contests are addressed, and of those especially the European Land Robot Trial (ELROB) is considered in detail. The ELROB took place for the sixth time in 2011. The contest is designed to compare unmanned ground vehicles in realistic outdoor scenarios. The tasks of the ELROB competition are described, as well as the participating academic teams. The educational impact of the ELROB and other robotic competitions is considered, especially in terms of team building and visibility aspects. © 2012 IEEE.;
-;-;
Author;Delle Fave, F.M., Farinelli, A., Rogers, A., Jennings, N.R.;
Title;A methodology for deploying the max-sum algorithm and a case study on unmanned aerial vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868294724&partnerID=40&md5=00dffbb1513f325d6647fa9894356814;
-;-;
Abstract;ABSTRACT: We present a methodology for the deployment of the max-sum algorithm, a well known decentralised algorithm for coordinating autonomous agents, for problems related to situational awareness. In these settings, unmanned autonomous vehicles are deployed to collect information about an unknown environment. Our methodology then helps identify the choices that need to be made to apply the algorithm to these problems. Next, we present a case study where the methodology is used to develop a system for disaster management in which a team of unmanned aerial vehicles coordinate to provide the first responders of the area of a disaster with live aerial imagery. To evaluate this system, we deploy it on two unmanned hexacopters in a variety of scenarios. Our tests show that the system performs well when confronted with the dynamism and the heterogeneity of the real world. Copyright © 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.;
-;-;
Author;Bookless, J., Callow, G.;
Title;Toward a goal-based mission planning capability: Using PDDL based automated planners;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862141181&partnerID=40&md5=76de6e59e2865fc5e31c5b34d087d84c;
-;-;
Abstract;ABSTRACT: This paper proposes a generic goal-based mission planning framework which provides an integration environment to support evaluation of existing planning and task assignment technologies. The framework facilitates planning across a team of heterogeneous assets with a distributed capability for generating plans to collaboratively achieve goals. A human operator assigns a team with a top-level goal which the framework then decomposes into a list of tasks that can either be tackled by an individual asset or collectively by a sub-team of assets with the appropriate capabilities. Each asset can generate individual plans with knowledge of the current world state and a goal state. A selection of candidate planners are investigated using the framework including a Hierarchical Task Network (HTN) Planner for goal decomposition and a Partial Ordered PDDL (Planning Domain Definition Language) Planner for action-based plan generation. The developed framework is applied to a search-and-rescue scenario requiring a team of UAVs (Unmanned Aerial Vehicle) to search a specified area of operation.;
-;-;
Author;Villarreal, B.L., Hassard, C., Gordillo, J.L.;
Title;Finding the direction of an odor source by using biologically inspired smell system;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888228774&doi=10.1007%2f978-3-642-34654-5_56&partnerID=40&md5=d987cccd5a5e94db62181fb5d528b41f;
-;-;
DOI;DOI: 10.1007/978-3-642-34654-5_56;
Abstract;ABSTRACT: There is a wide area of applications for sniffing robots where different intelligent algorithms can be applied to follow the smell of precise odors. The localization of odor sources is one way to increase the efficiency and the speed of a multi-robot team in a disaster area during search and rescue applications. Then, the most important task is not the search but the localization of these odor sources, which inspired in nature, requires a stereo sensor to find the direction from where an odor is coming. The intention of this document is to prove that the robot heading can be aligned to the real odor flow direction improving the odor and localization task based on a designed and implemented biologically inspired nose system. Experiments compare the results when the nose system is implemented and when it is not. © Springer-Verlag Berlin Heidelberg 2012.;
-;-;
Author;Tweedale, J.W.;
Title;Using mutli-agent systems to improve the level of autonomy for operators controlling unmanned vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879077473&doi=10.3233%2f978-1-61499-105-2-1666&partnerID=40&md5=576a1cedc7a9a55a7323eed24f660894;
-;-;
DOI;DOI: 10.3233/978-1-61499-105-2-1666;
Abstract;ABSTRACT: This paper describes preliminary work performed to gain an understanding of how to implement a Multi-Agent System (MAS) that can be used to improve the Level of Automation (LOA) used by operators when controlling Unmanned Air Vehicles (UAVs). The ultimate goal is to build an Autonomous Vehicle Management System (AVMS) with intuitive controls that empower the operator to achieve more with less effort. This concept will be supported by a framework comprised of inter-operable MASs acting as teams. Each team has a modular design that support dynamically linkable capabilities. The design provides the operator with an interface to enabled them to select the mode of operation desired based on trust. Technology can be used to provide automation, but innovation enables humans to make it trusted, robust, efficient and effective. Technology and research will effect the ability to adapt, therefore this paper presents the current issues relating to the existing state of knowledge in this domain. This premise relates to the fact that machines can't go beyond what they are programmed to achieve. © 2012 The authors and IOS Press. All rights reserved.;
-;-;
Author;Varela, G., Caamamño, P., Orjales, F., Deibe, A., López-Peña, F., Duro, R.J.;
Title;Swarm intelligence based approach for real time UAV team coordination in search operations;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-83755194878&doi=10.1109%2fNaBIC.2011.6089619&partnerID=40&md5=613ff0b4914b2502d9b1b87ee5dbfd61;
-;-;
DOI;DOI: 10.1109/NaBIC.2011.6089619;
Abstract;ABSTRACT: This paper proposes swarm intelligence based approach for the real time coordination of groups of UAVs (Unmanned Aerial Vehicles) in tasks where values that are sensed from the aerial platform can be used to qualify the individuals. In particular, as an example application, here we consider environmental monitoring UAV teams. Their function is to monitor an area and when some undesired environmental condition arises, coordinate themselves to find the source as fast as possible. The swarm based algorithm has been extensively tested using a 3D simulation platform and validated with real UAVs flying over an industrial area. © 2011 IEEE.;
-;-;
Author;Luo, J.-F., Tang, L.-H., Zhu, C., Zhang, W.-M.;
Title;Action-seeking team coordination for Unmanned Vehicles team planning;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863069186&doi=10.1109%2fCIS.2011.54&partnerID=40&md5=f91ec8f44fe905508e96fb54c5bf1e6f;
-;-;
DOI;DOI: 10.1109/CIS.2011.54;
Abstract;ABSTRACT: Current researches about multi-vehicle cooperation task assignment models, such as capacitated transshipment assignment problem (CTAP) and mixed integer linear programming (MILP), have extreme amounts of computation needed for the dynamic coordination planning of Unmanned Vehicles (UV) team. In this paper, we propose the Action-Seeking Team coordination (ASTC) model with an aim to promote the UV team's high-level dynamic coordination. During the planning execution, each vehicle involved is coordinately assigned to the emergent object in its available time windows in real time. It's an incremental planning approach that treats the gradually emergent object's plan as a problem about optimum combination, which can be solved through 0-1 programming method efficiently. Finally, we confirm the above properties of the methods through the simulation experiment. © 2011 IEEE.;
-;-;
Author;Oh, J., Im, E.-J., Yoon, K.;
Title;Optical flow computation on a heterogeneous platform;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857290363&doi=10.1109%2fURAI.2011.6145935&partnerID=40&md5=16ef72ceed620d4cdc0d9271cf013eee;
-;-;
DOI;DOI: 10.1109/URAI.2011.6145935;
Abstract;ABSTRACT: Unmanned Aerial Vehicles (UAV) are finding their way to a wide range of safety-critical missions. Our collaborative research team of computer scientists and aerospace engineers has worked on developing hardware and software of UAV. One of vital components in software used in UAV is image stabilization. The constantly-shaking images taken from the UAV, resulted from the vehicle's motion, need to be stabilized to perform its mission. In this paper, we present our implementation of image stabilization software. Our research is focused on using state-of-the-art Graphic Processing Unit (GPU) to improve the performance of the image stabilization software. The stabilizer estimates motion of the vehicle by calculating optical flow between successive two frames. In this study, we parallelized the calculation of the optical flow, which is identified as a computational bottleneck of the entire image stabilization process. Using the massive parallelism of NVIDIA C2060 GPU with 448 cores, we could improve the overall performance of image stabilizer. © 2011 IEEE.;
-;-;
Author;Chen, J., Gao, X., Yu, G.;
Title;Cooperative effect analysis of manned/unmanned aerial vehicle team based on fuzzy cognition map;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-81055150426&doi=10.1109%2fICSPCC.2011.6061630&partnerID=40&md5=67b1ce3661bc43f688b349421847d19a;
-;-;
DOI;DOI: 10.1109/ICSPCC.2011.6061630;
Abstract;ABSTRACT: At present, the cooperative operation pattern of manned/unmanned aerial vehicle team has became a focus of international research. To assessment the cooperative effect of manned/unmanned aerial vehicle team, some influential factors are analyzed and a analysis model of cooperative effect is built based on fuzzy cognitive map(FCM). From simulation results, this model can realize organic integration between expert knowledge and quantitative calculation. Through mapping the influential factors with concept nodes of FCM, the dynamic change of cooperative effect can be described more directly. © 2011 IEEE.;
-;-;
Author;Barber, D., Reinerman-Jones, L., Lackey, S., Hudson, I.;
Title;Augmenting robot behaviors using physiological measures;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960314291&doi=10.1007%2f978-3-642-21852-1_65&partnerID=40&md5=177e7dc56550afb49cedd614ac3dcd19;
-;-;
DOI;DOI: 10.1007/978-3-642-21852-1_65;
Abstract;ABSTRACT: In recent years, advancements in Unmanned Systems have allowed Human Robot Interaction (HRI) to transition from direct remote control to autonomous systems capable of self-navigation. However, these new technologies do not yet support true mixed-initiative solider-robot teaming where soldiers work with another agent as if it were another human being. In order to achieve this goal, researchers must explore new types of multi-modal and natural communication strategies and methods to provide robots improved understanding of their human counterparts' thought process. Physiological sensors are continuously becoming more portable and affordable leading to the possibility of providing new insight of team member state to a robot team member. However, steps need to be taken to improve how affective and cognitive states are measured and how these new metrics can be used to augment the decision making process for a robot team member. This paper describes current state of the art and next steps needed for accurate profile creation for improved human robot team performance. © 2011 Springer-Verlag.;
-;-;
Author;Rubin, S.H., Lee, G.;
Title;Human-machine learning for intelligent aircraft systems;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960075197&doi=10.1007%2f978-3-642-21538-4_33&partnerID=40&md5=25c61c8f842faf2778656f68cfb8c0b4;
-;-;
DOI;DOI: 10.1007/978-3-642-21538-4_33;
Abstract;ABSTRACT: The solution for insuring the safety of tele-operated or fully unmanned autonomous systems (UASs) in the air space requires a) that the human remain in and on the loop to the maximal extent practical and b) that the UASs, which share the air space, have an intelligent backend for the processing of their sensory data. Moreover, it is necessary that this sensory processor be capable of generalizing and learning more than it was told in order that it properly handle situations not explicitly programmed for. Given the advent of advances in nanotechnology and microsystems, several research teams continue to investigate the integration of such technologies for single UASs and small swarms of UASs for military, commercial, and civilian applications. Our proposed technology can be readily adapted for transparent learning to serve as an assistant for human piloting as well as an emergency intelligent autopilot for all manner of piloted vehicles. © 2011 Springer-Verlag.;
-;-;
Author;Hamel, W.;
Title;Measurement of autonomous operation;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871386310&doi=10.1145%2f2377576.2377598&partnerID=40&md5=2a3977e5b0334ea941de3424dfc9061b;
-;-;
DOI;DOI: 10.1145/2377576.2377598;
Abstract;"ABSTRACT: While robotic systems and the field of Artificial Intelligence (AI) have been funded through the Department Of Defense (DoD) and Industry for decades, it was not until recent years that the combination of these two technologies has made truly significant advances in the area of Autonomous Operation (AO) systems. Through the efforts of the Defense Advanced Research Project Agency (DARPA) challenges in 2004 - 2007 timeframe, the academic and industrial communities came together to overcome some significant hurdles for the development of AO ground vehicles in both the rural and desert environments (DARPA Grand Challenge 2004 - 2005) and the urban environment (DARPA Urban Challenge 2007). Although no AO vehicle succeeded in the 2004 event, the following year four systems completed the 132 mile course within the 10 hour time limit. The winner of the 2005 event (The Stanley from Stanford University) designed an autonomous (learning system) vehicle that fused five Lidars, Radar, and an Electro Optic sensor in addition to the waypoint GPS (provided by DARPA) and an internal Inertial Measurement Unit (IMU) system to produce the situational awareness required to meet the challenge. The team took approximately one year ""training"" the perception and planning sections of the software to compensate for various types of terrain and maneuvering. It was through extensive planning, meticulous design, and thorough testing that the final goal was achieved and it will take a much greater level of effort for DoD to realize a similar capability in the air environment. In the Air domain, DoD will not have the luxury of releasing autonomous vehicles (without significant constraints) within an operationally relevant environment (like the National Air Space (NAS)) until a very high level of confidence is achieved in their ability to perform the mission while providing a level of safety commensurate with manned operation. For DoD to succeed, it is imperative that we provide the Unmanned Air System (UAS) development community the tools required to assess all of the engineering components necessary for transition of AO vehicles into the NAS and operational environments. These tools should include a model of the required environments (emulated with access to standardized hardware/software in the loop), standard set of operational test procedures (with desired metrics), and a framework through which individual components can be assessed. It is ironic that the success of AO unmanned systems will require a structured collaborative learning process within the human domain for our goals to be realized. © 2010 ACM.";
-;-;
Author;Berger, J., Happe, J.;
Title;Co-evolutionary search path planning under constrained information-sharing for a cooperative unmanned aerial vehicle team;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959444133&doi=10.1109%2fCEC.2010.5586369&partnerID=40&md5=28a3c4cb705c4aaf68a1072c2dd9f501;
-;-;
DOI;DOI: 10.1109/CEC.2010.5586369;
Abstract;ABSTRACT: Mobile cooperative sensor networks are increasingly used for surveillance and reconnaissance tasks to support domain picture compilation. However, efficient distributed information gathering such as target search by a team of autonomous unmanned aerial vehicles (UAVs) remains very challenging in constrained environment. In this paper, we propose a new approach to learn resource-bounded multi-agent coordination for a multi-UAV target search problem subject to stringent communication bandwidth constraints in a dynamic uncertain environment. It relies on a new information-theoretic co-evolutionary algorithm to solve cooperative search path planning over receding horizons, providing agents with mutually adaptive and self-organizing behavior. The anytime coordination algorithm is coupled to a divergence-based information-sharing policy to exchange high-value world-state information under limited communication bandwidth. Computational results show the value of the proposed approach in comparison to a well-known reported technique. © 2010 IEEE.;
-;-;
Title;Unmanned Aircraft System (UAS) Sense and Avoid (SAA) technology development roadmap;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551635725&partnerID=40&md5=7b58de8a8accaf981cb63b5ef2ad43e2;
-;-;
Abstract;"ABSTRACT: Projected Department of Defense (DoD) Unmanned Aircraft Systems (UAS) utilization of the National Airspace System (NAS) requires a viable Sense and Avoid (SAA) capability. This capability is an alternate means of compliance with Federal Aviation Administration (FAA) Code of Federal Regulations (CFR) Part 91.113 requirement to ""see and avoid"" other aircraft. Currently there is no FAA approved SAA solution to meet the alternate means of compliance. The UAS Research and Engineering (R&E) Integrated Product Team (IPT) developed a technology roadmap to support future UAS SAA needs. This supports UAS Airspace Integration (AI) IPT activities. The roadmap includes DoD Military Department Science and Technology (S&T) efforts in Budget Activities (BA) 1-4. This white paper documents the SAA roadmap including the generation process, S&T technology planning targets and supporting technology development activities to meet planning targets. The roadmap development process included three, two-day workshops occurring from May to November of 2009. Workshop participants represented organizations from OSD, JFCOM/J85, Military Department S&T and Program Management, UAS AT IPT, NASA, FAA and IDA. Intermediate results included a common SAA organizational framework, Military Department S&T matrix and materiel solution categorization. These results reference, leverage or align with external SAA activities including: AT IPT activities for Ground Based Sense and Avoid (GBSAA), Airborne Sense and Avoid (ABSAA); draft Initial Capabilities Document (lCD) for UAS Integration into the NAS; FAA sponsored ""SAA Workshop Final Report; and draft biennial update to the National Plan for Aeronautics Research and Development and Related Infrastructure. S&T technology planning targets represent incremental increases in SAA capabilities over time. Initial capabilities are tied to current GBSAA and ABSAA activities. Timelines for projected technical capabilities are derived from the National Plan and infonned by Subject Matter Experts (SMEs). The roadmap includes increasing levels of capability related to SAA functionality for: Probability of Encounter (POE), Airspace Density, Multiple UAS Operations, Range of UAS Groups, and Classes of Airspace including Terminal Operations. The roadmap is populated with existing Military Department and proposed S&T activities to meet S&T planning targets. Each planning target represents an integrated technology demonstration in a relevant environment or Technology Readiness Level (TRL) 6. Supporting each integrated demonstration are component S&T development efforts. The SAA roadmap also provides traceability from the National Plan down to components of individual Military Department S&T development activities in BA 2-4 and Small Business Innovative Research (SBIR). Roadmap elements which are not covered by existing Military Department S&T efforts are represented by draft technology development project areas and functional needs to meet system level SAA technology planning. Future updates to the SAA S&T roadmap will be required as S&T efforts mature and the operational needs associated with UAS AI are more clearly defined.";
-;-;
Author;Squire, P.N., Parasuraman, R.;
Title;Effects of automation and task load on task switching during human supervision of multiple semi-autonomous robots in a dynamic environment;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954852960&doi=10.1080%2f00140139.2010.489969&partnerID=40&md5=a7d4fd9fcfd911303adbe3ea39d16d7f;
-;-;
DOI;DOI: 10.1080/00140139.2010.489969;
Abstract;ABSTRACT: The present study assessed the impact of task load and level of automation (LOA) on task switching in participants supervising a team of four or eight semi-autonomous robots in a simulated 'capture the flag' game. Participants were faster to perform the same task than when they chose to switch between different task actions. They also took longer to switch between different tasks when supervising the robots at a high compared to a low LOA. Task load, as manipulated by the number of robots to be supervised, did not influence switch costs. The results suggest that the design of future unmanned vehicle (UV) systems should take into account not simply how many UVs an operator can supervise, but also the impact of LOA and task operations on task switching during supervision of multiple UVs. The findings of this study are relevant for the ergonomics practice of UV systems. This research extends the cognitive theory of task switching to inform the design of UV systems and results show that switching between UVs is an important factor to consider.;
-;-;
Author;Tošić, P.T., Vilalta, R.;
Title;A unified framework for reinforcement learning, co-learning and meta-learning how to coordinate in collaborative multi-agent systems;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650301548&doi=10.1016%2fj.procs.2010.04.248&partnerID=40&md5=0584495290080b5efa68a0d596b1d7aa;
-;-;
DOI;DOI: 10.1016/j.procs.2010.04.248;
Abstract;ABSTRACT: Coordination among multiple autonomous, distributed cognitive agents is one of the most challenging and ubiquitous problems in Distributed AI and its applications in general, and in collaborative multi-agent systems in particular. A particularly prominent problem in multi-agent coordination is that of group, team or coalition formation. A considerable majority of the approaches to this problem found in the literature assume fixed interactions among autonomous agents involved in the coalition formation process. Moreover, most of the prior research where agents are actually able to learn and adapt based on their past interactions mainly focuses on reinforcement learning techniques at the individual agent level. We argue that, in many important applications and contexts, complex large-scale collaborative multi-agent systems need to be able to learn and adapt at multiple organization, hierarchical and logical levels. In particular, the agents need to be able to learn both at the level of individual agents and at the system or agent ensemble levels, and then to integrate these different sources of learned knowledge and behavior, in order to be effective at solving complex tasks in typical dynamic, partially observable and noisy multi-agent environments. In this paper, we describe a conceptual framework for addressing the problem of learning how to coordinate effectively at three qualitatively distinct levels - those of (i) individual agents, (ii) small groups of agents, and (iii) very large agent ensembles (or alternatively, depending on the nature of a multi-agent system, at the system or central control level). We briefly illustrate the applicability and usefulness of the proposed conceptual framework with an example of how it would apply to an important practical coordination problem, namely that of distributed coordination of a large ensemble of unmanned vehicles on a complex multi-task mission.;
-;-;
Author;Lin, L., Roscheck, M., Goodrich, M.A., Morse, B.S.;
Title;Supporting Wilderness Search and Rescue with integrated intelligence: Autonomy and information at the right time and the right place;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958578544&partnerID=40&md5=2b0cdf5c3c0c77198aca4ed11d13254c;
-;-;
Abstract;ABSTRACT: Current practice in Wilderness Search and Rescue (WiSAR) is analogous to an intelligent system designed to gather and analyze information to find missing persons in remote areas. The system consists of multiple parts - various tools for information management (maps, GPS, etc) distributed across personnel with different skills and responsibilities. Introducing a camera-equipped mini-UAV into this task requires autonomy and information technology that itself is an integrated intelligent system to be used by a sub-team that must be integrated into the overall intelligent system. In this paper, we identify key elements of the integration challenges along two dimensions: (a) attributes of intelligent system and (b) scale, meaning individual or group. We then present component technology that of fload or supplement many responsibilities to autonomous systems, and finally describe how autonomy and information are integrated into user interfaces to better support distributed search across time and space. The integrated system was demoed for Utah County Search and Rescue personnel. A real searcher flew the UAV after minimal training and successfully located the simulated missing person in a wilderness area. Copyright © 2010, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;
-;-;
Author;Sujit, P.B., Sousa, J., Pereira, F.;
Title;Multiple UAV teams for multiple tasks;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950556116&doi=10.1109%2fCISDA.2009.5356535&partnerID=40&md5=3efa0af03808ad1a6cb3cceaa0700ccd;
-;-;
DOI;DOI: 10.1109/CISDA.2009.5356535;
Abstract;ABSTRACT: In a search and prosecute mission, multiple heterogeneous unmanned aerial vehicles UAVs that carry different resources need to perform the classify, prosecute and battle damage assessment (BDA) tasks on targets sequentially. Depending on the target resource requirement, it may be necessary to deploy a coalition of UAVs to perform the action. In this paper, we propose coalition formation algorithms that have low computational overhead to determine coalitions for the prosecute and the BDA tasks. We also develop a simultaneous strike mechanism based on Dubins curves for the UAVs to prosecute the target simultaneously. Monte-Carlo simulation results are presented to show how the algorithms work and the effect of increasing the number of BDA tasks on the mission performance. © 2009 IEEE.;
-;-;
Author;King, A., Del Buono, M., Marolf, J., Dop, M., Stansbury, R.S.;
Title;An intelligent system for improving the efficiency of a PHEV for ECOCAR challenge;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953768407&doi=10.1115%2fES2009-90309&partnerID=40&md5=018acbbef1e316f64bf457c407f12299;
-;-;
DOI;DOI: 10.1115/ES2009-90309;
Abstract;"ABSTRACT: Globally, significant efforts are being made to reduce greenhouse gases and decrease the demand of fossil fuels. Automotive manufacturers are offering significantly more ""green"" versions of their popular automobiles in order to combat the negative impact of rising fuel prices. The EcoCar Challenge is a college-level competition primarily sponsored by General Motors and the United States Department of Energy in an effort to provide global awareness of this effort and educate future engineers in the processes and technologies used to construct fuel economic hybrid vehicles. The program consists of 17 teams with a wide variety of hybrid vehicle types. Embry-Riddle Aeronautical University (ERAU) is implementing a plug-in hybrid electric vehicle (PHEV) through the modification of a stock 2009 Saturn Vue as described in [1]. This paper presents the Intelligent Drive Efficiency Assistant (IDEA) system a hardware/software component being added to ERAU's EcoCar vehicle. The IDEA system uses artificial intelligence techniques to analyze the driving conditions ahead (terrain, traffic, and anticipated torque requirements) to select the best operating mode for the hybrid vehicle. The IDEA system submits its recommendation to a hybrid or supervisory control unit, presented in [2], which does the necessary work to transition the vehicle into that operating mode (so long as it deems the request safe). This preemptive strategy is believed to provide two key benefits. First, through learning algorithms, new control strategies may be developed based on the driving conditions and past experience. Second, by preemptively making recommendations ahead of a driving event such as an uphill climb, or a frequent stop in rush-hour traffic, it is believed that there will be less energy wasted by not waiting until the need arises to start making the transition between hybrid modes. Within this paper, the initial design of the IDEA system is be presented, and the evaluation plan using hardware-in-the-loop and software-in-the-loop simulation is discussed. Copyright © 2009 by ASME.";
-;-;
Author;Schulte, A., Meitinger, C., Onken, R.;
Title;Human factors in the guidance of uninhabited vehicles: Oxymoron or tautology? : ttial of cognitive and co-operative automation;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-65049087239&doi=10.1007%2fs10111-008-0123-2&partnerID=40&md5=889d42f20b0b8b101dda01d739453790;
-;-;
DOI;DOI: 10.1007/s10111-008-0123-2;
Abstract;ABSTRACT: Today's automation is typically tied into work processes as tools actively supporting the human operator in fulfilling certain well-defined sub-tasks. The human operator is in the role of the high-end decision component determining and supervising the work process. With emergent technology highly automated work systems can be beneficial on the one hand, but automation may as well cause problems on its own. A new way of introducing automation into work systems shall be advocated by this article overcoming the classical pitfalls of automation and simultaneously taking the benefit as wanted. This shall be achieved by so-called cognitive automation, i.e. providing human-like problem-solving, decision-making and knowledge processing capabilities to machines in order to obtain goal-directed behaviour and effective operator assistance. A key feature of cognitive automation is the ability to create its own comprehensive representation of the current situation and to provide reasonable action. By additionally providing full knowledge of the prime work objectives to the automation it will be enabled to co-operate with the human operator in supervision and decision tasks, then being intelligent machine assistants for the human operator in his work place. Such assistant systems understand the work objective and will be heading for the achievement of the overall desired work result. They will understand the situation (e.g. opportunities, conflicts) and actions of team members-whether humans or assistant systems-and will pursue goals for co-operation and co-ordination (e.g. task coverage, avoidance of redundancy or team member overcharge). On the other hand, cognitive automation can be emerged towards being highly automated intelligent agents in charge of certain supportive tasks to be performed in a semi-autonomous mode. These cognitive semi-autonomous systems and the cognitive assistants shall be denoted as the two faces of dual-mode cognitive automation (Onken and Schulte, in preparation). © 2008 Springer-Verlag London Limited.;
-;-;
Author;Verfaillie, G., Pralet, C.;
Title;How to model planning and scheduling problems using timelines;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857804810&partnerID=40&md5=3470a852bca0135c31e4bbb68ad93dc2;
-;-;
Abstract;ABSTRACT: The CNT framework (Constraint Network on Timelines (Ver-faillie, Pralet, and Lemaître 2008)) has been designed to model discrete event dynamic systems and the properties one knows, one wants to verify, or one wants to enforce on them. In this paper, after a reminder about the CNT framework, we show its modeling power, first on two generic problems (the planning problem in the STRIPS framework and the resource-constrained project scheduling problem), then on two specific problems coming from the aerospace domain (the mission management problems for a team of unmanned air vehicles and for an Earth watching and observing satellite). © 2008, Association for the Advancement of Artificial Intelligence.;
-;-;
Author;Clancey, W.J., Sierhuis, M., Seah, C., Buckley, C., Reynolds, F., Hall, T., Scott, M.;
Title;Multi-agent simulation to implementation: A practical engineering methodology for designing space flight operations;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-55249122928&doi=10.1007%2f978-3-540-87654-0_5&partnerID=40&md5=78a9e9a68f4a97ccd923a6b9b01749d6;
-;-;
DOI;DOI: 10.1007/978-3-540-87654-0_5;
Abstract;"ABSTRACT: OCAMS is a practical engineering application of multi-agent systems technology, involving redesign of the tools and practices in a complex, distributed system. OCAMS is designed to assist flight controllers in managing interactions with the file system onboard the International Space Station. The ""simulation to implementation"" development methodology combines ethnography, participatory design, multiagent simulation, and agent-based systems integration. We describe the model of existing operations and how it was converted into a future operations simulation that embeds a multiagent tool that automates part of the work. This hybrid simulation flexibly combines actual and simulated systems (e.g., mail) and objects (e.g., files) with simulated people, and is validated with actual data. A middleware infrastructure for agent societies is thus demonstrated in which agents are used to link arbitrary hardware and software systems to distributed teams of people on earth and in space-the first step in developing an interplanetary multiagent system. © 2008 Springer-Verlag Berlin Heidelberg.";
-;-;
Author;Baxter, J.W., Horn, G.S., Leivers, D.P.;
Title;Fly-by-agent: Controlling a pool of UAVs via a multi-agent system;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-40249110544&doi=10.1016%2fj.knosys.2007.11.005&partnerID=40&md5=f08547c923b24ed691d284688af62bec;
-;-;
DOI;DOI: 10.1016/j.knosys.2007.11.005;
Abstract;ABSTRACT: This paper describes the multi-agent system used to control a package of four uninhabited air vehicles (UAVs). The system has recently been used in a series of test flights where the pilot of a fast jet controlled a team of four UAVs (one real, three simulated) carrying out a representative mission. The structure of the system is described and the re-organisation of the agents as the mission progresses is illustrated with an example. The paper concludes by describing the importance of whole system issues and the integration and test cycle for getting AI techniques working and accepted in an application. © 2007 Qinetiq.;
-;-;
Author;Oh, P.Y., Sevcik, K.W., Green, W.E.;
Title;Aerial robotics competition: Lessons in autonomy;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-37349014819&partnerID=40&md5=33bbc998b4beeccda0f47c07d4fcb19a;
-;-;
Abstract;ABSTRACT: In May 2005, the Indoor Aerial Robot Competition was inaugurated. The goal of this annual event is to identify best design practices and gain insight on technical challenges facing the realization of near-Earth unmanned air vehicles. This paper describes the motivation, goals and objectives of this competition. Over the past two years, undergraduate teams from the Philadelphia-region participated from schools like Drexel, Swarthmore, Bryn Mawr, Rowan, Rutgers and Villanova. Robot design, competition highlights and lessons learned are described in this paper. Copyright © 2007, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.;
-;-;
Author;Smith III, J.F.;
Title;Fuzzy logic planning and control for a team of UAVs;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-54949094705&partnerID=40&md5=09827ea744e15662957a481e7b810163;
-;-;
Abstract;ABSTRACT: A fuzzy logic resource allocation algorithm that enables a collection of unmanned air vehicles (UAVs) to automatically cooperate as they make meteorological measurements will be discussed. No human intervention during the measurement process is required. A fuzzy logic based planning algorithm determines the optimal trajectory and points each UAV will sample, while taking into account the UAVs' risk, risk tolerance, reliability, and mission priority for sampling in certain regions. It also considers fuel limitations, mission cost, and related uncertainties. The real-time fuzzy control algorithm running on each UAV renders the UAVs autonomous allowing them to change course immediately without consulting with any commander, requests other UAVs to help, change the points that will be sampled when observing interesting phenomena, or to terminate the mission and return to base. The underlying optimization procedures including the fuzzy logic based cost function, the fuzzy logic decision rule for UAV path assignment, and the fuzzy algorithm that determines when a UAV should alter its mission to help another UAV are discussed. Simulations show the ability of the fuzzy algorithms to allow UAVs to effectively cooperate to increase the UAV team's likelihood of success even when UAV measurement devices, propulsion or communications fail.;
-;-;
Author;Crane, C., Armstrong, D., Arroyo, A., Baker, A., Dankel, D., Garcia, G., Johnson, N., Lee, J., Ridgeway, S., Schwartz, E., Thorn, E., Velat, S., Yoon, J.H., Washburn, J.R.;
Title;Team gator nation's autonomous vehicle development for the 2007 DARPA Urban challenge;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-38549098613&doi=10.2514%2f1.33342&partnerID=40&md5=6e77abb9a9d6db234eee59dbbf6c188f;
-;-;
DOI;DOI: 10.2514/1.33342;
Abstract;ABSTRACT: This paper describes the system design developed for Team Gator Nation's submission to the 2007 DARPA Urban Challenge. A hybrid Toyota Highlander has been automated and instrumented with pose estimation (GPS and inertial) and object detection (vision and ladar) sensors. The control architecture consists of four primary elements, i.e. Planning Element, Perception Element, Intelligence Element, and Control Element. The Intelligence Element implements the Adaptive Planning Framework developed by researchers at the University of Florida. This framework provides a means for situation assessment, behavior mode evaluation, and behavior selection and execution. The architecture is implemented on a system distributed over ten dual-core computers that intercommunicate via the Joint Architecture for Unmanned Systems (JAUS) version 3.2 protocol. This work's primary contribution addresses the technical challenges of (a) the reconciliation of differences in estimated global pose, a priori data, and sensed information, (b) the determination of the appropriate behavior mode, and (c) the smooth transition of vehicle control between behavior modes. The processes that perform these tasks as well as the other necessary processes that perform perception, data integration, planning, and control are described in detail together with their design rationale. Finally, testing results accomplished to date are presented. Copyright © 2007 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved.;
-;-;
Author;Digney, B.L.;
Title;Cohort: Critical science;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-35948985205&doi=10.1117%2f12.720201&partnerID=40&md5=7466be8826400cddbb6cf0800373b5fe;
-;-;
DOI;DOI: 10.1117/12.720201;
Abstract;ABSTRACT: Unmanned vehicle systems is an attractive technology for the military, but whose promises have remained largely undelivered. There currently exist fielded remote controlled UGVs and high altitude UAV whose benefits are based on standoff in low complexity environments that require sufficiently low control reaction time to allow for teleoperation. While effective within there limited operational niche such systems do not meet with the vision of future military UxV scenarios. Such scenarios envision unmanned vehicles operating effectively in complex environments and situations with high levels of independence and effective coordination with other machines and humans pursing high level, changing and sometimes conflicting goals. While these aims are clearly ambitious they do provide necessary targets and inspiration with hopes of fielding near term useful semi-autonomous unmanned systems. Autonomy involves many fields of research including machine vision, artificial intelligence, control theory, machine learning and distributed systems all of which are intertwined and have goals of creating more versatile broadly applicable algorithms. Cohort is a major Applied Research Program (ARP) led by Defence R&D Canada (DRDC) Suffield and its aim is to develop coordinated teams of unmanned vehicles (UxVs) for urban environments. This paper will discuss the critical science being addressed by DRDC developing semi-autonomous systems.;
-;-;
Author;Pantic, M., Zwitserloot, R.;
Title;Active learning of introductory machine learning;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-48749128308&doi=10.1109%2fFIE.2006.322738&partnerID=40&md5=dee55fdb7b433ee4d787771d9bb262fc;
-;-;
DOI;DOI: 10.1109/FIE.2006.322738;
Abstract;ABSTRACT: This paper describes a computer-based training program for active learning of Agent Technology, Expert Systems, Neural Networks and Case-Based Reasoning by undergraduate students using a simple agent framework. While many Machine Learning (ML) and Artificial Intelligence (AI) courses teach ML and AI concepts by means of programming assignments, these assignments have usually no connection to how the student will apply the newly obtained knowledge to previously unseen, real-world problems. The pedagogy that we adopted here is computer-based active learning: teams of students are presented with well-defined assignments aimed at building intelligent agents for person identification and recognition of facial expressions and emotions from video recordings of their faces. Classroom experience indicates that the students found the specified programming assignments highly motivating. Objective evaluation studies suggest that students learn much more effectively when a contextualized, collaborative, constructive, and reflective approach is used than when an orthodox, objectivist approach to teaching ML and AI techniques is used alone. © 2006 IEEE.;
-;-;
Author;Neerincx, M.A., Lindenberg, J., Smets, N., Grant, T., Bos, A., Olmedo-Soler, A., Brauer, U., Wolff, M.;
Title;Cognitive engineering for long duration missions: Human-machine collaboration on the moon and mars;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247186420&doi=10.1109%2fSMC-IT.2006.24&partnerID=40&md5=a4e319053f6a6808f4c7a48859b4c888;
-;-;
DOI;DOI: 10.1109/SMC-IT.2006.24;
Abstract;ABSTRACT: For manned long-duration missions to the Moon and Mars, there is a need for a Mission Execution Crew Assistant (MECA) that empowers the cognitive capacities of human-machine teams during planetary exploration missions in order to cope autonomously with unexpected, complex and potentially hazardous situations. MECA requirements are being derived via a cognitive engineering method, which addresses operational, human factors and technological aspects with their mutual dependencies. This method follows an iterative process of specification, evaluation and refinement to establish a sound - theoretical and empirical founded-set of requirements. It distinguishes three types of iterations: system-design review, scientific discourse and simulation-based evaluation. The first two iterations provided a set of requirements for distributed human-machine collaboration on the Moon or Mars. © 2006 IEEE.;
-;-;
Author;Dahn, D., Gacy, M.;
Title;Human control of unmanned systems under stressful conditions;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846070674&partnerID=40&md5=b7cc58583245961d80b9c9fe9d3a54b6;
-;-;
Abstract;ABSTRACT: Human operations in hazardous environments, or when responding to an emergency, are high cognitive workload tasks that reduce the number of simultaneous tasks a human can do. There is a constant cognitive load to prevent injury (self-preservation), as well as the stress and time pressure of an unknown situation. The use of robotics can mitigate some of these issues, both through the removal of the operator from the immediate environment and the intelligent management and presentation of information from the robotic system. One of the technical thrusts within the Robotics Collaborative Technology Alliance from the Army Research Laboratory (ARL) has been to design, build, and experiment with new concept control systems that will allow a single human to simultaneously control multiple unmanned ground and air vehicles in such hazardous/hostile environments. Our research focus has been to design and develop simple human interfaces and intelligent aids to reduce the human cognitive workload required to operate multiple unmanned vehicles. We have developed both vehicle mounted and dismounted controllers that all provide a similar look and feel, and relatively equivalent control capabilities. To evaluate human performance we have implemented a systems integration laboratory (SIL) that provides a virtual experimentation environment from which we can control the virtual equivalents of real unmanned vehicles. This environment has also provided a low-cost method to advance collaborative research in multi-modal human interfaces and intelligent aids needed to control unmanned vehicles. The resulting advances in operator control unit technology are used to reduce the workload required to operate real robotic vehicles including small unmanned ground vehicles (SUGV), experimental unmanned vehicles (XUV), large Army Stryker vehicles, the Raven and Pointer (small unmanned fixed-wing air vehicles), and a VTOL RMAX helicopter. This paper describes the SIL and the various unmanned vehicle control systems, some of the novel concepts implemented to symbolically represent necessary situational awareness cues to the operator, and intelligent aids that help effectively operate smart unmanned vehicles.;
-;-;
Author;Theisen, B.L., Nguyen, D.;
Title;The 14 TH annual intelligent ground vehicle competition: Intelligent teams creating intelligent ground robots;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-33751283299&doi=10.1117%2f12.685386&partnerID=40&md5=9c3ca3172c2575c75ba83720ff0d10f7;
-;-;
DOI;DOI: 10.1117/12.685386;
Abstract;ABSTRACT: The Intelligent Ground Vehicle Competition (IGVC) is one of three, unmanned systems, student competitions that were founded by the Association for Unmanned Vehicle Systems International (AUVSI) in the 1990s. The IGVC is a multidisciplinary exercise in product realization that challenges college engineering student teams to integrate advanced control theory, machine vision, vehicular electronics, and mobile platform fundamentals to design and build an unmanned system. Teams from around the world focus on developing a suite of dual-use technologies to equip ground vehicles of the future with intelligent driving capabilities. Over the past 14 years, the competition has challenged undergraduate, graduate and Ph.D. students with real world applications in intelligent transportation systems, the military and manufacturing automation. To date, teams from over 50 universities and colleges have participated. This paper describes some of the applications of the technologies required by this competition and discusses the educational benefits. The primary goal of the IGVC is to advance engineering education in intelligent vehicles and related technologies. The employment and professional networking opportunities created for students and industrial sponsors through a series of technical events over the three-day competition are highlighted. Finally, an assessment of the competition based on participant feedback is presented.;
-;-;
Author;Verret, S.R., Monckton, S.;
Title;Multi unmanned vehicle systems (nUxVs) at Defence R&D Canada;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748548033&doi=10.1117%2f12.664715&partnerID=40&md5=43bd3f63cc28e493feb6356fcba4df13;
-;-;
DOI;DOI: 10.1117/12.664715;
Abstract;"ABSTRACT: No single UxV is perfectly suited to all task assignments. A homogeneous UxV team, for example, a troop of identical UGVs, brings redundancy and reliability to a specific class of tasks. Heterogeneous UxV teams, for example, a troop of UGVs, a flight of low flying rotorcraft, and a high flying UAV, provide increased capability. They can tackle multiple tasks simultaneously through cooperative decision making, distributed task allocation, and collective mapping. Together, they can convoy payloads, provide communications, observe targets, shield troops, and, ultimately, deliver munitions. nUxVs have the potential to share, learn, and adapt information between like platforms and across platform types, to produce expanded capability and greater reliability. Current research exploits simple vehicle state exchange, communications relay and formation keeping. Our near-term research areas include map sharing and integration, task coordination, and heterogeneous nUxV teaming. Future research will address military nUxV C2; nUxV capability definition and understanding; behaviour-based and reactive nUxVs, emergence and stigmergy; and collaboration and interaction between human-robot teams.";
-;-;
Author;Jin, Y., Liao, Y., Minai, A.A., Polycarpou, M.M.;
Title;Balancing search and target response in cooperative unmanned aerial vehicle (UAV) teams;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744517415&doi=10.1109%2fTSMCB.2005.861881&partnerID=40&md5=89d349056985a00d480e0fd7f27ce20b;
-;-;
DOI;DOI: 10.1109/TSMCB.2005.861881;
Abstract;ABSTRACT: This paper considers a heterogeneous team of cooperating unmanned aerial vehicles (UAVs) drawn from several distinct classes and engaged in a search and action mission over a spatially extended battlefield with targets of several types. During the mission, the UAVs seek to confirm and verifiably destroy suspected targets and discover, confirm, and verifiably destroy unknown targets. The locations of some (or all) targets are unknown a priori, requiring them to be located using cooperative search. In addition, the tasks to be performed at each target location by the team of cooperative UAVs need to be coordinated. The tasks must, therefore, be allocated to UAVs in real time as they arise, while ensuring that appropriate vehicles are assigned to each task. Each class of UAVs has its own sensing and attack capabilities, so the need for appropriate assignment is paramount. In this paper, an extensive dynamic model that captures the stochastic nature of the cooperative search and task assignment problems is developed, and algorithms for achieving a high level of performance are designed. The paper focuses on investigating the value of predictive task assignment as a function of the number of unknown targets and number of UAVs. In particular, it is shown that there is a tradeoff between search and task response in the context of prediction. Based on the results, a hybrid algorithm for switching the use of prediction is proposed, which balances the search and task response. The performance of the proposed algorithms is evaluated through Monte Carlo simulations. © 2006 IEEE.;
-;-;
Author;Freedy, A., Weltman, G., Freedy, E., Devisser, E., Coeyman, N., Kalphat, M., Palmer, D.;
Title;Mixed initiative team performance assessment system (MITPAS);
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897526617&partnerID=40&md5=55e53a250a9b0c29eec914f84c67bced;
-;-;
Abstract;"ABSTRACT: MITPAS (Mixed Initiative Team Performance Assessment System) is a complete methodology for measuring the performance of teams involving both human and robotic elements in training as well as real world operational environments. MITPAS responds to the revolution in battlefield technology caused by mixed initiative combat systems involving warfighter and machine collaboration in combat, and to the concurrent need for performance measurement technology that recognizes the unique interaction of two cognitive systems - human and autonomous or semi-autonomous unmanned robot. MITPAS consists of three main components: (1) a multi-dimensional team performance model that aggregates measures of performance and measures of effectiveness into new scoring criteria adapted to human-robotic collectives; (2) advanced data logging software that uses inter-operable data exchange mechanisms based on Extensible Markup Language (XML) information representation to capture mixed initiative control events and Command and Control (C2) communication events over an XML-RPC based interface to a broad variety of simulation systems; and (3) a simulation environment based on the U.S. Army's OneSAF Testbed Baseline (OTB) that includes a Unmanned Ground Vehicle (UGV) controller station, a Battle Master/Platoon Leader station and a realistic initial scenario involving UGV surveillance and clearance of a planned convoy route. An initial experimental study was designed to validate initially the MITPAS methodology and to examine the relationship of trust to human-robot team performance. MITPAS performed successfully, and the study results were indicative of the type of new insights into human-robot team behavior that can be gained by combining MITPAS' measurement power with realistic simulations of tactical Unmanned Vehicle (UV) operations, such as that represented by our OneSAF-based experimental environment. Our objective is wide utilization of MITPAS technology by other researchers and operational users.";
-;-;
Author;Gluck, K.A., Ball, J.T., Gunzelmann, G., Krusmark, M.A., Lyon, D.R., Cooke, N.J.;
Title;A prospective look at a synthetic teammate for UAV applications;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748698291&partnerID=40&md5=7badc904e84e070417cd794e37d365a6;
-;-;
Abstract;ABSTRACT: This paper describes current progress and future plans for research and development in synthetic teammates for applications in training, analysis, and system design for UAV operations. The development of these teammates involves the eventual integration of several distinct, yet related, basic and applied research lines, including navigation and orientation in virtual environments, computational cognitive process modeling of aircraft maneuvering and reconnaissance missions, verbal interaction between human operators and synthetic entities, and the formal analysis of team skill. The use of the ACT-R cognitive modeling architecture to create computational cognitive process models serves as a common thread that will be helpful in integrating the products of these research lines into a functional system. The paper provides a summary of the current status of our research, as well as a description of externally developed technologies we plan to leverage in order to achieve our goal of a high-fidelity cognitive model that is able to operate as a member of a team performing UAV reconnaissance missions.;
-;-;
Author;Plump, J., Jarriel, M., Keegan, M., Ricard, M.;
Title;ONR's maritime reconnaissance demonstration-simulation based integration and test;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-33644750434&partnerID=40&md5=69f8747ef4affbccb48f9313944759e6;
-;-;
Abstract;ABSTRACT: Next-generation UUV missions will require increased levels of on-board adaptive, intelligent behavior. The development and testing of these advanced systems will require sophisticated virtual test environments that allow thorough system level checkout prior to in-water testing. All aspects of the mission, including sensors, sensor processing, situational awareness, and mission replanning, in addition to hydrodynamics and vehicle control functions, must be tested in a realistic environment. In addition, multiple simulation modes will be required starting with full emulation and continuing through Hardware-in-the-Loop in support of the incremental testing required of these complex systems. This type of end-to-end simulation capability has been developed by the team of the Charles Stark Draper Laboratory, NUWCDIVNPT, and Northrop Grumman as part of the Office of Naval Research Autonomous Operations Future Naval Capabilities (AOFNC) Maritime Reconnaissance Demonstration (MRD) program. The team is focused on developing, demonstrating, and transitioning open architecture autonomy along with ISR sensor technology to support US Navy UUV Acquisition Programs. This paper describes the high-level design and implementation of the MTV/21UUV simulation testbeds that includes the Narragansett Bay virtual environment and ISR sensor subsystems. It will also include a description of the multiple modes and the reconfiguration process devised to support the MRD integration and test phase.;
-;-;
Author;Czichon, C., Peterson, R.W., Mettala, E.G., Vondrak, I.;
Title;Coordinating teams of autonomous vehicles: An architectural perspective;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-27544477664&doi=10.1117%2f12.604115&partnerID=40&md5=87939e49e08fb33d41d661fb42508a16;
-;-;
DOI;DOI: 10.1117/12.604115;
Abstract;ABSTRACT: In defense-related robotics research, a mission level integration gap exists between mission tasks (tactical) performed by ground, sea, or air applications and elementary behaviors enacted by processing, communications, sensors, and weaponry resources (platform specific). The gap spans ensemble (heterogeneous team) behaviors, automatic MOE/MOP tracking, and tactical task modeling/simulation for virtual and mixed teams comprised of robotic and human combatants. This study surveys robotic system architectures, compares approaches for navigating problem/state spaces by autonomous systems, describes an architecture for an integrated, repository-based modeling, simulation, and execution environment, and outlines a multi-tiered scheme for robotic behavior components that is agent-based, platform-independent, and extendable via plug-ins. Tools for this integrated environment, along with a distributed agent framework for collaborative task performance are being developed by a U.S. Army funded SBIR project (RDECOM Contract N61339-04-C-0005).;
-;-;
Author;Fregene, K., Kennedy, D.C., Wang, D.W.L.;
Title;Toward a systems- and control-oriented agent framework;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-26844478270&doi=10.1109%2fTSMCB.2005.848491&partnerID=40&md5=1f34cddf64291eed1f3de3390b3b8213;
-;-;
DOI;DOI: 10.1109/TSMCB.2005.848491;
Abstract;ABSTRACT: This paper develops a systems- and control-oriented intelligent agent framework called the hybrid intelligent control agent (HICA), as well as its composition into specific kinds of multiagent systems. HICA is essentially developed around a hybrid control system core so that knowledge-based planning and coordination can be integrated with verified hybrid control primitives to achieve the coordinated control of multiple multimode dynamical systems. The scheme is applied to the control of teams of unmanned air and ground vehicles engaged in a pursuit-evasion war game. Results are demonstrated in simulation. © 2005 IEEE.;
-;-;
Author;SOFGE, D., BUGAJSKA, M., TRAFTON, J.G., PERZANOWSKI, D., THOMAS, S., SKUBIC, M., BLISARD, S., CASSIMATIS, N., BROCK, D., ADAMS, W., SCHULTZ, A.;
Title;COLLABORATING WITH HUMANOID ROBOTS IN SPACE;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122893540&doi=10.1142%2fS0219843605000442&partnerID=40&md5=1053b0478a838a8f4a11a0a3cc52e80a;
-;-;
DOI;DOI: 10.1142/S0219843605000442;
Abstract;ABSTRACT: One of the great challenges of putting humanoid robots into space is developing cognitive capabilities for the robots with an interface that allows human astronauts to collaborate with the robots as naturally and efficiently as they would with other astronauts. In this joint effort with NASA and the entire Robonaut team, we are integrating natural language and gesture understanding, spatial reasoning incorporating such features as human–robot perspective taking, and cognitive model-based understanding to achieve a high level of human–robot interaction. Building greater autonomy into the robot frees the human operator(s) from focusing strictly on the demands of operating the robot, and instead allows the possibility of actively collaborating with the robot to focus on the task at hand. By using shared representations between the human and robot, and enabling the robot to assume the perspectives of the human, the humanoid robot may become a more effective collaborator with a human astronaut for achieving mission objectives in space. © 2005 World Scientific Publishing Company;
-;-;
Author;Smith, P.R., Willcox, S.W.;
Title;Systems research for practical autonomy in unmanned air vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748708491&doi=10.2514%2f6.2005-7082&partnerID=40&md5=e9fd9144af5fa05d287aa1ebd2f2edc0;
-;-;
DOI;DOI: 10.2514/6.2005-7082;
Abstract;ABSTRACT: There exists a general expectation that advanced unmanned vehicles will require autonomous functionality, over and above a straightforward increase in level of automation. Much work is currently in hand in the research and development of algorithms and software approaches to achieve autonomy, but it is perceived that less attention is being given to hardware optimized to execute the algorithms. This paper will discuss practical approaches in achieving autonomy, what tools might be required to provide it, and what the implementation might be in a systems engineering context. The areas concerning systems testing and flight certification will also be touched upon. Work at Blue Bear Systems Research (BBSR), has concentrated on use of the Soar Artificial Intelligence language. This is not the only approach that can be used for the purpose, but has the attractive properties of reasoning, problem solving, planning and learning. Intelligent systems of this type are often referred to as 'agents'. It is often the case that these agents can become very large very quickly, and BBSR have been pursuing a more modular approach. To achieve the complexity likely to be implicit in a future autonomous system it is probable that the end system will need to be a multi-agent structure with communicating sub-agents having specialization in a specific task such as situational awareness, combat tactics, team-working or optimal route planning. Note that by their very nature these processes may be asynchronous, and indeed something like planning may be a 'batch-mode' job, where the agent is given a task and it then informs the other agents when it has completed, and presents its results. Note also that these different functions are likely to be expressed using differing techniques and software embodiment. Thus a multi-agent system could, for example, use Bayesian belief approaches for reasoning, Soar methods for problem solving and learning, and a direct mathematical algorithm implemented in C to carry out the route planning. Considerable effort at BBSR has been expended in investigating hardware solutions suitable for the implementation of distributed agents in smaller UAV's and Micro Air Vehicles. This requirement focuses on size weight and power requirements in order to provide sufficient the required computing resource, whilst providing a direct route to larger, more capable systems that could equip a larger J-UCAS class UCAV. The paper will present techniques from computer science in the employment of clustering techniques using low-cost X-scale and PC based processors, and the relative merits of Floating Point Gate Array (FPGA) solutions. This will be illustrated in the context of a complex multi-agent system designed to search a network of roads. Copyright © 2005 by Blue Bear Systems Research Ltd.;
-;-;
Author;Valavanis, K.P.;
Title;Heterogeneous system challenges in control, coordination, and communication: A case study with unmanned ground - Aerial vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744986507&doi=10.1109%2fcontel.2005.185804&partnerID=40&md5=cc6d59b005e921881b4c6ec86bd8d14d;
-;-;
DOI;DOI: 10.1109/contel.2005.185804;
Abstract;"ABSTRACT: Heterogeneous system design, modeling and testing requires that concepts and ideas from the diverse disciplines of Distributed Artificial Intelligence, Multi Agent Systems and Generalized System Theory be brought together under a common framework. Multi layer, hybrid, open architectures need be designed to manage distributed objects, services and modules between system components and support overall system functionality. Issues that need be addressed include, among others, individual component control, component coordination and communication, as well as overall system functionality in the presence of communication failures. This presentation considers the case of heterogeneous teams of unmanned ground - aerial robots operating in uncertain / hostile environments. It discusses aspects of distributed system architecture; it addresses fundamental control and communication problems and recommended solutions to distributed task allocation using unmanned ground - aerial vehicles; it examines asset recruitment with and without communication failures. Experimental studies and demos related to demining applications and traffic monitoring and emergency response have been conducted and they will be discussed.";
-;-;
Author;Bovard, M., De Lanerolle, T., Trinh, N., Votto, P., Gillette, M., Marinkovic, B., Bhandari, S., Harder, K.;
Title;Alvin-V: Design report;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-21644471551&partnerID=40&md5=aa1383ea2ebbacaf9640a892066e2aff;
-;-;
Abstract;ABSTRACT: The development of fifth generation of unmanned Intelligent Ground Vehicles, ALVIN-V, from the robot study team (RST) of Trinity College is reported. The ALVIN-V all-weather cover was designed using the Solidworks software package and was constructed using a semi-malleable wire mesh and polymer. The latest NI hardware has enabled to remove the laptop and Vesta board central to many generations of ALVIN. The robot body is made from light weight molded polymer, so as to avoid the chance of accidental electrical shock to the operators of the robot from the batteries.;
-;-;
Author;Cummings, M.L., Guerlain, S.;
Title;An interactive decision support tool for real-time in-flight replanning of autonomous vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-19644385335&partnerID=40&md5=ae2fa726929e83450157c89bb389d55a;
-;-;
Abstract;"ABSTRACT: There is significant interest in the Department of Defense to design and build networks of unmanned vehicles that will have the ability of operating autonomously, which will in effect, take the human out of the loop at certain levels of tasking. While unmanned systems do not necessarily have a human in direct, manual control, humans will be necessarily involved in planning, higher-level operation, and contingency interventions (including system failures). Thus a system of command and control unmanned vehicles is still a manned system. The implementation of networks of autonomous airborne vehicles means that not only will battlefield commanders have more flexibility and options; it also means that a layer of human command and control will be needed where none previously existed. In this futuristic command and control network, the nature of human interaction will change from that of manual control to supervisory control, with different layers of automation, which will require more abstract knowledge-based reasoning. Requiring an operator to manage high value assets in a time-pressure environment through constant replanning requires substantial cognitive effort, and affects both individuals and teams in the command and control environment. This paper will discuss a prototype created to address this dynamic replanning problem through a U.S. Navy future naval capabilities research effort.";
Abstract;;
Author;Smith, P., Rouff, C.;
Title;Integrated UGV and UAV autonomy for Urban area peace enforcement;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-19644378065&partnerID=40&md5=39a213c7943d928eb5de964505bbd5a5;
-;-;
Abstract;ABSTRACT: This paper describes the development of intelligent agents in Soar to exercise a group of communicating Unmanned Ground Vehicles (UGV's) and Unmanned Air Vehicles (UAV's) patrolling a representative network of roads in an urban peace keeping environment. The scenario features up to 6 ground vehicles undertaking a routine patrol and encountering threat regions. The UGV's can be accompanied by up to 4 airborne surveillance UAV's. No direct human components or intervention is considered at this stage, i.e. it has fully autonomous operation for the purposes of the simulation. The task for the vehicles is to work cooperatively to investigate the threat regions whilst dynamically re-routing around any blocked streets that may be encountered as the simulation proceeds. The study has served to provide a working illustration of some basic principles and possibilities for integrated teamwork of unmanned ground and air vehicles. Copyright © 2004 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved.;
-;-;
Author;Hart, D.M., Craig-Hart, P.A.;
Title;Reducing swarming theory to practice for UAV control;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-11244340783&doi=10.1109%2fAERO.2004.1368111&partnerID=40&md5=88c45e8c1339ca552d17daa23916737d;
-;-;
DOI;DOI: 10.1109/AERO.2004.1368111;
Abstract;ABSTRACT: The introduction of increasingly sophisticated unmanned aerial vehicles (UAVs) into the U.S. force structure has shown that the cognitive operator burden increases with the technical complexity of the robot. It takes more humans to control advanced UAVs than simple ones, and this burden is bound to increase when there are more UAVs to control. One promising approach for reducing the ratio of operators to UAVs can be found in a robotic theory that mimics emerging systems found in nature - swarming. An examination of the state-of-the art in swarm intelligence applications in the academic, commercial, and military research community indicates that this approach to robotic control may be achieving the critical mass necessary to exit the laboratory, but, despite its promise, swarm robotic control software is technically far behind its target hardware. This paper explores opportunities for reducing robotic swarming theory to practice for UAVs by identifying candidate swarm algorithms, examples of their utility to military robotics, and the challenges associated with swarm programming. We conclude with a systematic, theory-driven approach to metrics for gaining an accurate picture of man/machine team performance. 1,2.;
-;-;
Author;Vachtsevanos, G., Tang, L., Reimann, J.;
Title;An intelligent approach to coordinated control of multiple unmanned aerial vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-4143149552&partnerID=40&md5=ae74e409024330e0cdd95e4c826a4090;
-;-;
Abstract;ABSTRACT: This paper introduces a novel architecture for the coordinated control of multiple Unmanned Aerial Vehicles (UAVs) and a differential game theoretical approach to formation control and collision avoidance. The hierarchical architecture features an upper level with global situation awareness and team mission planning, a middle level with local knowledge, formation control and obstacle avoidance, and a low level that interfaces with onboard baseline controllers, sensors, communication and weapon systems. Each level consists of several interacting agents with dedicated functions. The formation control problem is viewed as a Pursuit Game of n pursuers and n evaders. Stability of the formation of vehicles is guaranteed if the vehicles can reach their destinations within a specified time, assuming that the destination points are avoiding the vehicles in an optimal fashion. A two-vehicle example is shown to illustrate the approach. Vehicle model is simplified to point mass with acceleration limit. Collision avoidance is achieved by designing the value function so that it ensures that the two vehicles move away from one another when they come too close to each one. Simulation results are provided to verify the performance of the proposed algorithm.;
-;-;
Author;Ortiz Jr., C.L., Agno, A., Berry, P., Vincent, R.;
Title;Multi-level adaptation in teams of unmanned air and ground vehicles;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085404490&doi=10.2514%2f6.2002-3474&partnerID=40&md5=b1e0c5ae898bc2bd8647c1147dd36154;
-;-;
DOI;DOI: 10.2514/6.2002-3474;
Abstract;ABSTRACT: We describe ongoing work to develop algorithms and software for the reprogrammable, coordinated command and control of teams of autonomous vehicles (AVs). This new software capability extends current work in distributed artificial intelligence and is intended to allow developers to build and test AV teams that collaboratively perform tasks - such as reconnaissance and surveillance - with minimal supervision in dynamic, unstructured environments. We describe a multilevel robot architecture which is adaptive along a number of dimensions, as well as several new technologies that have been developed to support behavior blending and inter-robot negotiation.;
-;-;
Author;Rajan, K., Shirley, M., Taylor, W., Kanefsky, B.;
Title;Ground tools for autonomy in the 21st century;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034431739&partnerID=40&md5=2bceb39ce3f38957224f6b53e44f1601;
-;-;
Abstract;ABSTRACT: Ground tools for unmanned spacecraft are changing rapidly driven by twin innovations: advanced autonomy and ubiquitous networking. Critical issues are the delegation of low-level decision-making to software, the transparency and accountability of that software, mixed-initiative control, i.e., the ability of controllers to adjust portions of the software's activity without disturbing other portions, and the makeup and geographic distribution of the flight control team. These innovations will enable ground controllers to manage space-based resources much more efficiently and, in the case of science missions, give principal investigators an unprecedented level of direct control. This paper explores these ideas by describing the ground tools for the Remote Agent experiment aboard the Deep Space 1 spacecraft in May of 1999. The experiment demonstrated autonomous control capabilities including goal-oriented commanding, on-board planning, robust plan execution and model-based fault protection. We then speculate on the effect of these technologies on the future of spacecraft ground control.;
-;-;
Author;Eilbert, J., Campbell, G., Bracken, K.;
Title;A Cognitive agent that delivers human-centric advice about system design;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034427589&doi=10.1117%2f12.407525&partnerID=40&md5=06d7535599eaf3297320591cee2608aa;
-;-;
DOI;DOI: 10.1117/12.407525;
Abstract;ABSTRACT: The design of new Navy ships that can be effectively manned with dramatically fewer sailors raises can be supported by a digital design environment. In this paper we will describe an effort currently underway to develop a software agent, the Executive Advisor, that can reason about human factors information accessible within the design environment. It will be able to alert and advise the engineering design team regarding human factors issues and analyses appropriate to the current stage of the system design process. The agent is being built with a cognitive modeling tool called iGENTM, in order to (a) give advice about human factors issues and analyses appropriate to the current stage of design and design team activity, (b) reason about when to deliver and how to filter advice, (c) explain its advice, and (d) monitor changes in the design environment and reason about their impact. The structure of the agent and the issues in creating it will be described. © 2000 SPIE-The International Society for Optical Engineering.;
-;-;
Author;Eilbert, J., Bracken, K., Campbell, G.E., McDonald, B.;
Title;The application of a cognitive model as a human factors decision support system for design teams;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-1842637374&doi=10.1177%2f154193120004400617&partnerID=40&md5=ee16e6aa69c5687f719b6b0c0924a30b;
-;-;
DOI;DOI: 10.1177/154193120004400617;
Abstract;ABSTRACT: The push in the Navy to design and build new ships that can be effectively manned with dramatically fewer sailors raises key Human Factors issues that must be addressed in the system design process. To promote the understanding of these issues and their solutions throughout the system design team, an effort is currently underway to develop a software agent, called the Executive Advisor (EA). This agent will alert and advise systems engineers and the rest of the engineering team regarding human factors issues and analyses appropriate to the current stage of the system design process. The EA is being built with a cognitive modeling tool called iGEN™, in order to (a) enable context-sensitive reasoning about relevant human factors issues, and (b) facilitate human-agent dialogue. The capabilities and structure of the agent will be described.;
-;-;
Author;Lane, Gerald R.;
Title;Tank-automotive robotics;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033318053&partnerID=40&md5=ba7cfef25543727243b71f8e0d940f72;
-;-;
Abstract;ABSTRACT: To provide an overview of Tank-Automotive Robotics. The briefing will contain program overviews & inter-relationships and technology challenges of TARDEC managed unmanned and robotic ground vehicle programs. Specific emphasis will focus on technology developments/approaches to achieve semi-autonomous operation and inherent chassis mobility features. Programs to be discussed include: DemoIII Experimental Unmanned Vehicle (XUV), Tactical Mobile Robotics (TMR), Intelligent Mobility, Commanders Driver Testbed, Collision Avoidance, International Ground Robotics Competition (IGRC). Specifically, the paper will discuss unique exterior/outdoor challenges facing the IGRC competing teams and the synergy created between the IGRC and ongoing DoD semi-autonomous Unmanned Ground Vehicle and DoT Intelligent Transportation System programs. Sensor and chassis approaches to meet the IGRC challenges and obstacles will be shown and discussed. Shortfalls in performance to meet the IGRC challenges will be identified.;
-;-;
Author;Murphy, Robin R.;
Title;Artificial intelligence approach to the 1994 AUVS unmanned ground robotics competition;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029547317&partnerID=40&md5=eed6a536c07e5343fd8e6f2232954c09;
-;-;
Abstract;ABSTRACT: This paper describes the artificial intelligence (AI) approach taken by the CSM team to the Second Annual AUVS International Unmanned Ground Robotics Competition held in Rochester, Michigan, May 20-22, 1994. Using this approach, the CSM entry Omnibot won first place and a $5000 prize for the six student team members. The AI approach relied on a reactive architecture to decompose the robot's functions into a set of reflexive behaviors, and the principle of action-oriented perception to guide the design of each individual behavior and its relationship to the others. The major contribution of this paper is a case study of a successful reactive behavioral design for an autonomous mobile robot.;
-;-;
Author;Geddes, Norman D.;
Title;Verification and validation testing of the pilot's associate;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026406032&partnerID=40&md5=4a23148631abb7b86f76f67fdd623d88;
-;-;
Abstract;ABSTRACT: The DARPA/USAF/Lockheed Pilot's Associate is a comprehensive and complex real-time artificial intelligence decision aid. The author discusses how the Lockheed team is conducting the verification and validation of the Pilot's Associate as an integrated methodology that brings design and test into a closer relationship. The issues of verification and validation have been addressed as an integral part of the design and development process over the course of the project. The methodology encompasses digital combat simulations, engineering development testing of individual software units and subsystems, prototype testing, manned functional testing, real-time performance testing, and a manned operational performance evaluation.;
-;-;
Author;Vere, Steven A.;
Title;DEVISER: AN AI PLANNER FOR SPACECRAFT OPERATIONS.;
-;-;
Link;https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022043034&partnerID=40&md5=33999a9e76bf51aba9fd6f684ebcd9f8;
-;-;
Abstract;ABSTRACT: Planning the actions of unmanned spacecraft, such as Voyager, calls for large teams of analysts and months of preparation. Last-minute changes are fraught with difficulty and risk. Application of artificial intelligence (AI) to this effort cuts time, cost, and risk. Over the past four years, a Jet Propulsion Lab (JPL) team has designed a prototype automatic planner called Deviser III. Running overnight on its dedicated Symbolics 3600 computer, Deviser III can plan complete Voyager sequences consisting of over 100 data-capture goals. The system works 10-50 times faster than a human analyst.;
